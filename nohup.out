Called with args:
Namespace(cfg_file='./experiments/activitynet/td_cnn_end2end.yml', gpu_id=0, max_iters=350000, pretrained_model='./pretrain/activitynet_iter_30000_3fps.caffemodel', randomize=False, set_cfgs=None, solver='./experiments/activitynet/solver.prototxt')
Using config:
{'DEDUP_BOXES': 0.125,
 'EPS': 1e-14,
 'FPS': 25,
 'GPU_ID': 0,
 'INPUT': 'video',
 'NUM_CLASSES': 201,
 'PIXEL_MEANS': array([[[ 90,  98, 102]]]),
 'PIXEL_MEANS_FLOW': array([128]),
 'RNG_SEED': 3,
 'TEST': {'CROP_SIZE': 112,
          'FRAME_SIZE': [128, 171],
          'HAS_RPN': True,
          'LENGTH': [768],
          'MAX_SIZE': 1000,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.9,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SVM': False,
          'TWIN_REG': True},
 'TRAIN': {'BATCH_SIZE': 128,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.1,
           'CINPUT': False,
           'CROP_SIZE': 112,
           'FG_FRACTION': 0.5,
           'FG_THRESH': 0.5,
           'FRAME_SIZE': [128, 171],
           'HAS_RPN': True,
           'LENGTH': [768],
           'OHEM_LOSS_ONLY_CLASSIFICATION': False,
           'OHEM_LOSS_ONLY_LOCALIZATION': False,
           'OHEM_NMS_THRESH': 0.7,
           'OHEM_USE_NMS': True,
           'PROPOSAL_METHOD': 'gt',
           'RANDOM': False,
           'RPN_BATCHSIZE': 64,
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.8,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'RPN_TWIN_INSIDE_WEIGHTS': [1.0, 1.0],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 1000,
           'TWIN_INSIDE_WEIGHTS': [1.0, 1.0],
           'TWIN_NORMALIZE_MEANS': [0.0, 0.0],
           'TWIN_NORMALIZE_STDS': [0.1, 0.2],
           'TWIN_NORMALIZE_TARGETS': False,
           'TWIN_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'TWIN_REG': True,
           'TWIN_THRESH': 0.5,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False,
           'VIDEO_BATCH': 1},
 'USE_GPU_NMS': True}
18388 roidb entries
Output will be saved to `./experiments/best_activitynet/snapshot/`
Computing bounding-box regression targets...
precimputed
twin target means:
twin target stdevs:
NOT normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0422 02:57:42.432971 21412 solver.cpp:48] Initializing solver from parameters: 
train_net: "./experiments/activitynet/train.prototxt"
base_lr: 0.0001
display: 1
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 350000
snapshot: 0
snapshot_prefix: "./experiments/activitynet/snapshot/activitynet"
average_loss: 100
iter_size: 1
I0422 02:57:42.433002 21412 solver.cpp:81] Creating training net from train_net file: ./experiments/activitynet/train.prototxt
I0422 02:57:42.434042 21412 net.cpp:58] Initializing net from parameters: 
name: "activitynet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 200"
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    kernel_size: 2
    kernel_size: 2
    stride: 1
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv2a"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv3a"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "conv3b"
  type: "Convolution"
  bottom: "conv3a"
  top: "conv3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3b"
  type: "ReLU"
  bottom: "conv3b"
  top: "conv3b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv4a"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "conv4b"
  type: "Convolution"
  bottom: "conv4a"
  top: "conv4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4b"
  type: "ReLU"
  bottom: "conv4b"
  top: "conv4b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv5a"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "conv5b"
  type: "Convolution"
  bottom: "conv5a"
  top: "conv5b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5b"
  type: "ReLU"
  bottom: "conv5b"
  top: "conv5b"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5b"
  top: "rpn/output"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_conv/3x3_2"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn/output_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3_2"
  type: "ReLU"
  bottom: "rpn/output_2"
  top: "rpn/output_2"
}
layer {
  name: "rpn/output_pool"
  type: "Pooling"
  bottom: "rpn/output_2"
  top: "rpn/output_pool"
  pooling_param {
    pool: MAX
    kernel_size: 1
    kernel_size: 2
    kernel_size: 2
  }
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output_pool"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 74
    kernel_size: 1
    kernel_size: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_twin_pred"
  type: "Convolution"
  bottom: "rpn/output_pool"
  top: "rpn_twin_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 74
    kernel_size: 1
    kernel_size: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_twin_targets"
  top: "rpn_twin_inside_weights"
  top: "rpn_twin_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 8 \n\'scales\': !!python/tuple [1,1.25, 1.5,1.75, 2,2.5, 3,3.5, 4,4.5, 5,5.5, 6,7, 8,9,10,11,12,14,16,18,20,22,24,28,32,36,40,44,52,60,68,76,84,92,100]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_twin"
  type: "SmoothL1Loss"
  bottom: "rpn_twin_pred"
  bottom: "rpn_twin_targets"
  bottom: "rpn_twin_inside_weights"
  bottom: "rpn_twin_outside_weights"
  top: "rpn_loss_twin"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_accuarcy"
  type: "Accuracy"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_accuarcy"
  top: "rpn_accuarcy_class"
  propagate_down: false
  propagate_down: false
  accuracy_param {
    ignore_label: -1
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 74
      dim: -1
      dim: 0
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_twin_pred"
  top: "rpn_rois"
  include {
    phase: TRAIN
  }
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 8 \n\'scales\': !!python/tuple [1,1.25, 1.5,1.75, 2,2.5, 3,3.5, 4,4.5, 5,5.5, 6,7, 8,9,10,11,12,14,16,18,20,22,24,28,32,36,40,44,52,60,68,76,84,92,100]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  top: "rois"
  top: "labels"
  top: "twin_targets"
  top: "twin_inside_weights"
  top: "twin_outside_weights"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 200"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5b"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 4
    pooled_w: 4
    spatial_scale: 0.0625
    pooled_l: 1
    temporal_scale: 0.125
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc6"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 200
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "twin_pred"
  type: "InnerProduct"
  bottom: "fc6"
  top: "twin_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 400
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SigmoidCrossEntropyLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_twin"
  type: "SmoothL1Loss"
  bottom: "twin_pred"
  bottom: "twin_targets"
  bottom: "twin_inside_weights"
  bottom: "twin_outside_weights"
  top: "loss_twin"
  loss_weight: 1
}
layer {
  name: "accuracy"
  type: "Python"
  bottom: "cls_score"
  bottom: "labels"
  top: "accuracy"
  python_param {
    module: "utils.accuracy_layer"
    layer: "AccuracyLayer"
    param_str: "{\"top_k\": 2}"
  }
}
I0422 02:57:42.434254 21412 layer_factory.hpp:77] Creating layer data
I0422 02:57:42.468348 21412 net.cpp:100] Creating Layer data
I0422 02:57:42.468371 21412 net.cpp:408] data -> data
I0422 02:57:42.468384 21412 net.cpp:408] data -> gt_boxes
setting up
has rpn
RoiDataLayer: name_to_top: {'gt_windows': 1, 'data': 0}
I0422 02:57:42.528177 21412 net.cpp:150] Setting up data
I0422 02:57:42.528199 21412 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 02:57:42.528208 21412 net.cpp:157] Top shape: 1 101 (101)
I0422 02:57:42.528213 21412 net.cpp:165] Memory required for data: 115605908
I0422 02:57:42.528219 21412 layer_factory.hpp:77] Creating layer data_data_0_split
I0422 02:57:42.528232 21412 net.cpp:100] Creating Layer data_data_0_split
I0422 02:57:42.528239 21412 net.cpp:434] data_data_0_split <- data
I0422 02:57:42.528249 21412 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0422 02:57:42.528259 21412 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0422 02:57:42.528290 21412 net.cpp:150] Setting up data_data_0_split
I0422 02:57:42.528297 21412 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 02:57:42.528303 21412 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 02:57:42.528306 21412 net.cpp:165] Memory required for data: 346816916
I0422 02:57:42.528311 21412 layer_factory.hpp:77] Creating layer gt_boxes_data_1_split
I0422 02:57:42.528317 21412 net.cpp:100] Creating Layer gt_boxes_data_1_split
I0422 02:57:42.528321 21412 net.cpp:434] gt_boxes_data_1_split <- gt_boxes
I0422 02:57:42.528326 21412 net.cpp:408] gt_boxes_data_1_split -> gt_boxes_data_1_split_0
I0422 02:57:42.528333 21412 net.cpp:408] gt_boxes_data_1_split -> gt_boxes_data_1_split_1
I0422 02:57:42.528357 21412 net.cpp:150] Setting up gt_boxes_data_1_split
I0422 02:57:42.528363 21412 net.cpp:157] Top shape: 1 101 (101)
I0422 02:57:42.528368 21412 net.cpp:157] Top shape: 1 101 (101)
I0422 02:57:42.528372 21412 net.cpp:165] Memory required for data: 346817724
I0422 02:57:42.528375 21412 layer_factory.hpp:77] Creating layer conv1a
I0422 02:57:42.528391 21412 net.cpp:100] Creating Layer conv1a
I0422 02:57:42.528398 21412 net.cpp:434] conv1a <- data_data_0_split_0
I0422 02:57:42.528404 21412 net.cpp:408] conv1a -> conv1a
I0422 02:57:42.941082 21412 net.cpp:150] Setting up conv1a
I0422 02:57:42.941109 21412 net.cpp:157] Top shape: 1 64 768 112 112 (616562688)
I0422 02:57:42.941114 21412 net.cpp:165] Memory required for data: 2813068476
I0422 02:57:42.941134 21412 layer_factory.hpp:77] Creating layer relu1a
I0422 02:57:42.941154 21412 net.cpp:100] Creating Layer relu1a
I0422 02:57:42.941159 21412 net.cpp:434] relu1a <- conv1a
I0422 02:57:42.941169 21412 net.cpp:395] relu1a -> conv1a (in-place)
I0422 02:57:42.941781 21412 net.cpp:150] Setting up relu1a
I0422 02:57:42.941794 21412 net.cpp:157] Top shape: 1 64 768 112 112 (616562688)
I0422 02:57:42.941799 21412 net.cpp:165] Memory required for data: 5279319228
I0422 02:57:42.941803 21412 layer_factory.hpp:77] Creating layer pool1
I0422 02:57:42.941813 21412 net.cpp:100] Creating Layer pool1
I0422 02:57:42.941819 21412 net.cpp:434] pool1 <- conv1a
I0422 02:57:42.941828 21412 net.cpp:408] pool1 -> pool1
I0422 02:57:42.942154 21412 net.cpp:150] Setting up pool1
I0422 02:57:42.942165 21412 net.cpp:157] Top shape: 1 64 768 56 56 (154140672)
I0422 02:57:42.942168 21412 net.cpp:165] Memory required for data: 5895881916
I0422 02:57:42.942173 21412 layer_factory.hpp:77] Creating layer conv2a
I0422 02:57:42.942184 21412 net.cpp:100] Creating Layer conv2a
I0422 02:57:42.942189 21412 net.cpp:434] conv2a <- pool1
I0422 02:57:42.942195 21412 net.cpp:408] conv2a -> conv2a
I0422 02:57:42.956401 21412 net.cpp:150] Setting up conv2a
I0422 02:57:42.956425 21412 net.cpp:157] Top shape: 1 128 768 56 56 (308281344)
I0422 02:57:42.956430 21412 net.cpp:165] Memory required for data: 7129007292
I0422 02:57:42.956444 21412 layer_factory.hpp:77] Creating layer relu2a
I0422 02:57:42.956454 21412 net.cpp:100] Creating Layer relu2a
I0422 02:57:42.956459 21412 net.cpp:434] relu2a <- conv2a
I0422 02:57:42.956472 21412 net.cpp:395] relu2a -> conv2a (in-place)
I0422 02:57:42.956995 21412 net.cpp:150] Setting up relu2a
I0422 02:57:42.957012 21412 net.cpp:157] Top shape: 1 128 768 56 56 (308281344)
I0422 02:57:42.957020 21412 net.cpp:165] Memory required for data: 8362132668
I0422 02:57:42.957026 21412 layer_factory.hpp:77] Creating layer pool2
I0422 02:57:42.957043 21412 net.cpp:100] Creating Layer pool2
I0422 02:57:42.957051 21412 net.cpp:434] pool2 <- conv2a
I0422 02:57:42.957062 21412 net.cpp:408] pool2 -> pool2
I0422 02:57:42.960203 21412 net.cpp:150] Setting up pool2
I0422 02:57:42.960216 21412 net.cpp:157] Top shape: 1 128 384 28 28 (38535168)
I0422 02:57:42.960220 21412 net.cpp:165] Memory required for data: 8516273340
I0422 02:57:42.960224 21412 layer_factory.hpp:77] Creating layer conv3a
I0422 02:57:42.960234 21412 net.cpp:100] Creating Layer conv3a
I0422 02:57:42.960240 21412 net.cpp:434] conv3a <- pool2
I0422 02:57:42.960247 21412 net.cpp:408] conv3a -> conv3a
I0422 02:57:42.986733 21412 net.cpp:150] Setting up conv3a
I0422 02:57:42.986750 21412 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 02:57:42.986754 21412 net.cpp:165] Memory required for data: 8824554684
I0422 02:57:42.986778 21412 layer_factory.hpp:77] Creating layer relu3a
I0422 02:57:42.986788 21412 net.cpp:100] Creating Layer relu3a
I0422 02:57:42.986793 21412 net.cpp:434] relu3a <- conv3a
I0422 02:57:42.986798 21412 net.cpp:395] relu3a -> conv3a (in-place)
I0422 02:57:42.988189 21412 net.cpp:150] Setting up relu3a
I0422 02:57:42.988203 21412 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 02:57:42.988206 21412 net.cpp:165] Memory required for data: 9132836028
I0422 02:57:42.988210 21412 layer_factory.hpp:77] Creating layer conv3b
I0422 02:57:42.988222 21412 net.cpp:100] Creating Layer conv3b
I0422 02:57:42.988229 21412 net.cpp:434] conv3b <- conv3a
I0422 02:57:42.988234 21412 net.cpp:408] conv3b -> conv3b
I0422 02:57:43.039436 21412 net.cpp:150] Setting up conv3b
I0422 02:57:43.039459 21412 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 02:57:43.039465 21412 net.cpp:165] Memory required for data: 9441117372
I0422 02:57:43.039475 21412 layer_factory.hpp:77] Creating layer relu3b
I0422 02:57:43.039489 21412 net.cpp:100] Creating Layer relu3b
I0422 02:57:43.039499 21412 net.cpp:434] relu3b <- conv3b
I0422 02:57:43.039505 21412 net.cpp:395] relu3b -> conv3b (in-place)
I0422 02:57:43.040318 21412 net.cpp:150] Setting up relu3b
I0422 02:57:43.040330 21412 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 02:57:43.040334 21412 net.cpp:165] Memory required for data: 9749398716
I0422 02:57:43.040338 21412 layer_factory.hpp:77] Creating layer pool3
I0422 02:57:43.040346 21412 net.cpp:100] Creating Layer pool3
I0422 02:57:43.040354 21412 net.cpp:434] pool3 <- conv3b
I0422 02:57:43.040361 21412 net.cpp:408] pool3 -> pool3
I0422 02:57:43.040612 21412 net.cpp:150] Setting up pool3
I0422 02:57:43.040623 21412 net.cpp:157] Top shape: 1 256 192 14 14 (9633792)
I0422 02:57:43.040627 21412 net.cpp:165] Memory required for data: 9787933884
I0422 02:57:43.040632 21412 layer_factory.hpp:77] Creating layer conv4a
I0422 02:57:43.040642 21412 net.cpp:100] Creating Layer conv4a
I0422 02:57:43.040647 21412 net.cpp:434] conv4a <- pool3
I0422 02:57:43.040654 21412 net.cpp:408] conv4a -> conv4a
I0422 02:57:43.141916 21412 net.cpp:150] Setting up conv4a
I0422 02:57:43.141952 21412 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 02:57:43.141958 21412 net.cpp:165] Memory required for data: 9865004220
I0422 02:57:43.141978 21412 layer_factory.hpp:77] Creating layer relu4a
I0422 02:57:43.141993 21412 net.cpp:100] Creating Layer relu4a
I0422 02:57:43.141999 21412 net.cpp:434] relu4a <- conv4a
I0422 02:57:43.142010 21412 net.cpp:395] relu4a -> conv4a (in-place)
I0422 02:57:43.142632 21412 net.cpp:150] Setting up relu4a
I0422 02:57:43.142645 21412 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 02:57:43.142649 21412 net.cpp:165] Memory required for data: 9942074556
I0422 02:57:43.142653 21412 layer_factory.hpp:77] Creating layer conv4b
I0422 02:57:43.142671 21412 net.cpp:100] Creating Layer conv4b
I0422 02:57:43.142678 21412 net.cpp:434] conv4b <- conv4a
I0422 02:57:43.142685 21412 net.cpp:408] conv4b -> conv4b
I0422 02:57:43.355798 21412 net.cpp:150] Setting up conv4b
I0422 02:57:43.355823 21412 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 02:57:43.355828 21412 net.cpp:165] Memory required for data: 10019144892
I0422 02:57:43.355837 21412 layer_factory.hpp:77] Creating layer relu4b
I0422 02:57:43.355846 21412 net.cpp:100] Creating Layer relu4b
I0422 02:57:43.355855 21412 net.cpp:434] relu4b <- conv4b
I0422 02:57:43.355864 21412 net.cpp:395] relu4b -> conv4b (in-place)
I0422 02:57:43.357678 21412 net.cpp:150] Setting up relu4b
I0422 02:57:43.357689 21412 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 02:57:43.357694 21412 net.cpp:165] Memory required for data: 10096215228
I0422 02:57:43.357699 21412 layer_factory.hpp:77] Creating layer pool4
I0422 02:57:43.357707 21412 net.cpp:100] Creating Layer pool4
I0422 02:57:43.357713 21412 net.cpp:434] pool4 <- conv4b
I0422 02:57:43.357719 21412 net.cpp:408] pool4 -> pool4
I0422 02:57:43.359971 21412 net.cpp:150] Setting up pool4
I0422 02:57:43.359984 21412 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:57:43.359988 21412 net.cpp:165] Memory required for data: 10105849020
I0422 02:57:43.359992 21412 layer_factory.hpp:77] Creating layer conv5a
I0422 02:57:43.360003 21412 net.cpp:100] Creating Layer conv5a
I0422 02:57:43.360009 21412 net.cpp:434] conv5a <- pool4
I0422 02:57:43.360015 21412 net.cpp:408] conv5a -> conv5a
I0422 02:57:43.550050 21412 net.cpp:150] Setting up conv5a
I0422 02:57:43.550083 21412 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:57:43.550087 21412 net.cpp:165] Memory required for data: 10115482812
I0422 02:57:43.550096 21412 layer_factory.hpp:77] Creating layer relu5a
I0422 02:57:43.550107 21412 net.cpp:100] Creating Layer relu5a
I0422 02:57:43.550112 21412 net.cpp:434] relu5a <- conv5a
I0422 02:57:43.550125 21412 net.cpp:395] relu5a -> conv5a (in-place)
I0422 02:57:43.551239 21412 net.cpp:150] Setting up relu5a
I0422 02:57:43.551252 21412 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:57:43.551257 21412 net.cpp:165] Memory required for data: 10125116604
I0422 02:57:43.551262 21412 layer_factory.hpp:77] Creating layer conv5b
I0422 02:57:43.551275 21412 net.cpp:100] Creating Layer conv5b
I0422 02:57:43.551280 21412 net.cpp:434] conv5b <- conv5a
I0422 02:57:43.551286 21412 net.cpp:408] conv5b -> conv5b
I0422 02:57:43.740964 21412 net.cpp:150] Setting up conv5b
I0422 02:57:43.740991 21412 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:57:43.740996 21412 net.cpp:165] Memory required for data: 10134750396
I0422 02:57:43.741005 21412 layer_factory.hpp:77] Creating layer relu5b
I0422 02:57:43.741017 21412 net.cpp:100] Creating Layer relu5b
I0422 02:57:43.741026 21412 net.cpp:434] relu5b <- conv5b
I0422 02:57:43.741034 21412 net.cpp:395] relu5b -> conv5b (in-place)
I0422 02:57:43.743249 21412 net.cpp:150] Setting up relu5b
I0422 02:57:43.743261 21412 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:57:43.743266 21412 net.cpp:165] Memory required for data: 10144384188
I0422 02:57:43.743270 21412 layer_factory.hpp:77] Creating layer conv5b_relu5b_0_split
I0422 02:57:43.743284 21412 net.cpp:100] Creating Layer conv5b_relu5b_0_split
I0422 02:57:43.743290 21412 net.cpp:434] conv5b_relu5b_0_split <- conv5b
I0422 02:57:43.743295 21412 net.cpp:408] conv5b_relu5b_0_split -> conv5b_relu5b_0_split_0
I0422 02:57:43.743306 21412 net.cpp:408] conv5b_relu5b_0_split -> conv5b_relu5b_0_split_1
I0422 02:57:43.743346 21412 net.cpp:150] Setting up conv5b_relu5b_0_split
I0422 02:57:43.743355 21412 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:57:43.743360 21412 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:57:43.743362 21412 net.cpp:165] Memory required for data: 10163651772
I0422 02:57:43.743366 21412 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0422 02:57:43.743376 21412 net.cpp:100] Creating Layer rpn_conv/3x3
I0422 02:57:43.743381 21412 net.cpp:434] rpn_conv/3x3 <- conv5b_relu5b_0_split_0
I0422 02:57:43.743387 21412 net.cpp:408] rpn_conv/3x3 -> rpn/output
I0422 02:57:43.935539 21412 net.cpp:150] Setting up rpn_conv/3x3
I0422 02:57:43.935564 21412 net.cpp:157] Top shape: 1 512 96 4 4 (786432)
I0422 02:57:43.935569 21412 net.cpp:165] Memory required for data: 10166797500
I0422 02:57:43.935581 21412 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0422 02:57:43.935591 21412 net.cpp:100] Creating Layer rpn_relu/3x3
I0422 02:57:43.935603 21412 net.cpp:434] rpn_relu/3x3 <- rpn/output
I0422 02:57:43.935611 21412 net.cpp:395] rpn_relu/3x3 -> rpn/output (in-place)
I0422 02:57:43.937052 21412 net.cpp:150] Setting up rpn_relu/3x3
I0422 02:57:43.937067 21412 net.cpp:157] Top shape: 1 512 96 4 4 (786432)
I0422 02:57:43.937070 21412 net.cpp:165] Memory required for data: 10169943228
I0422 02:57:43.937074 21412 layer_factory.hpp:77] Creating layer rpn_conv/3x3_2
I0422 02:57:43.937088 21412 net.cpp:100] Creating Layer rpn_conv/3x3_2
I0422 02:57:43.937094 21412 net.cpp:434] rpn_conv/3x3_2 <- rpn/output
I0422 02:57:43.937101 21412 net.cpp:408] rpn_conv/3x3_2 -> rpn/output_2
I0422 02:57:44.127483 21412 net.cpp:150] Setting up rpn_conv/3x3_2
I0422 02:57:44.127509 21412 net.cpp:157] Top shape: 1 512 96 2 2 (196608)
I0422 02:57:44.127514 21412 net.cpp:165] Memory required for data: 10170729660
I0422 02:57:44.127523 21412 layer_factory.hpp:77] Creating layer rpn_relu/3x3_2
I0422 02:57:44.127534 21412 net.cpp:100] Creating Layer rpn_relu/3x3_2
I0422 02:57:44.127545 21412 net.cpp:434] rpn_relu/3x3_2 <- rpn/output_2
I0422 02:57:44.127552 21412 net.cpp:395] rpn_relu/3x3_2 -> rpn/output_2 (in-place)
I0422 02:57:44.129006 21412 net.cpp:150] Setting up rpn_relu/3x3_2
I0422 02:57:44.129019 21412 net.cpp:157] Top shape: 1 512 96 2 2 (196608)
I0422 02:57:44.129024 21412 net.cpp:165] Memory required for data: 10171516092
I0422 02:57:44.129027 21412 layer_factory.hpp:77] Creating layer rpn/output_pool
I0422 02:57:44.129040 21412 net.cpp:100] Creating Layer rpn/output_pool
I0422 02:57:44.129046 21412 net.cpp:434] rpn/output_pool <- rpn/output_2
I0422 02:57:44.129051 21412 net.cpp:408] rpn/output_pool -> rpn/output_pool
I0422 02:57:44.130632 21412 net.cpp:150] Setting up rpn/output_pool
I0422 02:57:44.130643 21412 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 02:57:44.130646 21412 net.cpp:165] Memory required for data: 10171712700
I0422 02:57:44.130650 21412 layer_factory.hpp:77] Creating layer rpn/output_pool_rpn/output_pool_0_split
I0422 02:57:44.130657 21412 net.cpp:100] Creating Layer rpn/output_pool_rpn/output_pool_0_split
I0422 02:57:44.130664 21412 net.cpp:434] rpn/output_pool_rpn/output_pool_0_split <- rpn/output_pool
I0422 02:57:44.130669 21412 net.cpp:408] rpn/output_pool_rpn/output_pool_0_split -> rpn/output_pool_rpn/output_pool_0_split_0
I0422 02:57:44.130676 21412 net.cpp:408] rpn/output_pool_rpn/output_pool_0_split -> rpn/output_pool_rpn/output_pool_0_split_1
I0422 02:57:44.130710 21412 net.cpp:150] Setting up rpn/output_pool_rpn/output_pool_0_split
I0422 02:57:44.130717 21412 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 02:57:44.130722 21412 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 02:57:44.130726 21412 net.cpp:165] Memory required for data: 10172105916
I0422 02:57:44.130730 21412 layer_factory.hpp:77] Creating layer rpn_cls_score
I0422 02:57:44.130741 21412 net.cpp:100] Creating Layer rpn_cls_score
I0422 02:57:44.130746 21412 net.cpp:434] rpn_cls_score <- rpn/output_pool_rpn/output_pool_0_split_0
I0422 02:57:44.130753 21412 net.cpp:408] rpn_cls_score -> rpn_cls_score
I0422 02:57:44.135885 21412 net.cpp:150] Setting up rpn_cls_score
I0422 02:57:44.135900 21412 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:57:44.135905 21412 net.cpp:165] Memory required for data: 10172134332
I0422 02:57:44.135911 21412 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0422 02:57:44.135918 21412 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0422 02:57:44.135922 21412 net.cpp:434] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0422 02:57:44.135929 21412 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0422 02:57:44.135939 21412 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0422 02:57:44.135982 21412 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0422 02:57:44.135988 21412 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:57:44.135993 21412 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:57:44.135996 21412 net.cpp:165] Memory required for data: 10172191164
I0422 02:57:44.136000 21412 layer_factory.hpp:77] Creating layer rpn_twin_pred
I0422 02:57:44.136014 21412 net.cpp:100] Creating Layer rpn_twin_pred
I0422 02:57:44.136020 21412 net.cpp:434] rpn_twin_pred <- rpn/output_pool_rpn/output_pool_0_split_1
I0422 02:57:44.136029 21412 net.cpp:408] rpn_twin_pred -> rpn_twin_pred
I0422 02:57:44.143416 21412 net.cpp:150] Setting up rpn_twin_pred
I0422 02:57:44.143431 21412 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:57:44.143436 21412 net.cpp:165] Memory required for data: 10172219580
I0422 02:57:44.143445 21412 layer_factory.hpp:77] Creating layer rpn_twin_pred_rpn_twin_pred_0_split
I0422 02:57:44.143451 21412 net.cpp:100] Creating Layer rpn_twin_pred_rpn_twin_pred_0_split
I0422 02:57:44.143456 21412 net.cpp:434] rpn_twin_pred_rpn_twin_pred_0_split <- rpn_twin_pred
I0422 02:57:44.143462 21412 net.cpp:408] rpn_twin_pred_rpn_twin_pred_0_split -> rpn_twin_pred_rpn_twin_pred_0_split_0
I0422 02:57:44.143470 21412 net.cpp:408] rpn_twin_pred_rpn_twin_pred_0_split -> rpn_twin_pred_rpn_twin_pred_0_split_1
I0422 02:57:44.143512 21412 net.cpp:150] Setting up rpn_twin_pred_rpn_twin_pred_0_split
I0422 02:57:44.143520 21412 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:57:44.143527 21412 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:57:44.143529 21412 net.cpp:165] Memory required for data: 10172276412
I0422 02:57:44.143533 21412 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0422 02:57:44.143549 21412 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0422 02:57:44.143555 21412 net.cpp:434] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0422 02:57:44.143561 21412 net.cpp:408] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0422 02:57:44.143590 21412 net.cpp:150] Setting up rpn_cls_score_reshape
I0422 02:57:44.143597 21412 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 02:57:44.143602 21412 net.cpp:165] Memory required for data: 10172304828
I0422 02:57:44.143607 21412 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 02:57:44.143612 21412 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 02:57:44.143617 21412 net.cpp:434] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0422 02:57:44.143625 21412 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0422 02:57:44.143635 21412 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0422 02:57:44.143640 21412 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_2
I0422 02:57:44.143682 21412 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 02:57:44.143690 21412 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 02:57:44.143695 21412 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 02:57:44.143699 21412 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 02:57:44.143703 21412 net.cpp:165] Memory required for data: 10172390076
I0422 02:57:44.143708 21412 layer_factory.hpp:77] Creating layer rpn-data
I0422 02:57:44.144119 21412 net.cpp:100] Creating Layer rpn-data
I0422 02:57:44.144131 21412 net.cpp:434] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0422 02:57:44.144137 21412 net.cpp:434] rpn-data <- gt_boxes_data_1_split_0
I0422 02:57:44.144143 21412 net.cpp:434] rpn-data <- data_data_0_split_1
I0422 02:57:44.144148 21412 net.cpp:408] rpn-data -> rpn_labels
I0422 02:57:44.144158 21412 net.cpp:408] rpn-data -> rpn_twin_targets
I0422 02:57:44.144165 21412 net.cpp:408] rpn-data -> rpn_twin_inside_weights
I0422 02:57:44.144172 21412 net.cpp:408] rpn-data -> rpn_twin_outside_weights
I0422 02:57:44.146440 21412 net.cpp:150] Setting up rpn-data
I0422 02:57:44.146456 21412 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 02:57:44.146461 21412 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:57:44.146466 21412 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:57:44.146469 21412 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:57:44.146472 21412 net.cpp:165] Memory required for data: 10172489532
I0422 02:57:44.146477 21412 layer_factory.hpp:77] Creating layer rpn_labels_rpn-data_0_split
I0422 02:57:44.146483 21412 net.cpp:100] Creating Layer rpn_labels_rpn-data_0_split
I0422 02:57:44.146492 21412 net.cpp:434] rpn_labels_rpn-data_0_split <- rpn_labels
I0422 02:57:44.146498 21412 net.cpp:408] rpn_labels_rpn-data_0_split -> rpn_labels_rpn-data_0_split_0
I0422 02:57:44.146507 21412 net.cpp:408] rpn_labels_rpn-data_0_split -> rpn_labels_rpn-data_0_split_1
I0422 02:57:44.146540 21412 net.cpp:150] Setting up rpn_labels_rpn-data_0_split
I0422 02:57:44.146548 21412 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 02:57:44.146553 21412 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 02:57:44.146556 21412 net.cpp:165] Memory required for data: 10172517948
I0422 02:57:44.146560 21412 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0422 02:57:44.146569 21412 net.cpp:100] Creating Layer rpn_loss_cls
I0422 02:57:44.146574 21412 net.cpp:434] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0422 02:57:44.146580 21412 net.cpp:434] rpn_loss_cls <- rpn_labels_rpn-data_0_split_0
I0422 02:57:44.146585 21412 net.cpp:408] rpn_loss_cls -> rpn_cls_loss
I0422 02:57:44.146598 21412 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0422 02:57:44.147193 21412 net.cpp:150] Setting up rpn_loss_cls
I0422 02:57:44.147207 21412 net.cpp:157] Top shape: (1)
I0422 02:57:44.147212 21412 net.cpp:160]     with loss weight 1
I0422 02:57:44.147225 21412 net.cpp:165] Memory required for data: 10172517952
I0422 02:57:44.147229 21412 layer_factory.hpp:77] Creating layer rpn_loss_twin
I0422 02:57:44.147238 21412 net.cpp:100] Creating Layer rpn_loss_twin
I0422 02:57:44.147244 21412 net.cpp:434] rpn_loss_twin <- rpn_twin_pred_rpn_twin_pred_0_split_0
I0422 02:57:44.147250 21412 net.cpp:434] rpn_loss_twin <- rpn_twin_targets
I0422 02:57:44.147255 21412 net.cpp:434] rpn_loss_twin <- rpn_twin_inside_weights
I0422 02:57:44.147260 21412 net.cpp:434] rpn_loss_twin <- rpn_twin_outside_weights
I0422 02:57:44.147265 21412 net.cpp:408] rpn_loss_twin -> rpn_loss_twin
I0422 02:57:44.147353 21412 net.cpp:150] Setting up rpn_loss_twin
I0422 02:57:44.147361 21412 net.cpp:157] Top shape: (1)
I0422 02:57:44.147367 21412 net.cpp:160]     with loss weight 1
I0422 02:57:44.147372 21412 net.cpp:165] Memory required for data: 10172517956
I0422 02:57:44.147375 21412 layer_factory.hpp:77] Creating layer rpn_accuarcy
I0422 02:57:44.147387 21412 net.cpp:100] Creating Layer rpn_accuarcy
I0422 02:57:44.147392 21412 net.cpp:434] rpn_accuarcy <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0422 02:57:44.147398 21412 net.cpp:434] rpn_accuarcy <- rpn_labels_rpn-data_0_split_1
I0422 02:57:44.147404 21412 net.cpp:408] rpn_accuarcy -> rpn_accuarcy
I0422 02:57:44.147413 21412 net.cpp:408] rpn_accuarcy -> rpn_accuarcy_class
I0422 02:57:44.147450 21412 net.cpp:150] Setting up rpn_accuarcy
I0422 02:57:44.147459 21412 net.cpp:157] Top shape: (1)
I0422 02:57:44.147464 21412 net.cpp:157] Top shape: 2 (2)
I0422 02:57:44.147467 21412 net.cpp:165] Memory required for data: 10172517968
I0422 02:57:44.147471 21412 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0422 02:57:44.147478 21412 net.cpp:100] Creating Layer rpn_cls_prob
I0422 02:57:44.147483 21412 net.cpp:434] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_2
I0422 02:57:44.147488 21412 net.cpp:408] rpn_cls_prob -> rpn_cls_prob
I0422 02:57:44.148905 21412 net.cpp:150] Setting up rpn_cls_prob
I0422 02:57:44.148917 21412 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 02:57:44.148923 21412 net.cpp:165] Memory required for data: 10172546384
I0422 02:57:44.148927 21412 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0422 02:57:44.148936 21412 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0422 02:57:44.148941 21412 net.cpp:434] rpn_cls_prob_reshape <- rpn_cls_prob
I0422 02:57:44.148946 21412 net.cpp:408] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0422 02:57:44.148975 21412 net.cpp:150] Setting up rpn_cls_prob_reshape
I0422 02:57:44.148983 21412 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:57:44.148988 21412 net.cpp:165] Memory required for data: 10172574800
I0422 02:57:44.148993 21412 layer_factory.hpp:77] Creating layer proposal
I0422 02:57:44.173526 21412 net.cpp:100] Creating Layer proposal
I0422 02:57:44.173545 21412 net.cpp:434] proposal <- rpn_cls_prob_reshape
I0422 02:57:44.173553 21412 net.cpp:434] proposal <- rpn_twin_pred_rpn_twin_pred_0_split_1
I0422 02:57:44.173560 21412 net.cpp:408] proposal -> rpn_rois
I0422 02:57:44.178251 21412 net.cpp:150] Setting up proposal
I0422 02:57:44.178266 21412 net.cpp:157] Top shape: 1 3 (3)
I0422 02:57:44.178269 21412 net.cpp:165] Memory required for data: 10172574812
I0422 02:57:44.178274 21412 layer_factory.hpp:77] Creating layer roi-data
I0422 02:57:44.178407 21412 net.cpp:100] Creating Layer roi-data
I0422 02:57:44.178419 21412 net.cpp:434] roi-data <- rpn_rois
I0422 02:57:44.178426 21412 net.cpp:434] roi-data <- gt_boxes_data_1_split_1
I0422 02:57:44.178431 21412 net.cpp:408] roi-data -> rois
I0422 02:57:44.178438 21412 net.cpp:408] roi-data -> labels
I0422 02:57:44.178447 21412 net.cpp:408] roi-data -> twin_targets
I0422 02:57:44.178452 21412 net.cpp:408] roi-data -> twin_inside_weights
I0422 02:57:44.178462 21412 net.cpp:408] roi-data -> twin_outside_weights
('sampling method:', 'Random')
I0422 02:57:44.178807 21412 net.cpp:150] Setting up roi-data
I0422 02:57:44.178822 21412 net.cpp:157] Top shape: 1 3 (3)
I0422 02:57:44.178827 21412 net.cpp:157] Top shape: 1 200 (200)
I0422 02:57:44.178830 21412 net.cpp:157] Top shape: 1 400 (400)
I0422 02:57:44.178834 21412 net.cpp:157] Top shape: 1 400 (400)
I0422 02:57:44.178838 21412 net.cpp:157] Top shape: 1 400 (400)
I0422 02:57:44.178841 21412 net.cpp:165] Memory required for data: 10172580424
I0422 02:57:44.178845 21412 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0422 02:57:44.178851 21412 net.cpp:100] Creating Layer labels_roi-data_1_split
I0422 02:57:44.178859 21412 net.cpp:434] labels_roi-data_1_split <- labels
I0422 02:57:44.178864 21412 net.cpp:408] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0422 02:57:44.178872 21412 net.cpp:408] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0422 02:57:44.178905 21412 net.cpp:150] Setting up labels_roi-data_1_split
I0422 02:57:44.178911 21412 net.cpp:157] Top shape: 1 200 (200)
I0422 02:57:44.178915 21412 net.cpp:157] Top shape: 1 200 (200)
I0422 02:57:44.178920 21412 net.cpp:165] Memory required for data: 10172582024
I0422 02:57:44.178923 21412 layer_factory.hpp:77] Creating layer roi_pool5
I0422 02:57:44.178932 21412 net.cpp:100] Creating Layer roi_pool5
I0422 02:57:44.178938 21412 net.cpp:434] roi_pool5 <- conv5b_relu5b_0_split_1
I0422 02:57:44.178944 21412 net.cpp:434] roi_pool5 <- rois
I0422 02:57:44.178949 21412 net.cpp:408] roi_pool5 -> pool5
I0422 02:57:44.178958 21412 roi_pooling_layer.cpp:34] Temporal scale: 0.125
I0422 02:57:44.178966 21412 roi_pooling_layer.cpp:35] Spatial scale: 0.0625
I0422 02:57:44.179002 21412 net.cpp:150] Setting up roi_pool5
I0422 02:57:44.179009 21412 net.cpp:157] Top shape: 1 512 1 4 4 (8192)
I0422 02:57:44.179013 21412 net.cpp:165] Memory required for data: 10172614792
I0422 02:57:44.179016 21412 layer_factory.hpp:77] Creating layer fc6
I0422 02:57:44.179025 21412 net.cpp:100] Creating Layer fc6
I0422 02:57:44.179033 21412 net.cpp:434] fc6 <- pool5
I0422 02:57:44.179039 21412 net.cpp:408] fc6 -> fc6
I0422 02:57:45.064024 21412 net.cpp:150] Setting up fc6
I0422 02:57:45.064050 21412 net.cpp:157] Top shape: 1 4096 (4096)
I0422 02:57:45.064055 21412 net.cpp:165] Memory required for data: 10172631176
I0422 02:57:45.064066 21412 layer_factory.hpp:77] Creating layer relu6
I0422 02:57:45.064079 21412 net.cpp:100] Creating Layer relu6
I0422 02:57:45.064091 21412 net.cpp:434] relu6 <- fc6
I0422 02:57:45.064100 21412 net.cpp:395] relu6 -> fc6 (in-place)
I0422 02:57:45.064712 21412 net.cpp:150] Setting up relu6
I0422 02:57:45.064726 21412 net.cpp:157] Top shape: 1 4096 (4096)
I0422 02:57:45.064730 21412 net.cpp:165] Memory required for data: 10172647560
I0422 02:57:45.064734 21412 layer_factory.hpp:77] Creating layer drop6
I0422 02:57:45.064749 21412 net.cpp:100] Creating Layer drop6
I0422 02:57:45.064755 21412 net.cpp:434] drop6 <- fc6
I0422 02:57:45.064760 21412 net.cpp:395] drop6 -> fc6 (in-place)
I0422 02:57:45.064790 21412 net.cpp:150] Setting up drop6
I0422 02:57:45.064798 21412 net.cpp:157] Top shape: 1 4096 (4096)
I0422 02:57:45.064803 21412 net.cpp:165] Memory required for data: 10172663944
I0422 02:57:45.064808 21412 layer_factory.hpp:77] Creating layer fc6_drop6_0_split
I0422 02:57:45.064815 21412 net.cpp:100] Creating Layer fc6_drop6_0_split
I0422 02:57:45.064818 21412 net.cpp:434] fc6_drop6_0_split <- fc6
I0422 02:57:45.064823 21412 net.cpp:408] fc6_drop6_0_split -> fc6_drop6_0_split_0
I0422 02:57:45.064834 21412 net.cpp:408] fc6_drop6_0_split -> fc6_drop6_0_split_1
I0422 02:57:45.064867 21412 net.cpp:150] Setting up fc6_drop6_0_split
I0422 02:57:45.064874 21412 net.cpp:157] Top shape: 1 4096 (4096)
I0422 02:57:45.064878 21412 net.cpp:157] Top shape: 1 4096 (4096)
I0422 02:57:45.064882 21412 net.cpp:165] Memory required for data: 10172696712
I0422 02:57:45.064887 21412 layer_factory.hpp:77] Creating layer cls_score
I0422 02:57:45.064893 21412 net.cpp:100] Creating Layer cls_score
I0422 02:57:45.064899 21412 net.cpp:434] cls_score <- fc6_drop6_0_split_0
I0422 02:57:45.064908 21412 net.cpp:408] cls_score -> cls_score
I0422 02:57:45.086545 21412 net.cpp:150] Setting up cls_score
I0422 02:57:45.086565 21412 net.cpp:157] Top shape: 1 200 (200)
I0422 02:57:45.086570 21412 net.cpp:165] Memory required for data: 10172697512
I0422 02:57:45.086580 21412 layer_factory.hpp:77] Creating layer cls_score_cls_score_0_split
I0422 02:57:45.086586 21412 net.cpp:100] Creating Layer cls_score_cls_score_0_split
I0422 02:57:45.086597 21412 net.cpp:434] cls_score_cls_score_0_split <- cls_score
I0422 02:57:45.086603 21412 net.cpp:408] cls_score_cls_score_0_split -> cls_score_cls_score_0_split_0
I0422 02:57:45.086611 21412 net.cpp:408] cls_score_cls_score_0_split -> cls_score_cls_score_0_split_1
I0422 02:57:45.086647 21412 net.cpp:150] Setting up cls_score_cls_score_0_split
I0422 02:57:45.086653 21412 net.cpp:157] Top shape: 1 200 (200)
I0422 02:57:45.086658 21412 net.cpp:157] Top shape: 1 200 (200)
I0422 02:57:45.086661 21412 net.cpp:165] Memory required for data: 10172699112
I0422 02:57:45.086665 21412 layer_factory.hpp:77] Creating layer twin_pred
I0422 02:57:45.086673 21412 net.cpp:100] Creating Layer twin_pred
I0422 02:57:45.086678 21412 net.cpp:434] twin_pred <- fc6_drop6_0_split_1
I0422 02:57:45.086685 21412 net.cpp:408] twin_pred -> twin_pred
I0422 02:57:45.130126 21412 net.cpp:150] Setting up twin_pred
I0422 02:57:45.130153 21412 net.cpp:157] Top shape: 1 400 (400)
I0422 02:57:45.130157 21412 net.cpp:165] Memory required for data: 10172700712
I0422 02:57:45.130167 21412 layer_factory.hpp:77] Creating layer loss_cls
I0422 02:57:45.130182 21412 net.cpp:100] Creating Layer loss_cls
I0422 02:57:45.130188 21412 net.cpp:434] loss_cls <- cls_score_cls_score_0_split_0
I0422 02:57:45.130195 21412 net.cpp:434] loss_cls <- labels_roi-data_1_split_0
I0422 02:57:45.130201 21412 net.cpp:408] loss_cls -> loss_cls
I0422 02:57:45.130262 21412 net.cpp:150] Setting up loss_cls
I0422 02:57:45.130270 21412 net.cpp:157] Top shape: (1)
I0422 02:57:45.130275 21412 net.cpp:160]     with loss weight 1
I0422 02:57:45.130282 21412 net.cpp:165] Memory required for data: 10172700716
I0422 02:57:45.130287 21412 layer_factory.hpp:77] Creating layer loss_twin
I0422 02:57:45.130295 21412 net.cpp:100] Creating Layer loss_twin
I0422 02:57:45.130300 21412 net.cpp:434] loss_twin <- twin_pred
I0422 02:57:45.130306 21412 net.cpp:434] loss_twin <- twin_targets
I0422 02:57:45.130311 21412 net.cpp:434] loss_twin <- twin_inside_weights
I0422 02:57:45.130316 21412 net.cpp:434] loss_twin <- twin_outside_weights
I0422 02:57:45.130321 21412 net.cpp:408] loss_twin -> loss_twin
I0422 02:57:45.130400 21412 net.cpp:150] Setting up loss_twin
I0422 02:57:45.130409 21412 net.cpp:157] Top shape: (1)
I0422 02:57:45.130414 21412 net.cpp:160]     with loss weight 1
I0422 02:57:45.130419 21412 net.cpp:165] Memory required for data: 10172700720
I0422 02:57:45.130421 21412 layer_factory.hpp:77] Creating layer accuracy
I0422 02:57:45.130617 21412 net.cpp:100] Creating Layer accuracy
I0422 02:57:45.130630 21412 net.cpp:434] accuracy <- cls_score_cls_score_0_split_1
I0422 02:57:45.130635 21412 net.cpp:434] accuracy <- labels_roi-data_1_split_1
I0422 02:57:45.130641 21412 net.cpp:408] accuracy -> accuracy
I0422 02:57:45.130722 21412 net.cpp:150] Setting up accuracy
I0422 02:57:45.130733 21412 net.cpp:157] Top shape: 1 (1)
I0422 02:57:45.130738 21412 net.cpp:165] Memory required for data: 10172700724
I0422 02:57:45.130743 21412 net.cpp:228] accuracy does not need backward computation.
I0422 02:57:45.130748 21412 net.cpp:226] loss_twin needs backward computation.
I0422 02:57:45.130751 21412 net.cpp:226] loss_cls needs backward computation.
I0422 02:57:45.130756 21412 net.cpp:226] twin_pred needs backward computation.
I0422 02:57:45.130784 21412 net.cpp:226] cls_score_cls_score_0_split needs backward computation.
I0422 02:57:45.130792 21412 net.cpp:226] cls_score needs backward computation.
I0422 02:57:45.130796 21412 net.cpp:226] fc6_drop6_0_split needs backward computation.
I0422 02:57:45.130801 21412 net.cpp:226] drop6 needs backward computation.
I0422 02:57:45.130805 21412 net.cpp:226] relu6 needs backward computation.
I0422 02:57:45.130810 21412 net.cpp:226] fc6 needs backward computation.
I0422 02:57:45.130813 21412 net.cpp:226] roi_pool5 needs backward computation.
I0422 02:57:45.130820 21412 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0422 02:57:45.130827 21412 net.cpp:226] roi-data needs backward computation.
I0422 02:57:45.130831 21412 net.cpp:226] proposal needs backward computation.
I0422 02:57:45.130836 21412 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0422 02:57:45.130841 21412 net.cpp:226] rpn_cls_prob needs backward computation.
I0422 02:57:45.130846 21412 net.cpp:228] rpn_accuarcy does not need backward computation.
I0422 02:57:45.130852 21412 net.cpp:226] rpn_loss_twin needs backward computation.
I0422 02:57:45.130857 21412 net.cpp:226] rpn_loss_cls needs backward computation.
I0422 02:57:45.130863 21412 net.cpp:228] rpn_labels_rpn-data_0_split does not need backward computation.
I0422 02:57:45.130870 21412 net.cpp:226] rpn-data needs backward computation.
I0422 02:57:45.130877 21412 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0422 02:57:45.130882 21412 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0422 02:57:45.130887 21412 net.cpp:226] rpn_twin_pred_rpn_twin_pred_0_split needs backward computation.
I0422 02:57:45.130894 21412 net.cpp:226] rpn_twin_pred needs backward computation.
I0422 02:57:45.130899 21412 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0422 02:57:45.130906 21412 net.cpp:226] rpn_cls_score needs backward computation.
I0422 02:57:45.130910 21412 net.cpp:226] rpn/output_pool_rpn/output_pool_0_split needs backward computation.
I0422 02:57:45.130918 21412 net.cpp:226] rpn/output_pool needs backward computation.
I0422 02:57:45.130923 21412 net.cpp:226] rpn_relu/3x3_2 needs backward computation.
I0422 02:57:45.130928 21412 net.cpp:226] rpn_conv/3x3_2 needs backward computation.
I0422 02:57:45.130934 21412 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0422 02:57:45.130939 21412 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0422 02:57:45.130942 21412 net.cpp:226] conv5b_relu5b_0_split needs backward computation.
I0422 02:57:45.130949 21412 net.cpp:226] relu5b needs backward computation.
I0422 02:57:45.130952 21412 net.cpp:226] conv5b needs backward computation.
I0422 02:57:45.130959 21412 net.cpp:226] relu5a needs backward computation.
I0422 02:57:45.130964 21412 net.cpp:226] conv5a needs backward computation.
I0422 02:57:45.130970 21412 net.cpp:226] pool4 needs backward computation.
I0422 02:57:45.130973 21412 net.cpp:226] relu4b needs backward computation.
I0422 02:57:45.130978 21412 net.cpp:226] conv4b needs backward computation.
I0422 02:57:45.130982 21412 net.cpp:226] relu4a needs backward computation.
I0422 02:57:45.130986 21412 net.cpp:226] conv4a needs backward computation.
I0422 02:57:45.130992 21412 net.cpp:226] pool3 needs backward computation.
I0422 02:57:45.130997 21412 net.cpp:226] relu3b needs backward computation.
I0422 02:57:45.131002 21412 net.cpp:226] conv3b needs backward computation.
I0422 02:57:45.131006 21412 net.cpp:226] relu3a needs backward computation.
I0422 02:57:45.131011 21412 net.cpp:226] conv3a needs backward computation.
I0422 02:57:45.131014 21412 net.cpp:228] pool2 does not need backward computation.
I0422 02:57:45.131019 21412 net.cpp:228] relu2a does not need backward computation.
I0422 02:57:45.131026 21412 net.cpp:228] conv2a does not need backward computation.
I0422 02:57:45.131031 21412 net.cpp:228] pool1 does not need backward computation.
I0422 02:57:45.131036 21412 net.cpp:228] relu1a does not need backward computation.
I0422 02:57:45.131039 21412 net.cpp:228] conv1a does not need backward computation.
I0422 02:57:45.131045 21412 net.cpp:228] gt_boxes_data_1_split does not need backward computation.
I0422 02:57:45.131050 21412 net.cpp:228] data_data_0_split does not need backward computation.
I0422 02:57:45.131058 21412 net.cpp:228] data does not need backward computation.
I0422 02:57:45.131062 21412 net.cpp:270] This network produces output accuracy
I0422 02:57:45.131067 21412 net.cpp:270] This network produces output loss_cls
I0422 02:57:45.131070 21412 net.cpp:270] This network produces output loss_twin
I0422 02:57:45.131078 21412 net.cpp:270] This network produces output rpn_accuarcy
I0422 02:57:45.131081 21412 net.cpp:270] This network produces output rpn_accuarcy_class
I0422 02:57:45.131088 21412 net.cpp:270] This network produces output rpn_cls_loss
I0422 02:57:45.131091 21412 net.cpp:270] This network produces output rpn_loss_twin
I0422 02:57:45.131127 21412 net.cpp:283] Network initialization done.
I0422 02:57:45.131264 21412 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from ./pretrain/activitynet_iter_30000_3fps.caffemodel
I0422 02:57:46.154222 21412 net.cpp:761] Ignoring source layer pool5
I0422 02:57:46.174216 21412 net.cpp:761] Ignoring source layer fc7
I0422 02:57:46.174242 21412 net.cpp:761] Ignoring source layer relu7
I0422 02:57:46.174245 21412 net.cpp:761] Ignoring source layer drop7
I0422 02:57:46.174249 21412 net.cpp:761] Ignoring source layer fc8-200
I0422 02:57:46.174254 21412 net.cpp:761] Ignoring source layer loss
Solving...
F0422 02:57:46.997335 21412 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***

real	0m7.823s
user	0m4.505s
sys	0m3.963s
Called with args:
Namespace(cfg_file='./experiments/activitynet/td_cnn_end2end.yml', gpu_id=0, max_iters=350000, pretrained_model='./pretrain/activitynet_iter_30000_3fps.caffemodel', randomize=False, set_cfgs=None, solver='./experiments/activitynet/solver.prototxt')
Using config:
{'DEDUP_BOXES': 0.125,
 'EPS': 1e-14,
 'FPS': 25,
 'GPU_ID': 0,
 'INPUT': 'video',
 'NUM_CLASSES': 201,
 'PIXEL_MEANS': array([[[ 90,  98, 102]]]),
 'PIXEL_MEANS_FLOW': array([128]),
 'RNG_SEED': 3,
 'TEST': {'CROP_SIZE': 112,
          'FRAME_SIZE': [128, 171],
          'HAS_RPN': True,
          'LENGTH': [768],
          'MAX_SIZE': 1000,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.9,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SVM': False,
          'TWIN_REG': True},
 'TRAIN': {'BATCH_SIZE': 128,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.1,
           'CINPUT': False,
           'CROP_SIZE': 112,
           'FG_FRACTION': 0.5,
           'FG_THRESH': 0.5,
           'FRAME_SIZE': [128, 171],
           'HAS_RPN': True,
           'LENGTH': [768],
           'OHEM_LOSS_ONLY_CLASSIFICATION': False,
           'OHEM_LOSS_ONLY_LOCALIZATION': False,
           'OHEM_NMS_THRESH': 0.7,
           'OHEM_USE_NMS': True,
           'PROPOSAL_METHOD': 'gt',
           'RANDOM': False,
           'RPN_BATCHSIZE': 64,
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.8,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'RPN_TWIN_INSIDE_WEIGHTS': [1.0, 1.0],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 1000,
           'TWIN_INSIDE_WEIGHTS': [1.0, 1.0],
           'TWIN_NORMALIZE_MEANS': [0.0, 0.0],
           'TWIN_NORMALIZE_STDS': [0.1, 0.2],
           'TWIN_NORMALIZE_TARGETS': False,
           'TWIN_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'TWIN_REG': True,
           'TWIN_THRESH': 0.5,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False,
           'VIDEO_BATCH': 1},
 'USE_GPU_NMS': True}
18388 roidb entries
Output will be saved to `./experiments/best_activitynet/snapshot/`
Computing bounding-box regression targets...
precimputed
twin target means:
twin target stdevs:
NOT normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0422 02:58:22.039034 23865 solver.cpp:48] Initializing solver from parameters: 
train_net: "./experiments/activitynet/train.prototxt"
base_lr: 0.0001
display: 1
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 350000
snapshot: 0
snapshot_prefix: "./experiments/activitynet/snapshot/activitynet"
average_loss: 100
iter_size: 1
I0422 02:58:22.039090 23865 solver.cpp:81] Creating training net from train_net file: ./experiments/activitynet/train.prototxt
I0422 02:58:22.040241 23865 net.cpp:58] Initializing net from parameters: 
name: "activitynet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 200"
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    kernel_size: 2
    kernel_size: 2
    stride: 1
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv2a"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv3a"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "conv3b"
  type: "Convolution"
  bottom: "conv3a"
  top: "conv3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3b"
  type: "ReLU"
  bottom: "conv3b"
  top: "conv3b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv4a"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "conv4b"
  type: "Convolution"
  bottom: "conv4a"
  top: "conv4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4b"
  type: "ReLU"
  bottom: "conv4b"
  top: "conv4b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv5a"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "conv5b"
  type: "Convolution"
  bottom: "conv5a"
  top: "conv5b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5b"
  type: "ReLU"
  bottom: "conv5b"
  top: "conv5b"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5b"
  top: "rpn/output"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_conv/3x3_2"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn/output_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3_2"
  type: "ReLU"
  bottom: "rpn/output_2"
  top: "rpn/output_2"
}
layer {
  name: "rpn/output_pool"
  type: "Pooling"
  bottom: "rpn/output_2"
  top: "rpn/output_pool"
  pooling_param {
    pool: MAX
    kernel_size: 1
    kernel_size: 2
    kernel_size: 2
  }
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output_pool"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 74
    kernel_size: 1
    kernel_size: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_twin_pred"
  type: "Convolution"
  bottom: "rpn/output_pool"
  top: "rpn_twin_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 74
    kernel_size: 1
    kernel_size: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_twin_targets"
  top: "rpn_twin_inside_weights"
  top: "rpn_twin_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 8 \n\'scales\': !!python/tuple [1,1.25, 1.5,1.75, 2,2.5, 3,3.5, 4,4.5, 5,5.5, 6,7, 8,9,10,11,12,14,16,18,20,22,24,28,32,36,40,44,52,60,68,76,84,92,100]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_twin"
  type: "SmoothL1Loss"
  bottom: "rpn_twin_pred"
  bottom: "rpn_twin_targets"
  bottom: "rpn_twin_inside_weights"
  bottom: "rpn_twin_outside_weights"
  top: "rpn_loss_twin"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_accuarcy"
  type: "Accuracy"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_accuarcy"
  top: "rpn_accuarcy_class"
  propagate_down: false
  propagate_down: false
  accuracy_param {
    ignore_label: -1
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 74
      dim: -1
      dim: 0
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_twin_pred"
  top: "rpn_rois"
  include {
    phase: TRAIN
  }
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 8 \n\'scales\': !!python/tuple [1,1.25, 1.5,1.75, 2,2.5, 3,3.5, 4,4.5, 5,5.5, 6,7, 8,9,10,11,12,14,16,18,20,22,24,28,32,36,40,44,52,60,68,76,84,92,100]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  top: "rois"
  top: "labels"
  top: "twin_targets"
  top: "twin_inside_weights"
  top: "twin_outside_weights"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 200"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5b"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 4
    pooled_w: 4
    spatial_scale: 0.0625
    pooled_l: 1
    temporal_scale: 0.125
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc6"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 200
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "twin_pred"
  type: "InnerProduct"
  bottom: "fc6"
  top: "twin_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 400
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SigmoidCrossEntropyLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_twin"
  type: "SmoothL1Loss"
  bottom: "twin_pred"
  bottom: "twin_targets"
  bottom: "twin_inside_weights"
  bottom: "twin_outside_weights"
  top: "loss_twin"
  loss_weight: 1
}
layer {
  name: "accuracy"
  type: "Python"
  bottom: "cls_score"
  bottom: "labels"
  top: "accuracy"
  python_param {
    module: "utils.accuracy_layer"
    layer: "AccuracyLayer"
    param_str: "{\"top_k\": 2}"
  }
}
I0422 02:58:22.040511 23865 layer_factory.hpp:77] Creating layer data
I0422 02:58:22.070212 23865 net.cpp:100] Creating Layer data
I0422 02:58:22.070240 23865 net.cpp:408] data -> data
I0422 02:58:22.070258 23865 net.cpp:408] data -> gt_boxes
setting up
has rpn
RoiDataLayer: name_to_top: {'gt_windows': 1, 'data': 0}
I0422 02:58:22.132182 23865 net.cpp:150] Setting up data
I0422 02:58:22.132208 23865 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 02:58:22.132218 23865 net.cpp:157] Top shape: 1 101 (101)
I0422 02:58:22.132225 23865 net.cpp:165] Memory required for data: 115605908
I0422 02:58:22.132236 23865 layer_factory.hpp:77] Creating layer data_data_0_split
I0422 02:58:22.132253 23865 net.cpp:100] Creating Layer data_data_0_split
I0422 02:58:22.132263 23865 net.cpp:434] data_data_0_split <- data
I0422 02:58:22.132275 23865 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0422 02:58:22.132289 23865 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0422 02:58:22.132330 23865 net.cpp:150] Setting up data_data_0_split
I0422 02:58:22.132340 23865 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 02:58:22.132347 23865 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 02:58:22.132351 23865 net.cpp:165] Memory required for data: 346816916
I0422 02:58:22.132357 23865 layer_factory.hpp:77] Creating layer gt_boxes_data_1_split
I0422 02:58:22.132366 23865 net.cpp:100] Creating Layer gt_boxes_data_1_split
I0422 02:58:22.132374 23865 net.cpp:434] gt_boxes_data_1_split <- gt_boxes
I0422 02:58:22.132382 23865 net.cpp:408] gt_boxes_data_1_split -> gt_boxes_data_1_split_0
I0422 02:58:22.132393 23865 net.cpp:408] gt_boxes_data_1_split -> gt_boxes_data_1_split_1
I0422 02:58:22.132422 23865 net.cpp:150] Setting up gt_boxes_data_1_split
I0422 02:58:22.132431 23865 net.cpp:157] Top shape: 1 101 (101)
I0422 02:58:22.132438 23865 net.cpp:157] Top shape: 1 101 (101)
I0422 02:58:22.132445 23865 net.cpp:165] Memory required for data: 346817724
I0422 02:58:22.132452 23865 layer_factory.hpp:77] Creating layer conv1a
I0422 02:58:22.132473 23865 net.cpp:100] Creating Layer conv1a
I0422 02:58:22.132480 23865 net.cpp:434] conv1a <- data_data_0_split_0
I0422 02:58:22.132490 23865 net.cpp:408] conv1a -> conv1a
I0422 02:58:22.427331 23865 net.cpp:150] Setting up conv1a
I0422 02:58:22.427368 23865 net.cpp:157] Top shape: 1 64 768 112 112 (616562688)
I0422 02:58:22.427373 23865 net.cpp:165] Memory required for data: 2813068476
I0422 02:58:22.427393 23865 layer_factory.hpp:77] Creating layer relu1a
I0422 02:58:22.427409 23865 net.cpp:100] Creating Layer relu1a
I0422 02:58:22.427415 23865 net.cpp:434] relu1a <- conv1a
I0422 02:58:22.427422 23865 net.cpp:395] relu1a -> conv1a (in-place)
I0422 02:58:22.427902 23865 net.cpp:150] Setting up relu1a
I0422 02:58:22.427917 23865 net.cpp:157] Top shape: 1 64 768 112 112 (616562688)
I0422 02:58:22.427920 23865 net.cpp:165] Memory required for data: 5279319228
I0422 02:58:22.427925 23865 layer_factory.hpp:77] Creating layer pool1
I0422 02:58:22.427934 23865 net.cpp:100] Creating Layer pool1
I0422 02:58:22.427939 23865 net.cpp:434] pool1 <- conv1a
I0422 02:58:22.427945 23865 net.cpp:408] pool1 -> pool1
I0422 02:58:22.428117 23865 net.cpp:150] Setting up pool1
I0422 02:58:22.428128 23865 net.cpp:157] Top shape: 1 64 768 56 56 (154140672)
I0422 02:58:22.428133 23865 net.cpp:165] Memory required for data: 5895881916
I0422 02:58:22.428136 23865 layer_factory.hpp:77] Creating layer conv2a
I0422 02:58:22.428148 23865 net.cpp:100] Creating Layer conv2a
I0422 02:58:22.428153 23865 net.cpp:434] conv2a <- pool1
I0422 02:58:22.428159 23865 net.cpp:408] conv2a -> conv2a
I0422 02:58:22.439569 23865 net.cpp:150] Setting up conv2a
I0422 02:58:22.439597 23865 net.cpp:157] Top shape: 1 128 768 56 56 (308281344)
I0422 02:58:22.439602 23865 net.cpp:165] Memory required for data: 7129007292
I0422 02:58:22.439616 23865 layer_factory.hpp:77] Creating layer relu2a
I0422 02:58:22.439630 23865 net.cpp:100] Creating Layer relu2a
I0422 02:58:22.439635 23865 net.cpp:434] relu2a <- conv2a
I0422 02:58:22.439642 23865 net.cpp:395] relu2a -> conv2a (in-place)
I0422 02:58:22.440026 23865 net.cpp:150] Setting up relu2a
I0422 02:58:22.440043 23865 net.cpp:157] Top shape: 1 128 768 56 56 (308281344)
I0422 02:58:22.440048 23865 net.cpp:165] Memory required for data: 8362132668
I0422 02:58:22.440053 23865 layer_factory.hpp:77] Creating layer pool2
I0422 02:58:22.440069 23865 net.cpp:100] Creating Layer pool2
I0422 02:58:22.440074 23865 net.cpp:434] pool2 <- conv2a
I0422 02:58:22.440083 23865 net.cpp:408] pool2 -> pool2
I0422 02:58:22.440268 23865 net.cpp:150] Setting up pool2
I0422 02:58:22.440279 23865 net.cpp:157] Top shape: 1 128 384 28 28 (38535168)
I0422 02:58:22.440282 23865 net.cpp:165] Memory required for data: 8516273340
I0422 02:58:22.440287 23865 layer_factory.hpp:77] Creating layer conv3a
I0422 02:58:22.440299 23865 net.cpp:100] Creating Layer conv3a
I0422 02:58:22.440304 23865 net.cpp:434] conv3a <- pool2
I0422 02:58:22.440311 23865 net.cpp:408] conv3a -> conv3a
I0422 02:58:22.465812 23865 net.cpp:150] Setting up conv3a
I0422 02:58:22.465842 23865 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 02:58:22.465845 23865 net.cpp:165] Memory required for data: 8824554684
I0422 02:58:22.465858 23865 layer_factory.hpp:77] Creating layer relu3a
I0422 02:58:22.465870 23865 net.cpp:100] Creating Layer relu3a
I0422 02:58:22.465875 23865 net.cpp:434] relu3a <- conv3a
I0422 02:58:22.465885 23865 net.cpp:395] relu3a -> conv3a (in-place)
I0422 02:58:22.466223 23865 net.cpp:150] Setting up relu3a
I0422 02:58:22.466238 23865 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 02:58:22.466243 23865 net.cpp:165] Memory required for data: 9132836028
I0422 02:58:22.466246 23865 layer_factory.hpp:77] Creating layer conv3b
I0422 02:58:22.466259 23865 net.cpp:100] Creating Layer conv3b
I0422 02:58:22.466265 23865 net.cpp:434] conv3b <- conv3a
I0422 02:58:22.466271 23865 net.cpp:408] conv3b -> conv3b
I0422 02:58:22.516006 23865 net.cpp:150] Setting up conv3b
I0422 02:58:22.516031 23865 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 02:58:22.516036 23865 net.cpp:165] Memory required for data: 9441117372
I0422 02:58:22.516047 23865 layer_factory.hpp:77] Creating layer relu3b
I0422 02:58:22.516057 23865 net.cpp:100] Creating Layer relu3b
I0422 02:58:22.516062 23865 net.cpp:434] relu3b <- conv3b
I0422 02:58:22.516067 23865 net.cpp:395] relu3b -> conv3b (in-place)
I0422 02:58:22.516414 23865 net.cpp:150] Setting up relu3b
I0422 02:58:22.516427 23865 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 02:58:22.516432 23865 net.cpp:165] Memory required for data: 9749398716
I0422 02:58:22.516435 23865 layer_factory.hpp:77] Creating layer pool3
I0422 02:58:22.516444 23865 net.cpp:100] Creating Layer pool3
I0422 02:58:22.516449 23865 net.cpp:434] pool3 <- conv3b
I0422 02:58:22.516456 23865 net.cpp:408] pool3 -> pool3
I0422 02:58:22.516624 23865 net.cpp:150] Setting up pool3
I0422 02:58:22.516636 23865 net.cpp:157] Top shape: 1 256 192 14 14 (9633792)
I0422 02:58:22.516640 23865 net.cpp:165] Memory required for data: 9787933884
I0422 02:58:22.516644 23865 layer_factory.hpp:77] Creating layer conv4a
I0422 02:58:22.516655 23865 net.cpp:100] Creating Layer conv4a
I0422 02:58:22.516666 23865 net.cpp:434] conv4a <- pool3
I0422 02:58:22.516674 23865 net.cpp:408] conv4a -> conv4a
I0422 02:58:22.617892 23865 net.cpp:150] Setting up conv4a
I0422 02:58:22.617931 23865 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 02:58:22.617938 23865 net.cpp:165] Memory required for data: 9865004220
I0422 02:58:22.617956 23865 layer_factory.hpp:77] Creating layer relu4a
I0422 02:58:22.617971 23865 net.cpp:100] Creating Layer relu4a
I0422 02:58:22.617980 23865 net.cpp:434] relu4a <- conv4a
I0422 02:58:22.617990 23865 net.cpp:395] relu4a -> conv4a (in-place)
I0422 02:58:22.618489 23865 net.cpp:150] Setting up relu4a
I0422 02:58:22.618505 23865 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 02:58:22.618510 23865 net.cpp:165] Memory required for data: 9942074556
I0422 02:58:22.618520 23865 layer_factory.hpp:77] Creating layer conv4b
I0422 02:58:22.618541 23865 net.cpp:100] Creating Layer conv4b
I0422 02:58:22.618547 23865 net.cpp:434] conv4b <- conv4a
I0422 02:58:22.618557 23865 net.cpp:408] conv4b -> conv4b
I0422 02:58:22.872349 23865 net.cpp:150] Setting up conv4b
I0422 02:58:22.872385 23865 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 02:58:22.872392 23865 net.cpp:165] Memory required for data: 10019144892
I0422 02:58:22.872407 23865 layer_factory.hpp:77] Creating layer relu4b
I0422 02:58:22.872423 23865 net.cpp:100] Creating Layer relu4b
I0422 02:58:22.872440 23865 net.cpp:434] relu4b <- conv4b
I0422 02:58:22.872452 23865 net.cpp:395] relu4b -> conv4b (in-place)
I0422 02:58:22.872678 23865 net.cpp:150] Setting up relu4b
I0422 02:58:22.872694 23865 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 02:58:22.872700 23865 net.cpp:165] Memory required for data: 10096215228
I0422 02:58:22.872714 23865 layer_factory.hpp:77] Creating layer pool4
I0422 02:58:22.872725 23865 net.cpp:100] Creating Layer pool4
I0422 02:58:22.872733 23865 net.cpp:434] pool4 <- conv4b
I0422 02:58:22.872742 23865 net.cpp:408] pool4 -> pool4
I0422 02:58:22.873311 23865 net.cpp:150] Setting up pool4
I0422 02:58:22.873328 23865 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:58:22.873337 23865 net.cpp:165] Memory required for data: 10105849020
I0422 02:58:22.873342 23865 layer_factory.hpp:77] Creating layer conv5a
I0422 02:58:22.873363 23865 net.cpp:100] Creating Layer conv5a
I0422 02:58:22.873370 23865 net.cpp:434] conv5a <- pool4
I0422 02:58:22.873380 23865 net.cpp:408] conv5a -> conv5a
I0422 02:58:23.092664 23865 net.cpp:150] Setting up conv5a
I0422 02:58:23.092696 23865 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:58:23.092702 23865 net.cpp:165] Memory required for data: 10115482812
I0422 02:58:23.092716 23865 layer_factory.hpp:77] Creating layer relu5a
I0422 02:58:23.092737 23865 net.cpp:100] Creating Layer relu5a
I0422 02:58:23.092744 23865 net.cpp:434] relu5a <- conv5a
I0422 02:58:23.092758 23865 net.cpp:395] relu5a -> conv5a (in-place)
I0422 02:58:23.093297 23865 net.cpp:150] Setting up relu5a
I0422 02:58:23.093312 23865 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:58:23.093317 23865 net.cpp:165] Memory required for data: 10125116604
I0422 02:58:23.093328 23865 layer_factory.hpp:77] Creating layer conv5b
I0422 02:58:23.093346 23865 net.cpp:100] Creating Layer conv5b
I0422 02:58:23.093353 23865 net.cpp:434] conv5b <- conv5a
I0422 02:58:23.093365 23865 net.cpp:408] conv5b -> conv5b
I0422 02:58:23.309568 23865 net.cpp:150] Setting up conv5b
I0422 02:58:23.309645 23865 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:58:23.309662 23865 net.cpp:165] Memory required for data: 10134750396
I0422 02:58:23.309684 23865 layer_factory.hpp:77] Creating layer relu5b
I0422 02:58:23.309705 23865 net.cpp:100] Creating Layer relu5b
I0422 02:58:23.309727 23865 net.cpp:434] relu5b <- conv5b
I0422 02:58:23.309746 23865 net.cpp:395] relu5b -> conv5b (in-place)
I0422 02:58:23.309967 23865 net.cpp:150] Setting up relu5b
I0422 02:58:23.309993 23865 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:58:23.310008 23865 net.cpp:165] Memory required for data: 10144384188
I0422 02:58:23.310020 23865 layer_factory.hpp:77] Creating layer conv5b_relu5b_0_split
I0422 02:58:23.310036 23865 net.cpp:100] Creating Layer conv5b_relu5b_0_split
I0422 02:58:23.310050 23865 net.cpp:434] conv5b_relu5b_0_split <- conv5b
I0422 02:58:23.310066 23865 net.cpp:408] conv5b_relu5b_0_split -> conv5b_relu5b_0_split_0
I0422 02:58:23.310084 23865 net.cpp:408] conv5b_relu5b_0_split -> conv5b_relu5b_0_split_1
I0422 02:58:23.310148 23865 net.cpp:150] Setting up conv5b_relu5b_0_split
I0422 02:58:23.310169 23865 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:58:23.310184 23865 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 02:58:23.310197 23865 net.cpp:165] Memory required for data: 10163651772
I0422 02:58:23.310210 23865 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0422 02:58:23.310235 23865 net.cpp:100] Creating Layer rpn_conv/3x3
I0422 02:58:23.310250 23865 net.cpp:434] rpn_conv/3x3 <- conv5b_relu5b_0_split_0
I0422 02:58:23.310269 23865 net.cpp:408] rpn_conv/3x3 -> rpn/output
I0422 02:58:23.510455 23865 net.cpp:150] Setting up rpn_conv/3x3
I0422 02:58:23.510484 23865 net.cpp:157] Top shape: 1 512 96 4 4 (786432)
I0422 02:58:23.510490 23865 net.cpp:165] Memory required for data: 10166797500
I0422 02:58:23.510510 23865 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0422 02:58:23.510529 23865 net.cpp:100] Creating Layer rpn_relu/3x3
I0422 02:58:23.510538 23865 net.cpp:434] rpn_relu/3x3 <- rpn/output
I0422 02:58:23.510548 23865 net.cpp:395] rpn_relu/3x3 -> rpn/output (in-place)
I0422 02:58:23.510934 23865 net.cpp:150] Setting up rpn_relu/3x3
I0422 02:58:23.510949 23865 net.cpp:157] Top shape: 1 512 96 4 4 (786432)
I0422 02:58:23.510956 23865 net.cpp:165] Memory required for data: 10169943228
I0422 02:58:23.510962 23865 layer_factory.hpp:77] Creating layer rpn_conv/3x3_2
I0422 02:58:23.510980 23865 net.cpp:100] Creating Layer rpn_conv/3x3_2
I0422 02:58:23.510988 23865 net.cpp:434] rpn_conv/3x3_2 <- rpn/output
I0422 02:58:23.510998 23865 net.cpp:408] rpn_conv/3x3_2 -> rpn/output_2
I0422 02:58:23.730262 23865 net.cpp:150] Setting up rpn_conv/3x3_2
I0422 02:58:23.730290 23865 net.cpp:157] Top shape: 1 512 96 2 2 (196608)
I0422 02:58:23.730298 23865 net.cpp:165] Memory required for data: 10170729660
I0422 02:58:23.730310 23865 layer_factory.hpp:77] Creating layer rpn_relu/3x3_2
I0422 02:58:23.730330 23865 net.cpp:100] Creating Layer rpn_relu/3x3_2
I0422 02:58:23.730338 23865 net.cpp:434] rpn_relu/3x3_2 <- rpn/output_2
I0422 02:58:23.730352 23865 net.cpp:395] rpn_relu/3x3_2 -> rpn/output_2 (in-place)
I0422 02:58:23.730729 23865 net.cpp:150] Setting up rpn_relu/3x3_2
I0422 02:58:23.730743 23865 net.cpp:157] Top shape: 1 512 96 2 2 (196608)
I0422 02:58:23.730751 23865 net.cpp:165] Memory required for data: 10171516092
I0422 02:58:23.730787 23865 layer_factory.hpp:77] Creating layer rpn/output_pool
I0422 02:58:23.730813 23865 net.cpp:100] Creating Layer rpn/output_pool
I0422 02:58:23.730820 23865 net.cpp:434] rpn/output_pool <- rpn/output_2
I0422 02:58:23.730831 23865 net.cpp:408] rpn/output_pool -> rpn/output_pool
I0422 02:58:23.731029 23865 net.cpp:150] Setting up rpn/output_pool
I0422 02:58:23.731042 23865 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 02:58:23.731048 23865 net.cpp:165] Memory required for data: 10171712700
I0422 02:58:23.731055 23865 layer_factory.hpp:77] Creating layer rpn/output_pool_rpn/output_pool_0_split
I0422 02:58:23.731066 23865 net.cpp:100] Creating Layer rpn/output_pool_rpn/output_pool_0_split
I0422 02:58:23.731075 23865 net.cpp:434] rpn/output_pool_rpn/output_pool_0_split <- rpn/output_pool
I0422 02:58:23.731082 23865 net.cpp:408] rpn/output_pool_rpn/output_pool_0_split -> rpn/output_pool_rpn/output_pool_0_split_0
I0422 02:58:23.731092 23865 net.cpp:408] rpn/output_pool_rpn/output_pool_0_split -> rpn/output_pool_rpn/output_pool_0_split_1
I0422 02:58:23.731135 23865 net.cpp:150] Setting up rpn/output_pool_rpn/output_pool_0_split
I0422 02:58:23.731145 23865 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 02:58:23.731153 23865 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 02:58:23.731159 23865 net.cpp:165] Memory required for data: 10172105916
I0422 02:58:23.731165 23865 layer_factory.hpp:77] Creating layer rpn_cls_score
I0422 02:58:23.731181 23865 net.cpp:100] Creating Layer rpn_cls_score
I0422 02:58:23.731189 23865 net.cpp:434] rpn_cls_score <- rpn/output_pool_rpn/output_pool_0_split_0
I0422 02:58:23.731200 23865 net.cpp:408] rpn_cls_score -> rpn_cls_score
I0422 02:58:23.733474 23865 net.cpp:150] Setting up rpn_cls_score
I0422 02:58:23.733492 23865 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:58:23.733500 23865 net.cpp:165] Memory required for data: 10172134332
I0422 02:58:23.733510 23865 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0422 02:58:23.733520 23865 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0422 02:58:23.733527 23865 net.cpp:434] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0422 02:58:23.733539 23865 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0422 02:58:23.733549 23865 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0422 02:58:23.733597 23865 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0422 02:58:23.733609 23865 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:58:23.733618 23865 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:58:23.733625 23865 net.cpp:165] Memory required for data: 10172191164
I0422 02:58:23.733631 23865 layer_factory.hpp:77] Creating layer rpn_twin_pred
I0422 02:58:23.733652 23865 net.cpp:100] Creating Layer rpn_twin_pred
I0422 02:58:23.733659 23865 net.cpp:434] rpn_twin_pred <- rpn/output_pool_rpn/output_pool_0_split_1
I0422 02:58:23.733671 23865 net.cpp:408] rpn_twin_pred -> rpn_twin_pred
I0422 02:58:23.735771 23865 net.cpp:150] Setting up rpn_twin_pred
I0422 02:58:23.735787 23865 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:58:23.735798 23865 net.cpp:165] Memory required for data: 10172219580
I0422 02:58:23.735810 23865 layer_factory.hpp:77] Creating layer rpn_twin_pred_rpn_twin_pred_0_split
I0422 02:58:23.735826 23865 net.cpp:100] Creating Layer rpn_twin_pred_rpn_twin_pred_0_split
I0422 02:58:23.735836 23865 net.cpp:434] rpn_twin_pred_rpn_twin_pred_0_split <- rpn_twin_pred
I0422 02:58:23.735846 23865 net.cpp:408] rpn_twin_pred_rpn_twin_pred_0_split -> rpn_twin_pred_rpn_twin_pred_0_split_0
I0422 02:58:23.735857 23865 net.cpp:408] rpn_twin_pred_rpn_twin_pred_0_split -> rpn_twin_pred_rpn_twin_pred_0_split_1
I0422 02:58:23.735903 23865 net.cpp:150] Setting up rpn_twin_pred_rpn_twin_pred_0_split
I0422 02:58:23.735913 23865 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:58:23.735920 23865 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:58:23.735926 23865 net.cpp:165] Memory required for data: 10172276412
I0422 02:58:23.735932 23865 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0422 02:58:23.735949 23865 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0422 02:58:23.735956 23865 net.cpp:434] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0422 02:58:23.735965 23865 net.cpp:408] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0422 02:58:23.736001 23865 net.cpp:150] Setting up rpn_cls_score_reshape
I0422 02:58:23.736011 23865 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 02:58:23.736016 23865 net.cpp:165] Memory required for data: 10172304828
I0422 02:58:23.736022 23865 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 02:58:23.736032 23865 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 02:58:23.736038 23865 net.cpp:434] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0422 02:58:23.736049 23865 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0422 02:58:23.736069 23865 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0422 02:58:23.736078 23865 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_2
I0422 02:58:23.736140 23865 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 02:58:23.736150 23865 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 02:58:23.736157 23865 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 02:58:23.736165 23865 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 02:58:23.736171 23865 net.cpp:165] Memory required for data: 10172390076
I0422 02:58:23.736176 23865 layer_factory.hpp:77] Creating layer rpn-data
I0422 02:58:23.736599 23865 net.cpp:100] Creating Layer rpn-data
I0422 02:58:23.736613 23865 net.cpp:434] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0422 02:58:23.736621 23865 net.cpp:434] rpn-data <- gt_boxes_data_1_split_0
I0422 02:58:23.736629 23865 net.cpp:434] rpn-data <- data_data_0_split_1
I0422 02:58:23.736640 23865 net.cpp:408] rpn-data -> rpn_labels
I0422 02:58:23.736654 23865 net.cpp:408] rpn-data -> rpn_twin_targets
I0422 02:58:23.736665 23865 net.cpp:408] rpn-data -> rpn_twin_inside_weights
I0422 02:58:23.736676 23865 net.cpp:408] rpn-data -> rpn_twin_outside_weights
I0422 02:58:23.739096 23865 net.cpp:150] Setting up rpn-data
I0422 02:58:23.739114 23865 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 02:58:23.739122 23865 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:58:23.739130 23865 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:58:23.739138 23865 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:58:23.739145 23865 net.cpp:165] Memory required for data: 10172489532
I0422 02:58:23.739151 23865 layer_factory.hpp:77] Creating layer rpn_labels_rpn-data_0_split
I0422 02:58:23.739161 23865 net.cpp:100] Creating Layer rpn_labels_rpn-data_0_split
I0422 02:58:23.739169 23865 net.cpp:434] rpn_labels_rpn-data_0_split <- rpn_labels
I0422 02:58:23.739179 23865 net.cpp:408] rpn_labels_rpn-data_0_split -> rpn_labels_rpn-data_0_split_0
I0422 02:58:23.739190 23865 net.cpp:408] rpn_labels_rpn-data_0_split -> rpn_labels_rpn-data_0_split_1
I0422 02:58:23.739233 23865 net.cpp:150] Setting up rpn_labels_rpn-data_0_split
I0422 02:58:23.739243 23865 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 02:58:23.739251 23865 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 02:58:23.739257 23865 net.cpp:165] Memory required for data: 10172517948
I0422 02:58:23.739264 23865 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0422 02:58:23.739279 23865 net.cpp:100] Creating Layer rpn_loss_cls
I0422 02:58:23.739284 23865 net.cpp:434] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0422 02:58:23.739292 23865 net.cpp:434] rpn_loss_cls <- rpn_labels_rpn-data_0_split_0
I0422 02:58:23.739301 23865 net.cpp:408] rpn_loss_cls -> rpn_cls_loss
I0422 02:58:23.739320 23865 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0422 02:58:23.739828 23865 net.cpp:150] Setting up rpn_loss_cls
I0422 02:58:23.739842 23865 net.cpp:157] Top shape: (1)
I0422 02:58:23.739848 23865 net.cpp:160]     with loss weight 1
I0422 02:58:23.739866 23865 net.cpp:165] Memory required for data: 10172517952
I0422 02:58:23.739873 23865 layer_factory.hpp:77] Creating layer rpn_loss_twin
I0422 02:58:23.739888 23865 net.cpp:100] Creating Layer rpn_loss_twin
I0422 02:58:23.739894 23865 net.cpp:434] rpn_loss_twin <- rpn_twin_pred_rpn_twin_pred_0_split_0
I0422 02:58:23.739904 23865 net.cpp:434] rpn_loss_twin <- rpn_twin_targets
I0422 02:58:23.739914 23865 net.cpp:434] rpn_loss_twin <- rpn_twin_inside_weights
I0422 02:58:23.739923 23865 net.cpp:434] rpn_loss_twin <- rpn_twin_outside_weights
I0422 02:58:23.739931 23865 net.cpp:408] rpn_loss_twin -> rpn_loss_twin
I0422 02:58:23.740015 23865 net.cpp:150] Setting up rpn_loss_twin
I0422 02:58:23.740025 23865 net.cpp:157] Top shape: (1)
I0422 02:58:23.740031 23865 net.cpp:160]     with loss weight 1
I0422 02:58:23.740038 23865 net.cpp:165] Memory required for data: 10172517956
I0422 02:58:23.740046 23865 layer_factory.hpp:77] Creating layer rpn_accuarcy
I0422 02:58:23.740057 23865 net.cpp:100] Creating Layer rpn_accuarcy
I0422 02:58:23.740064 23865 net.cpp:434] rpn_accuarcy <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0422 02:58:23.740072 23865 net.cpp:434] rpn_accuarcy <- rpn_labels_rpn-data_0_split_1
I0422 02:58:23.740082 23865 net.cpp:408] rpn_accuarcy -> rpn_accuarcy
I0422 02:58:23.740093 23865 net.cpp:408] rpn_accuarcy -> rpn_accuarcy_class
I0422 02:58:23.740139 23865 net.cpp:150] Setting up rpn_accuarcy
I0422 02:58:23.740147 23865 net.cpp:157] Top shape: (1)
I0422 02:58:23.740154 23865 net.cpp:157] Top shape: 2 (2)
I0422 02:58:23.740160 23865 net.cpp:165] Memory required for data: 10172517968
I0422 02:58:23.740166 23865 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0422 02:58:23.740177 23865 net.cpp:100] Creating Layer rpn_cls_prob
I0422 02:58:23.740185 23865 net.cpp:434] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_2
I0422 02:58:23.740195 23865 net.cpp:408] rpn_cls_prob -> rpn_cls_prob
I0422 02:58:23.740403 23865 net.cpp:150] Setting up rpn_cls_prob
I0422 02:58:23.740416 23865 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 02:58:23.740422 23865 net.cpp:165] Memory required for data: 10172546384
I0422 02:58:23.740429 23865 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0422 02:58:23.740447 23865 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0422 02:58:23.740454 23865 net.cpp:434] rpn_cls_prob_reshape <- rpn_cls_prob
I0422 02:58:23.740463 23865 net.cpp:408] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0422 02:58:23.740499 23865 net.cpp:150] Setting up rpn_cls_prob_reshape
I0422 02:58:23.740507 23865 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 02:58:23.740514 23865 net.cpp:165] Memory required for data: 10172574800
I0422 02:58:23.740520 23865 layer_factory.hpp:77] Creating layer proposal
I0422 02:58:23.741116 23865 net.cpp:100] Creating Layer proposal
I0422 02:58:23.741129 23865 net.cpp:434] proposal <- rpn_cls_prob_reshape
I0422 02:58:23.741137 23865 net.cpp:434] proposal <- rpn_twin_pred_rpn_twin_pred_0_split_1
I0422 02:58:23.741147 23865 net.cpp:408] proposal -> rpn_rois
I0422 02:58:23.743623 23865 net.cpp:150] Setting up proposal
I0422 02:58:23.743640 23865 net.cpp:157] Top shape: 1 3 (3)
I0422 02:58:23.743646 23865 net.cpp:165] Memory required for data: 10172574812
I0422 02:58:23.743654 23865 layer_factory.hpp:77] Creating layer roi-data
I0422 02:58:23.743806 23865 net.cpp:100] Creating Layer roi-data
I0422 02:58:23.743818 23865 net.cpp:434] roi-data <- rpn_rois
I0422 02:58:23.743826 23865 net.cpp:434] roi-data <- gt_boxes_data_1_split_1
I0422 02:58:23.743839 23865 net.cpp:408] roi-data -> rois
I0422 02:58:23.743851 23865 net.cpp:408] roi-data -> labels
I0422 02:58:23.743863 23865 net.cpp:408] roi-data -> twin_targets
I0422 02:58:23.743873 23865 net.cpp:408] roi-data -> twin_inside_weights
I0422 02:58:23.743885 23865 net.cpp:408] roi-data -> twin_outside_weights
('sampling method:', 'Random')
I0422 02:58:23.744230 23865 net.cpp:150] Setting up roi-data
I0422 02:58:23.744244 23865 net.cpp:157] Top shape: 1 3 (3)
I0422 02:58:23.744251 23865 net.cpp:157] Top shape: 1 200 (200)
I0422 02:58:23.744261 23865 net.cpp:157] Top shape: 1 400 (400)
I0422 02:58:23.744268 23865 net.cpp:157] Top shape: 1 400 (400)
I0422 02:58:23.744276 23865 net.cpp:157] Top shape: 1 400 (400)
I0422 02:58:23.744282 23865 net.cpp:165] Memory required for data: 10172580424
I0422 02:58:23.744289 23865 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0422 02:58:23.744298 23865 net.cpp:100] Creating Layer labels_roi-data_1_split
I0422 02:58:23.744305 23865 net.cpp:434] labels_roi-data_1_split <- labels
I0422 02:58:23.744316 23865 net.cpp:408] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0422 02:58:23.744328 23865 net.cpp:408] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0422 02:58:23.744369 23865 net.cpp:150] Setting up labels_roi-data_1_split
I0422 02:58:23.744379 23865 net.cpp:157] Top shape: 1 200 (200)
I0422 02:58:23.744385 23865 net.cpp:157] Top shape: 1 200 (200)
I0422 02:58:23.744392 23865 net.cpp:165] Memory required for data: 10172582024
I0422 02:58:23.744398 23865 layer_factory.hpp:77] Creating layer roi_pool5
I0422 02:58:23.744412 23865 net.cpp:100] Creating Layer roi_pool5
I0422 02:58:23.744419 23865 net.cpp:434] roi_pool5 <- conv5b_relu5b_0_split_1
I0422 02:58:23.744426 23865 net.cpp:434] roi_pool5 <- rois
I0422 02:58:23.744434 23865 net.cpp:408] roi_pool5 -> pool5
I0422 02:58:23.744446 23865 roi_pooling_layer.cpp:34] Temporal scale: 0.125
I0422 02:58:23.744457 23865 roi_pooling_layer.cpp:35] Spatial scale: 0.0625
I0422 02:58:23.744508 23865 net.cpp:150] Setting up roi_pool5
I0422 02:58:23.744518 23865 net.cpp:157] Top shape: 1 512 1 4 4 (8192)
I0422 02:58:23.744524 23865 net.cpp:165] Memory required for data: 10172614792
I0422 02:58:23.744530 23865 layer_factory.hpp:77] Creating layer fc6
I0422 02:58:23.744545 23865 net.cpp:100] Creating Layer fc6
I0422 02:58:23.744552 23865 net.cpp:434] fc6 <- pool5
I0422 02:58:23.744562 23865 net.cpp:408] fc6 -> fc6
I0422 02:58:24.691558 23865 net.cpp:150] Setting up fc6
I0422 02:58:24.691587 23865 net.cpp:157] Top shape: 1 4096 (4096)
I0422 02:58:24.691592 23865 net.cpp:165] Memory required for data: 10172631176
I0422 02:58:24.691606 23865 layer_factory.hpp:77] Creating layer relu6
I0422 02:58:24.691619 23865 net.cpp:100] Creating Layer relu6
I0422 02:58:24.691629 23865 net.cpp:434] relu6 <- fc6
I0422 02:58:24.691639 23865 net.cpp:395] relu6 -> fc6 (in-place)
I0422 02:58:24.692147 23865 net.cpp:150] Setting up relu6
I0422 02:58:24.692162 23865 net.cpp:157] Top shape: 1 4096 (4096)
I0422 02:58:24.692167 23865 net.cpp:165] Memory required for data: 10172647560
I0422 02:58:24.692173 23865 layer_factory.hpp:77] Creating layer drop6
I0422 02:58:24.692198 23865 net.cpp:100] Creating Layer drop6
I0422 02:58:24.692204 23865 net.cpp:434] drop6 <- fc6
I0422 02:58:24.692214 23865 net.cpp:395] drop6 -> fc6 (in-place)
I0422 02:58:24.692250 23865 net.cpp:150] Setting up drop6
I0422 02:58:24.692260 23865 net.cpp:157] Top shape: 1 4096 (4096)
I0422 02:58:24.692265 23865 net.cpp:165] Memory required for data: 10172663944
I0422 02:58:24.692272 23865 layer_factory.hpp:77] Creating layer fc6_drop6_0_split
I0422 02:58:24.692281 23865 net.cpp:100] Creating Layer fc6_drop6_0_split
I0422 02:58:24.692286 23865 net.cpp:434] fc6_drop6_0_split <- fc6
I0422 02:58:24.692297 23865 net.cpp:408] fc6_drop6_0_split -> fc6_drop6_0_split_0
I0422 02:58:24.692307 23865 net.cpp:408] fc6_drop6_0_split -> fc6_drop6_0_split_1
I0422 02:58:24.692348 23865 net.cpp:150] Setting up fc6_drop6_0_split
I0422 02:58:24.692358 23865 net.cpp:157] Top shape: 1 4096 (4096)
I0422 02:58:24.692364 23865 net.cpp:157] Top shape: 1 4096 (4096)
I0422 02:58:24.692370 23865 net.cpp:165] Memory required for data: 10172696712
I0422 02:58:24.692376 23865 layer_factory.hpp:77] Creating layer cls_score
I0422 02:58:24.692394 23865 net.cpp:100] Creating Layer cls_score
I0422 02:58:24.692400 23865 net.cpp:434] cls_score <- fc6_drop6_0_split_0
I0422 02:58:24.692410 23865 net.cpp:408] cls_score -> cls_score
I0422 02:58:24.714191 23865 net.cpp:150] Setting up cls_score
I0422 02:58:24.714218 23865 net.cpp:157] Top shape: 1 200 (200)
I0422 02:58:24.714224 23865 net.cpp:165] Memory required for data: 10172697512
I0422 02:58:24.714237 23865 layer_factory.hpp:77] Creating layer cls_score_cls_score_0_split
I0422 02:58:24.714251 23865 net.cpp:100] Creating Layer cls_score_cls_score_0_split
I0422 02:58:24.714259 23865 net.cpp:434] cls_score_cls_score_0_split <- cls_score
I0422 02:58:24.714275 23865 net.cpp:408] cls_score_cls_score_0_split -> cls_score_cls_score_0_split_0
I0422 02:58:24.714288 23865 net.cpp:408] cls_score_cls_score_0_split -> cls_score_cls_score_0_split_1
I0422 02:58:24.714330 23865 net.cpp:150] Setting up cls_score_cls_score_0_split
I0422 02:58:24.714339 23865 net.cpp:157] Top shape: 1 200 (200)
I0422 02:58:24.714346 23865 net.cpp:157] Top shape: 1 200 (200)
I0422 02:58:24.714351 23865 net.cpp:165] Memory required for data: 10172699112
I0422 02:58:24.714356 23865 layer_factory.hpp:77] Creating layer twin_pred
I0422 02:58:24.714370 23865 net.cpp:100] Creating Layer twin_pred
I0422 02:58:24.714377 23865 net.cpp:434] twin_pred <- fc6_drop6_0_split_1
I0422 02:58:24.714387 23865 net.cpp:408] twin_pred -> twin_pred
I0422 02:58:24.757038 23865 net.cpp:150] Setting up twin_pred
I0422 02:58:24.757064 23865 net.cpp:157] Top shape: 1 400 (400)
I0422 02:58:24.757071 23865 net.cpp:165] Memory required for data: 10172700712
I0422 02:58:24.757082 23865 layer_factory.hpp:77] Creating layer loss_cls
I0422 02:58:24.757102 23865 net.cpp:100] Creating Layer loss_cls
I0422 02:58:24.757110 23865 net.cpp:434] loss_cls <- cls_score_cls_score_0_split_0
I0422 02:58:24.757118 23865 net.cpp:434] loss_cls <- labels_roi-data_1_split_0
I0422 02:58:24.757129 23865 net.cpp:408] loss_cls -> loss_cls
I0422 02:58:24.757191 23865 net.cpp:150] Setting up loss_cls
I0422 02:58:24.757201 23865 net.cpp:157] Top shape: (1)
I0422 02:58:24.757206 23865 net.cpp:160]     with loss weight 1
I0422 02:58:24.757220 23865 net.cpp:165] Memory required for data: 10172700716
I0422 02:58:24.757225 23865 layer_factory.hpp:77] Creating layer loss_twin
I0422 02:58:24.757236 23865 net.cpp:100] Creating Layer loss_twin
I0422 02:58:24.757244 23865 net.cpp:434] loss_twin <- twin_pred
I0422 02:58:24.757251 23865 net.cpp:434] loss_twin <- twin_targets
I0422 02:58:24.757258 23865 net.cpp:434] loss_twin <- twin_inside_weights
I0422 02:58:24.757266 23865 net.cpp:434] loss_twin <- twin_outside_weights
I0422 02:58:24.757277 23865 net.cpp:408] loss_twin -> loss_twin
I0422 02:58:24.757359 23865 net.cpp:150] Setting up loss_twin
I0422 02:58:24.757369 23865 net.cpp:157] Top shape: (1)
I0422 02:58:24.757374 23865 net.cpp:160]     with loss weight 1
I0422 02:58:24.757381 23865 net.cpp:165] Memory required for data: 10172700720
I0422 02:58:24.757387 23865 layer_factory.hpp:77] Creating layer accuracy
I0422 02:58:24.757585 23865 net.cpp:100] Creating Layer accuracy
I0422 02:58:24.757596 23865 net.cpp:434] accuracy <- cls_score_cls_score_0_split_1
I0422 02:58:24.757604 23865 net.cpp:434] accuracy <- labels_roi-data_1_split_1
I0422 02:58:24.757613 23865 net.cpp:408] accuracy -> accuracy
I0422 02:58:24.757702 23865 net.cpp:150] Setting up accuracy
I0422 02:58:24.757715 23865 net.cpp:157] Top shape: 1 (1)
I0422 02:58:24.757721 23865 net.cpp:165] Memory required for data: 10172700724
I0422 02:58:24.757727 23865 net.cpp:228] accuracy does not need backward computation.
I0422 02:58:24.757735 23865 net.cpp:226] loss_twin needs backward computation.
I0422 02:58:24.757741 23865 net.cpp:226] loss_cls needs backward computation.
I0422 02:58:24.757750 23865 net.cpp:226] twin_pred needs backward computation.
I0422 02:58:24.757756 23865 net.cpp:226] cls_score_cls_score_0_split needs backward computation.
I0422 02:58:24.757762 23865 net.cpp:226] cls_score needs backward computation.
I0422 02:58:24.757768 23865 net.cpp:226] fc6_drop6_0_split needs backward computation.
I0422 02:58:24.757776 23865 net.cpp:226] drop6 needs backward computation.
I0422 02:58:24.757781 23865 net.cpp:226] relu6 needs backward computation.
I0422 02:58:24.757787 23865 net.cpp:226] fc6 needs backward computation.
I0422 02:58:24.757793 23865 net.cpp:226] roi_pool5 needs backward computation.
I0422 02:58:24.757802 23865 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0422 02:58:24.757809 23865 net.cpp:226] roi-data needs backward computation.
I0422 02:58:24.757817 23865 net.cpp:226] proposal needs backward computation.
I0422 02:58:24.757823 23865 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0422 02:58:24.757829 23865 net.cpp:226] rpn_cls_prob needs backward computation.
I0422 02:58:24.757836 23865 net.cpp:228] rpn_accuarcy does not need backward computation.
I0422 02:58:24.757843 23865 net.cpp:226] rpn_loss_twin needs backward computation.
I0422 02:58:24.757850 23865 net.cpp:226] rpn_loss_cls needs backward computation.
I0422 02:58:24.757858 23865 net.cpp:228] rpn_labels_rpn-data_0_split does not need backward computation.
I0422 02:58:24.757865 23865 net.cpp:226] rpn-data needs backward computation.
I0422 02:58:24.757874 23865 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0422 02:58:24.757880 23865 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0422 02:58:24.757897 23865 net.cpp:226] rpn_twin_pred_rpn_twin_pred_0_split needs backward computation.
I0422 02:58:24.757903 23865 net.cpp:226] rpn_twin_pred needs backward computation.
I0422 02:58:24.757910 23865 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0422 02:58:24.757916 23865 net.cpp:226] rpn_cls_score needs backward computation.
I0422 02:58:24.757923 23865 net.cpp:226] rpn/output_pool_rpn/output_pool_0_split needs backward computation.
I0422 02:58:24.757930 23865 net.cpp:226] rpn/output_pool needs backward computation.
I0422 02:58:24.757936 23865 net.cpp:226] rpn_relu/3x3_2 needs backward computation.
I0422 02:58:24.757942 23865 net.cpp:226] rpn_conv/3x3_2 needs backward computation.
I0422 02:58:24.757948 23865 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0422 02:58:24.757954 23865 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0422 02:58:24.757961 23865 net.cpp:226] conv5b_relu5b_0_split needs backward computation.
I0422 02:58:24.757966 23865 net.cpp:226] relu5b needs backward computation.
I0422 02:58:24.757973 23865 net.cpp:226] conv5b needs backward computation.
I0422 02:58:24.757979 23865 net.cpp:226] relu5a needs backward computation.
I0422 02:58:24.757985 23865 net.cpp:226] conv5a needs backward computation.
I0422 02:58:24.757990 23865 net.cpp:226] pool4 needs backward computation.
I0422 02:58:24.757997 23865 net.cpp:226] relu4b needs backward computation.
I0422 02:58:24.758003 23865 net.cpp:226] conv4b needs backward computation.
I0422 02:58:24.758009 23865 net.cpp:226] relu4a needs backward computation.
I0422 02:58:24.758015 23865 net.cpp:226] conv4a needs backward computation.
I0422 02:58:24.758021 23865 net.cpp:226] pool3 needs backward computation.
I0422 02:58:24.758028 23865 net.cpp:226] relu3b needs backward computation.
I0422 02:58:24.758033 23865 net.cpp:226] conv3b needs backward computation.
I0422 02:58:24.758039 23865 net.cpp:226] relu3a needs backward computation.
I0422 02:58:24.758044 23865 net.cpp:226] conv3a needs backward computation.
I0422 02:58:24.758050 23865 net.cpp:228] pool2 does not need backward computation.
I0422 02:58:24.758059 23865 net.cpp:228] relu2a does not need backward computation.
I0422 02:58:24.758064 23865 net.cpp:228] conv2a does not need backward computation.
I0422 02:58:24.758070 23865 net.cpp:228] pool1 does not need backward computation.
I0422 02:58:24.758076 23865 net.cpp:228] relu1a does not need backward computation.
I0422 02:58:24.758082 23865 net.cpp:228] conv1a does not need backward computation.
I0422 02:58:24.758090 23865 net.cpp:228] gt_boxes_data_1_split does not need backward computation.
I0422 02:58:24.758096 23865 net.cpp:228] data_data_0_split does not need backward computation.
I0422 02:58:24.758103 23865 net.cpp:228] data does not need backward computation.
I0422 02:58:24.758111 23865 net.cpp:270] This network produces output accuracy
I0422 02:58:24.758116 23865 net.cpp:270] This network produces output loss_cls
I0422 02:58:24.758123 23865 net.cpp:270] This network produces output loss_twin
I0422 02:58:24.758131 23865 net.cpp:270] This network produces output rpn_accuarcy
I0422 02:58:24.758136 23865 net.cpp:270] This network produces output rpn_accuarcy_class
I0422 02:58:24.758141 23865 net.cpp:270] This network produces output rpn_cls_loss
I0422 02:58:24.758147 23865 net.cpp:270] This network produces output rpn_loss_twin
I0422 02:58:24.758195 23865 net.cpp:283] Network initialization done.
I0422 02:58:24.758330 23865 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from ./pretrain/activitynet_iter_30000_3fps.caffemodel
I0422 02:58:27.035221 23865 net.cpp:761] Ignoring source layer pool5
I0422 02:58:27.058123 23865 net.cpp:761] Ignoring source layer fc7
I0422 02:58:27.058151 23865 net.cpp:761] Ignoring source layer relu7
I0422 02:58:27.058158 23865 net.cpp:761] Ignoring source layer drop7
I0422 02:58:27.058163 23865 net.cpp:761] Ignoring source layer fc8-200
I0422 02:58:27.058169 23865 net.cpp:761] Ignoring source layer loss
Solving...
rpn: num_positive 6
rpn: num_negative 58
I0422 02:58:30.397982 23865 accuracy_layer.cpp:96] Accuracy: 0.5625
I0422 02:58:30.398006 23865 accuracy_layer.cpp:101] Class 0 accuracy : 0.534483
I0422 02:58:30.398015 23865 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
num fg: 11
num bg: 26
('accuracy: ', 0.0)
I0422 02:58:30.454882 23865 solver.cpp:228] Iteration 0, loss = 162.124
I0422 02:58:30.454908 23865 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 02:58:30.454922 23865 solver.cpp:244]     Train net output #1: loss_cls = 161.403 (* 1 = 161.403 loss)
I0422 02:58:30.454933 23865 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 02:58:30.454944 23865 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.5625
I0422 02:58:30.454955 23865 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.534483
I0422 02:58:30.454965 23865 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 02:58:30.454977 23865 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.695534 (* 1 = 0.695534 loss)
I0422 02:58:30.454991 23865 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0254261 (* 1 = 0.0254261 loss)
I0422 02:58:30.455003 23865 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 02:58:34.977605 23865 accuracy_layer.cpp:96] Accuracy: 0.421875
I0422 02:58:34.977634 23865 accuracy_layer.cpp:101] Class 0 accuracy : 0.409836
I0422 02:58:34.977639 23865 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
num fg: 4
num bg: 18
('accuracy: ', 0.0)
I0422 02:58:34.995018 23865 solver.cpp:228] Iteration 1, loss = 150.323
I0422 02:58:34.995055 23865 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 02:58:34.995065 23865 solver.cpp:244]     Train net output #1: loss_cls = 149.61 (* 1 = 149.61 loss)
I0422 02:58:34.995072 23865 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 02:58:34.995076 23865 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.421875
I0422 02:58:34.995082 23865 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.409836
I0422 02:58:34.995086 23865 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 02:58:34.995091 23865 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.701006 (* 1 = 0.701006 loss)
I0422 02:58:34.995098 23865 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.011682 (* 1 = 0.011682 loss)
I0422 02:58:34.995106 23865 sgd_solver.cpp:106] Iteration 1, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 02:58:39.715672 23865 accuracy_layer.cpp:96] Accuracy: 0.65625
I0422 02:58:39.715732 23865 accuracy_layer.cpp:101] Class 0 accuracy : 0.644068
I0422 02:58:39.715750 23865 accuracy_layer.cpp:101] Class 1 accuracy : 0.8
TRAIN
num fg: 10
num bg: 20
('accuracy: ', 0.0)
I0422 02:58:39.735657 23865 solver.cpp:228] Iteration 2, loss = 118.678
I0422 02:58:39.735733 23865 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 02:58:39.735757 23865 solver.cpp:244]     Train net output #1: loss_cls = 117.979 (* 1 = 117.979 loss)
I0422 02:58:39.735777 23865 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 02:58:39.735793 23865 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.65625
I0422 02:58:39.735810 23865 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.644068
I0422 02:58:39.735826 23865 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.8
I0422 02:58:39.735843 23865 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.688338 (* 1 = 0.688338 loss)
I0422 02:58:39.735862 23865 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0112732 (* 1 = 0.0112732 loss)
I0422 02:58:39.735894 23865 sgd_solver.cpp:106] Iteration 2, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 02:58:44.263701 23865 accuracy_layer.cpp:96] Accuracy: 0.390625
I0422 02:58:44.263723 23865 accuracy_layer.cpp:101] Class 0 accuracy : 0.37931
I0422 02:58:44.263731 23865 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 9
num bg: 22
('accuracy: ', 0.0)
I0422 02:58:44.281486 23865 solver.cpp:228] Iteration 3, loss = 91.1619
I0422 02:58:44.281507 23865 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 02:58:44.281522 23865 solver.cpp:244]     Train net output #1: loss_cls = 90.4052 (* 1 = 90.4052 loss)
I0422 02:58:44.281534 23865 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 02:58:44.281546 23865 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.390625
I0422 02:58:44.281556 23865 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.37931
I0422 02:58:44.281566 23865 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 02:58:44.281579 23865 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.724751 (* 1 = 0.724751 loss)
I0422 02:58:44.281590 23865 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0319101 (* 1 = 0.0319101 loss)
I0422 02:58:44.281601 23865 sgd_solver.cpp:106] Iteration 3, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 02:58:48.981520 23865 accuracy_layer.cpp:96] Accuracy: 0.5
I0422 02:58:48.981544 23865 accuracy_layer.cpp:101] Class 0 accuracy : 0.5
I0422 02:58:48.981550 23865 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 02:58:48.999346 23865 solver.cpp:228] Iteration 4, loss = 50.746
I0422 02:58:48.999373 23865 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 02:58:48.999392 23865 solver.cpp:244]     Train net output #1: loss_cls = 49.9841 (* 1 = 49.9841 loss)
I0422 02:58:48.999408 23865 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 02:58:48.999421 23865 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.5
I0422 02:58:48.999430 23865 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.5
I0422 02:58:48.999440 23865 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 02:58:48.999455 23865 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.723772 (* 1 = 0.723772 loss)
I0422 02:58:48.999466 23865 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0381253 (* 1 = 0.0381253 loss)
I0422 02:58:48.999480 23865 sgd_solver.cpp:106] Iteration 4, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 02:58:53.530897 23865 accuracy_layer.cpp:96] Accuracy: 0.4375
I0422 02:58:53.530920 23865 accuracy_layer.cpp:101] Class 0 accuracy : 0.396552
I0422 02:58:53.530927 23865 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 02:58:53.552652 23865 solver.cpp:228] Iteration 5, loss = 8.40165
I0422 02:58:53.552677 23865 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 02:58:53.552691 23865 solver.cpp:244]     Train net output #1: loss_cls = 7.19968 (* 1 = 7.19968 loss)
I0422 02:58:53.552709 23865 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 02:58:53.552721 23865 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.4375
I0422 02:58:53.552734 23865 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.396552
I0422 02:58:53.552747 23865 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 02:58:53.552759 23865 solver.cpp:244]     Train net output #6: rpn_cls_loss = 1.02294 (* 1 = 1.02294 loss)
I0422 02:58:53.552774 23865 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.179035 (* 1 = 0.179035 loss)
I0422 02:58:53.552788 23865 sgd_solver.cpp:106] Iteration 5, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 02:58:58.379011 23865 accuracy_layer.cpp:96] Accuracy: 0.625
I0422 02:58:58.379034 23865 accuracy_layer.cpp:101] Class 0 accuracy : 0.603448
I0422 02:58:58.379041 23865 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
Traceback (most recent call last):
  File "./experiments/activitynet/train_net.py", line 97, in <module>
    max_iters=args.max_iters)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/tdcnn/train.py", line 125, in train_net
    model_paths = sw.train_model(max_iters)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/tdcnn/train.py", line 102, in train_model
    self.solver.step(1)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/rpn/proposal_target_layer.py", line 84, in forward
    rois_per_image, self._num_classes)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/rpn/proposal_target_layer.py", line 225, in _sample_rois
    _get_twin_regression_labels(twin_target_data, num_classes)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/rpn/proposal_target_layer.py", line 157, in _get_twin_regression_labels
    twin_targets[ind, start:end] = twin_target_data[ind, 1:]
ValueError: could not broadcast input array from shape (201) into shape (2)

real	0m38.761s
user	0m10.170s
sys	0m30.095s
Called with args:
Namespace(cfg_file='./experiments/activitynet/td_cnn_end2end.yml', gpu_id=0, max_iters=350000, pretrained_model='./pretrain/activitynet_iter_30000_3fps.caffemodel', randomize=False, set_cfgs=None, solver='./experiments/activitynet/solver.prototxt')
Using config:
{'DEDUP_BOXES': 0.125,
 'EPS': 1e-14,
 'FPS': 25,
 'GPU_ID': 0,
 'INPUT': 'video',
 'NUM_CLASSES': 201,
 'PIXEL_MEANS': array([[[ 90,  98, 102]]]),
 'PIXEL_MEANS_FLOW': array([128]),
 'RNG_SEED': 3,
 'TEST': {'CROP_SIZE': 112,
          'FRAME_SIZE': [128, 171],
          'HAS_RPN': True,
          'LENGTH': [768],
          'MAX_SIZE': 1000,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.9,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SVM': False,
          'TWIN_REG': True},
 'TRAIN': {'BATCH_SIZE': 128,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.1,
           'CINPUT': False,
           'CROP_SIZE': 112,
           'FG_FRACTION': 0.5,
           'FG_THRESH': 0.5,
           'FRAME_SIZE': [128, 171],
           'HAS_RPN': True,
           'LENGTH': [768],
           'OHEM_LOSS_ONLY_CLASSIFICATION': False,
           'OHEM_LOSS_ONLY_LOCALIZATION': False,
           'OHEM_NMS_THRESH': 0.7,
           'OHEM_USE_NMS': True,
           'PROPOSAL_METHOD': 'gt',
           'RANDOM': False,
           'RPN_BATCHSIZE': 64,
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.8,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'RPN_TWIN_INSIDE_WEIGHTS': [1.0, 1.0],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 1000,
           'TWIN_INSIDE_WEIGHTS': [1.0, 1.0],
           'TWIN_NORMALIZE_MEANS': [0.0, 0.0],
           'TWIN_NORMALIZE_STDS': [0.1, 0.2],
           'TWIN_NORMALIZE_TARGETS': False,
           'TWIN_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'TWIN_REG': True,
           'TWIN_THRESH': 0.5,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False,
           'VIDEO_BATCH': 1},
 'USE_GPU_NMS': True}
18024 roidb entries
Output will be saved to `./experiments/best_activitynet/snapshot/`
Computing bounding-box regression targets...
precimputed
twin target means:
twin target stdevs:
NOT normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0422 03:07:18.274410 24110 solver.cpp:48] Initializing solver from parameters: 
train_net: "./experiments/activitynet/train.prototxt"
base_lr: 0.0001
display: 1
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 350000
snapshot: 0
snapshot_prefix: "./experiments/activitynet/snapshot/activitynet"
average_loss: 100
iter_size: 1
I0422 03:07:18.274440 24110 solver.cpp:81] Creating training net from train_net file: ./experiments/activitynet/train.prototxt
I0422 03:07:18.275502 24110 net.cpp:58] Initializing net from parameters: 
name: "activitynet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 200"
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    kernel_size: 2
    kernel_size: 2
    stride: 1
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv2a"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv3a"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "conv3b"
  type: "Convolution"
  bottom: "conv3a"
  top: "conv3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3b"
  type: "ReLU"
  bottom: "conv3b"
  top: "conv3b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv4a"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "conv4b"
  type: "Convolution"
  bottom: "conv4a"
  top: "conv4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4b"
  type: "ReLU"
  bottom: "conv4b"
  top: "conv4b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv5a"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "conv5b"
  type: "Convolution"
  bottom: "conv5a"
  top: "conv5b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5b"
  type: "ReLU"
  bottom: "conv5b"
  top: "conv5b"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5b"
  top: "rpn/output"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_conv/3x3_2"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn/output_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3_2"
  type: "ReLU"
  bottom: "rpn/output_2"
  top: "rpn/output_2"
}
layer {
  name: "rpn/output_pool"
  type: "Pooling"
  bottom: "rpn/output_2"
  top: "rpn/output_pool"
  pooling_param {
    pool: MAX
    kernel_size: 1
    kernel_size: 2
    kernel_size: 2
  }
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output_pool"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 74
    kernel_size: 1
    kernel_size: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_twin_pred"
  type: "Convolution"
  bottom: "rpn/output_pool"
  top: "rpn_twin_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 74
    kernel_size: 1
    kernel_size: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_twin_targets"
  top: "rpn_twin_inside_weights"
  top: "rpn_twin_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 8 \n\'scales\': !!python/tuple [1,1.25, 1.5,1.75, 2,2.5, 3,3.5, 4,4.5, 5,5.5, 6,7, 8,9,10,11,12,14,16,18,20,22,24,28,32,36,40,44,52,60,68,76,84,92,100]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_twin"
  type: "SmoothL1Loss"
  bottom: "rpn_twin_pred"
  bottom: "rpn_twin_targets"
  bottom: "rpn_twin_inside_weights"
  bottom: "rpn_twin_outside_weights"
  top: "rpn_loss_twin"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_accuarcy"
  type: "Accuracy"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_accuarcy"
  top: "rpn_accuarcy_class"
  propagate_down: false
  propagate_down: false
  accuracy_param {
    ignore_label: -1
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 74
      dim: -1
      dim: 0
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_twin_pred"
  top: "rpn_rois"
  include {
    phase: TRAIN
  }
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 8 \n\'scales\': !!python/tuple [1,1.25, 1.5,1.75, 2,2.5, 3,3.5, 4,4.5, 5,5.5, 6,7, 8,9,10,11,12,14,16,18,20,22,24,28,32,36,40,44,52,60,68,76,84,92,100]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  top: "rois"
  top: "labels"
  top: "twin_targets"
  top: "twin_inside_weights"
  top: "twin_outside_weights"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 200"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5b"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 4
    pooled_w: 4
    spatial_scale: 0.0625
    pooled_l: 1
    temporal_scale: 0.125
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc6"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 200
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "twin_pred"
  type: "InnerProduct"
  bottom: "fc6"
  top: "twin_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 400
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SigmoidCrossEntropyLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_twin"
  type: "SmoothL1Loss"
  bottom: "twin_pred"
  bottom: "twin_targets"
  bottom: "twin_inside_weights"
  bottom: "twin_outside_weights"
  top: "loss_twin"
  loss_weight: 1
}
layer {
  name: "accuracy"
  type: "Python"
  bottom: "cls_score"
  bottom: "labels"
  top: "accuracy"
  python_param {
    module: "utils.accuracy_layer"
    layer: "AccuracyLayer"
    param_str: "{\"top_k\": 2}"
  }
}
I0422 03:07:18.275708 24110 layer_factory.hpp:77] Creating layer data
I0422 03:07:18.302681 24110 net.cpp:100] Creating Layer data
I0422 03:07:18.302706 24110 net.cpp:408] data -> data
I0422 03:07:18.302719 24110 net.cpp:408] data -> gt_boxes
setting up
has rpn
RoiDataLayer: name_to_top: {'gt_windows': 1, 'data': 0}
I0422 03:07:18.315758 24110 net.cpp:150] Setting up data
I0422 03:07:18.315780 24110 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 03:07:18.315786 24110 net.cpp:157] Top shape: 1 101 (101)
I0422 03:07:18.315789 24110 net.cpp:165] Memory required for data: 115605908
I0422 03:07:18.315795 24110 layer_factory.hpp:77] Creating layer data_data_0_split
I0422 03:07:18.315805 24110 net.cpp:100] Creating Layer data_data_0_split
I0422 03:07:18.315812 24110 net.cpp:434] data_data_0_split <- data
I0422 03:07:18.315820 24110 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0422 03:07:18.315830 24110 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0422 03:07:18.315862 24110 net.cpp:150] Setting up data_data_0_split
I0422 03:07:18.315871 24110 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 03:07:18.315874 24110 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 03:07:18.315877 24110 net.cpp:165] Memory required for data: 346816916
I0422 03:07:18.315881 24110 layer_factory.hpp:77] Creating layer gt_boxes_data_1_split
I0422 03:07:18.315886 24110 net.cpp:100] Creating Layer gt_boxes_data_1_split
I0422 03:07:18.315889 24110 net.cpp:434] gt_boxes_data_1_split <- gt_boxes
I0422 03:07:18.315894 24110 net.cpp:408] gt_boxes_data_1_split -> gt_boxes_data_1_split_0
I0422 03:07:18.315901 24110 net.cpp:408] gt_boxes_data_1_split -> gt_boxes_data_1_split_1
I0422 03:07:18.315923 24110 net.cpp:150] Setting up gt_boxes_data_1_split
I0422 03:07:18.315929 24110 net.cpp:157] Top shape: 1 101 (101)
I0422 03:07:18.315933 24110 net.cpp:157] Top shape: 1 101 (101)
I0422 03:07:18.315937 24110 net.cpp:165] Memory required for data: 346817724
I0422 03:07:18.315939 24110 layer_factory.hpp:77] Creating layer conv1a
I0422 03:07:18.315954 24110 net.cpp:100] Creating Layer conv1a
I0422 03:07:18.315960 24110 net.cpp:434] conv1a <- data_data_0_split_0
I0422 03:07:18.315965 24110 net.cpp:408] conv1a -> conv1a
I0422 03:07:18.506427 24110 net.cpp:150] Setting up conv1a
I0422 03:07:18.506458 24110 net.cpp:157] Top shape: 1 64 768 112 112 (616562688)
I0422 03:07:18.506461 24110 net.cpp:165] Memory required for data: 2813068476
I0422 03:07:18.506480 24110 layer_factory.hpp:77] Creating layer relu1a
I0422 03:07:18.506495 24110 net.cpp:100] Creating Layer relu1a
I0422 03:07:18.506505 24110 net.cpp:434] relu1a <- conv1a
I0422 03:07:18.506510 24110 net.cpp:395] relu1a -> conv1a (in-place)
I0422 03:07:18.507020 24110 net.cpp:150] Setting up relu1a
I0422 03:07:18.507033 24110 net.cpp:157] Top shape: 1 64 768 112 112 (616562688)
I0422 03:07:18.507038 24110 net.cpp:165] Memory required for data: 5279319228
I0422 03:07:18.507041 24110 layer_factory.hpp:77] Creating layer pool1
I0422 03:07:18.507052 24110 net.cpp:100] Creating Layer pool1
I0422 03:07:18.507055 24110 net.cpp:434] pool1 <- conv1a
I0422 03:07:18.507061 24110 net.cpp:408] pool1 -> pool1
I0422 03:07:18.507251 24110 net.cpp:150] Setting up pool1
I0422 03:07:18.507261 24110 net.cpp:157] Top shape: 1 64 768 56 56 (154140672)
I0422 03:07:18.507266 24110 net.cpp:165] Memory required for data: 5895881916
I0422 03:07:18.507268 24110 layer_factory.hpp:77] Creating layer conv2a
I0422 03:07:18.507282 24110 net.cpp:100] Creating Layer conv2a
I0422 03:07:18.507285 24110 net.cpp:434] conv2a <- pool1
I0422 03:07:18.507290 24110 net.cpp:408] conv2a -> conv2a
I0422 03:07:18.519220 24110 net.cpp:150] Setting up conv2a
I0422 03:07:18.519251 24110 net.cpp:157] Top shape: 1 128 768 56 56 (308281344)
I0422 03:07:18.519255 24110 net.cpp:165] Memory required for data: 7129007292
I0422 03:07:18.519268 24110 layer_factory.hpp:77] Creating layer relu2a
I0422 03:07:18.519279 24110 net.cpp:100] Creating Layer relu2a
I0422 03:07:18.519282 24110 net.cpp:434] relu2a <- conv2a
I0422 03:07:18.519290 24110 net.cpp:395] relu2a -> conv2a (in-place)
I0422 03:07:18.519675 24110 net.cpp:150] Setting up relu2a
I0422 03:07:18.519687 24110 net.cpp:157] Top shape: 1 128 768 56 56 (308281344)
I0422 03:07:18.519691 24110 net.cpp:165] Memory required for data: 8362132668
I0422 03:07:18.519695 24110 layer_factory.hpp:77] Creating layer pool2
I0422 03:07:18.519712 24110 net.cpp:100] Creating Layer pool2
I0422 03:07:18.519718 24110 net.cpp:434] pool2 <- conv2a
I0422 03:07:18.519724 24110 net.cpp:408] pool2 -> pool2
I0422 03:07:18.519901 24110 net.cpp:150] Setting up pool2
I0422 03:07:18.519912 24110 net.cpp:157] Top shape: 1 128 384 28 28 (38535168)
I0422 03:07:18.519915 24110 net.cpp:165] Memory required for data: 8516273340
I0422 03:07:18.519918 24110 layer_factory.hpp:77] Creating layer conv3a
I0422 03:07:18.519930 24110 net.cpp:100] Creating Layer conv3a
I0422 03:07:18.519937 24110 net.cpp:434] conv3a <- pool2
I0422 03:07:18.519942 24110 net.cpp:408] conv3a -> conv3a
I0422 03:07:18.555138 24110 net.cpp:150] Setting up conv3a
I0422 03:07:18.555210 24110 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 03:07:18.555235 24110 net.cpp:165] Memory required for data: 8824554684
I0422 03:07:18.555264 24110 layer_factory.hpp:77] Creating layer relu3a
I0422 03:07:18.555286 24110 net.cpp:100] Creating Layer relu3a
I0422 03:07:18.555300 24110 net.cpp:434] relu3a <- conv3a
I0422 03:07:18.555320 24110 net.cpp:395] relu3a -> conv3a (in-place)
I0422 03:07:18.555996 24110 net.cpp:150] Setting up relu3a
I0422 03:07:18.556033 24110 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 03:07:18.556046 24110 net.cpp:165] Memory required for data: 9132836028
I0422 03:07:18.556061 24110 layer_factory.hpp:77] Creating layer conv3b
I0422 03:07:18.556089 24110 net.cpp:100] Creating Layer conv3b
I0422 03:07:18.556104 24110 net.cpp:434] conv3b <- conv3a
I0422 03:07:18.556124 24110 net.cpp:408] conv3b -> conv3b
I0422 03:07:18.619623 24110 net.cpp:150] Setting up conv3b
I0422 03:07:18.619647 24110 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 03:07:18.619652 24110 net.cpp:165] Memory required for data: 9441117372
I0422 03:07:18.619660 24110 layer_factory.hpp:77] Creating layer relu3b
I0422 03:07:18.619669 24110 net.cpp:100] Creating Layer relu3b
I0422 03:07:18.619675 24110 net.cpp:434] relu3b <- conv3b
I0422 03:07:18.619683 24110 net.cpp:395] relu3b -> conv3b (in-place)
I0422 03:07:18.620028 24110 net.cpp:150] Setting up relu3b
I0422 03:07:18.620040 24110 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 03:07:18.620043 24110 net.cpp:165] Memory required for data: 9749398716
I0422 03:07:18.620048 24110 layer_factory.hpp:77] Creating layer pool3
I0422 03:07:18.620055 24110 net.cpp:100] Creating Layer pool3
I0422 03:07:18.620060 24110 net.cpp:434] pool3 <- conv3b
I0422 03:07:18.620066 24110 net.cpp:408] pool3 -> pool3
I0422 03:07:18.620236 24110 net.cpp:150] Setting up pool3
I0422 03:07:18.620245 24110 net.cpp:157] Top shape: 1 256 192 14 14 (9633792)
I0422 03:07:18.620249 24110 net.cpp:165] Memory required for data: 9787933884
I0422 03:07:18.620254 24110 layer_factory.hpp:77] Creating layer conv4a
I0422 03:07:18.620265 24110 net.cpp:100] Creating Layer conv4a
I0422 03:07:18.620270 24110 net.cpp:434] conv4a <- pool3
I0422 03:07:18.620276 24110 net.cpp:408] conv4a -> conv4a
I0422 03:07:18.720363 24110 net.cpp:150] Setting up conv4a
I0422 03:07:18.720392 24110 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 03:07:18.720396 24110 net.cpp:165] Memory required for data: 9865004220
I0422 03:07:18.720408 24110 layer_factory.hpp:77] Creating layer relu4a
I0422 03:07:18.720419 24110 net.cpp:100] Creating Layer relu4a
I0422 03:07:18.720424 24110 net.cpp:434] relu4a <- conv4a
I0422 03:07:18.720430 24110 net.cpp:395] relu4a -> conv4a (in-place)
I0422 03:07:18.720779 24110 net.cpp:150] Setting up relu4a
I0422 03:07:18.720791 24110 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 03:07:18.720795 24110 net.cpp:165] Memory required for data: 9942074556
I0422 03:07:18.720798 24110 layer_factory.hpp:77] Creating layer conv4b
I0422 03:07:18.720813 24110 net.cpp:100] Creating Layer conv4b
I0422 03:07:18.720816 24110 net.cpp:434] conv4b <- conv4a
I0422 03:07:18.720823 24110 net.cpp:408] conv4b -> conv4b
I0422 03:07:18.909610 24110 net.cpp:150] Setting up conv4b
I0422 03:07:18.909636 24110 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 03:07:18.909641 24110 net.cpp:165] Memory required for data: 10019144892
I0422 03:07:18.909648 24110 layer_factory.hpp:77] Creating layer relu4b
I0422 03:07:18.909659 24110 net.cpp:100] Creating Layer relu4b
I0422 03:07:18.909664 24110 net.cpp:434] relu4b <- conv4b
I0422 03:07:18.909670 24110 net.cpp:395] relu4b -> conv4b (in-place)
I0422 03:07:18.909827 24110 net.cpp:150] Setting up relu4b
I0422 03:07:18.909837 24110 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 03:07:18.909842 24110 net.cpp:165] Memory required for data: 10096215228
I0422 03:07:18.909847 24110 layer_factory.hpp:77] Creating layer pool4
I0422 03:07:18.909853 24110 net.cpp:100] Creating Layer pool4
I0422 03:07:18.909857 24110 net.cpp:434] pool4 <- conv4b
I0422 03:07:18.909864 24110 net.cpp:408] pool4 -> pool4
I0422 03:07:18.910243 24110 net.cpp:150] Setting up pool4
I0422 03:07:18.910255 24110 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 03:07:18.910260 24110 net.cpp:165] Memory required for data: 10105849020
I0422 03:07:18.910264 24110 layer_factory.hpp:77] Creating layer conv5a
I0422 03:07:18.910275 24110 net.cpp:100] Creating Layer conv5a
I0422 03:07:18.910280 24110 net.cpp:434] conv5a <- pool4
I0422 03:07:18.910289 24110 net.cpp:408] conv5a -> conv5a
I0422 03:07:19.102663 24110 net.cpp:150] Setting up conv5a
I0422 03:07:19.102691 24110 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 03:07:19.102696 24110 net.cpp:165] Memory required for data: 10115482812
I0422 03:07:19.102707 24110 layer_factory.hpp:77] Creating layer relu5a
I0422 03:07:19.102718 24110 net.cpp:100] Creating Layer relu5a
I0422 03:07:19.102723 24110 net.cpp:434] relu5a <- conv5a
I0422 03:07:19.102730 24110 net.cpp:395] relu5a -> conv5a (in-place)
I0422 03:07:19.103298 24110 net.cpp:150] Setting up relu5a
I0422 03:07:19.103313 24110 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 03:07:19.103317 24110 net.cpp:165] Memory required for data: 10125116604
I0422 03:07:19.103322 24110 layer_factory.hpp:77] Creating layer conv5b
I0422 03:07:19.103333 24110 net.cpp:100] Creating Layer conv5b
I0422 03:07:19.103338 24110 net.cpp:434] conv5b <- conv5a
I0422 03:07:19.103343 24110 net.cpp:408] conv5b -> conv5b
I0422 03:07:19.305435 24110 net.cpp:150] Setting up conv5b
I0422 03:07:19.305506 24110 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 03:07:19.305521 24110 net.cpp:165] Memory required for data: 10134750396
I0422 03:07:19.305543 24110 layer_factory.hpp:77] Creating layer relu5b
I0422 03:07:19.305565 24110 net.cpp:100] Creating Layer relu5b
I0422 03:07:19.305582 24110 net.cpp:434] relu5b <- conv5b
I0422 03:07:19.305601 24110 net.cpp:395] relu5b -> conv5b (in-place)
I0422 03:07:19.305846 24110 net.cpp:150] Setting up relu5b
I0422 03:07:19.305873 24110 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 03:07:19.305887 24110 net.cpp:165] Memory required for data: 10144384188
I0422 03:07:19.305902 24110 layer_factory.hpp:77] Creating layer conv5b_relu5b_0_split
I0422 03:07:19.305917 24110 net.cpp:100] Creating Layer conv5b_relu5b_0_split
I0422 03:07:19.305930 24110 net.cpp:434] conv5b_relu5b_0_split <- conv5b
I0422 03:07:19.305948 24110 net.cpp:408] conv5b_relu5b_0_split -> conv5b_relu5b_0_split_0
I0422 03:07:19.305966 24110 net.cpp:408] conv5b_relu5b_0_split -> conv5b_relu5b_0_split_1
I0422 03:07:19.306042 24110 net.cpp:150] Setting up conv5b_relu5b_0_split
I0422 03:07:19.306066 24110 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 03:07:19.306080 24110 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 03:07:19.306092 24110 net.cpp:165] Memory required for data: 10163651772
I0422 03:07:19.306104 24110 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0422 03:07:19.306139 24110 net.cpp:100] Creating Layer rpn_conv/3x3
I0422 03:07:19.306154 24110 net.cpp:434] rpn_conv/3x3 <- conv5b_relu5b_0_split_0
I0422 03:07:19.306170 24110 net.cpp:408] rpn_conv/3x3 -> rpn/output
I0422 03:07:19.515698 24110 net.cpp:150] Setting up rpn_conv/3x3
I0422 03:07:19.515729 24110 net.cpp:157] Top shape: 1 512 96 4 4 (786432)
I0422 03:07:19.515735 24110 net.cpp:165] Memory required for data: 10166797500
I0422 03:07:19.515755 24110 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0422 03:07:19.515769 24110 net.cpp:100] Creating Layer rpn_relu/3x3
I0422 03:07:19.515782 24110 net.cpp:434] rpn_relu/3x3 <- rpn/output
I0422 03:07:19.515792 24110 net.cpp:395] rpn_relu/3x3 -> rpn/output (in-place)
I0422 03:07:19.516858 24110 net.cpp:150] Setting up rpn_relu/3x3
I0422 03:07:19.516875 24110 net.cpp:157] Top shape: 1 512 96 4 4 (786432)
I0422 03:07:19.516880 24110 net.cpp:165] Memory required for data: 10169943228
I0422 03:07:19.516885 24110 layer_factory.hpp:77] Creating layer rpn_conv/3x3_2
I0422 03:07:19.516901 24110 net.cpp:100] Creating Layer rpn_conv/3x3_2
I0422 03:07:19.516906 24110 net.cpp:434] rpn_conv/3x3_2 <- rpn/output
I0422 03:07:19.516917 24110 net.cpp:408] rpn_conv/3x3_2 -> rpn/output_2
I0422 03:07:19.728931 24110 net.cpp:150] Setting up rpn_conv/3x3_2
I0422 03:07:19.728961 24110 net.cpp:157] Top shape: 1 512 96 2 2 (196608)
I0422 03:07:19.728967 24110 net.cpp:165] Memory required for data: 10170729660
I0422 03:07:19.728979 24110 layer_factory.hpp:77] Creating layer rpn_relu/3x3_2
I0422 03:07:19.728992 24110 net.cpp:100] Creating Layer rpn_relu/3x3_2
I0422 03:07:19.729001 24110 net.cpp:434] rpn_relu/3x3_2 <- rpn/output_2
I0422 03:07:19.729013 24110 net.cpp:395] rpn_relu/3x3_2 -> rpn/output_2 (in-place)
I0422 03:07:19.729511 24110 net.cpp:150] Setting up rpn_relu/3x3_2
I0422 03:07:19.729527 24110 net.cpp:157] Top shape: 1 512 96 2 2 (196608)
I0422 03:07:19.729534 24110 net.cpp:165] Memory required for data: 10171516092
I0422 03:07:19.729540 24110 layer_factory.hpp:77] Creating layer rpn/output_pool
I0422 03:07:19.729553 24110 net.cpp:100] Creating Layer rpn/output_pool
I0422 03:07:19.729560 24110 net.cpp:434] rpn/output_pool <- rpn/output_2
I0422 03:07:19.729568 24110 net.cpp:408] rpn/output_pool -> rpn/output_pool
I0422 03:07:19.729809 24110 net.cpp:150] Setting up rpn/output_pool
I0422 03:07:19.729823 24110 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 03:07:19.729830 24110 net.cpp:165] Memory required for data: 10171712700
I0422 03:07:19.729837 24110 layer_factory.hpp:77] Creating layer rpn/output_pool_rpn/output_pool_0_split
I0422 03:07:19.729846 24110 net.cpp:100] Creating Layer rpn/output_pool_rpn/output_pool_0_split
I0422 03:07:19.729853 24110 net.cpp:434] rpn/output_pool_rpn/output_pool_0_split <- rpn/output_pool
I0422 03:07:19.729861 24110 net.cpp:408] rpn/output_pool_rpn/output_pool_0_split -> rpn/output_pool_rpn/output_pool_0_split_0
I0422 03:07:19.729871 24110 net.cpp:408] rpn/output_pool_rpn/output_pool_0_split -> rpn/output_pool_rpn/output_pool_0_split_1
I0422 03:07:19.729915 24110 net.cpp:150] Setting up rpn/output_pool_rpn/output_pool_0_split
I0422 03:07:19.729926 24110 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 03:07:19.729933 24110 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 03:07:19.729939 24110 net.cpp:165] Memory required for data: 10172105916
I0422 03:07:19.729944 24110 layer_factory.hpp:77] Creating layer rpn_cls_score
I0422 03:07:19.729961 24110 net.cpp:100] Creating Layer rpn_cls_score
I0422 03:07:19.729969 24110 net.cpp:434] rpn_cls_score <- rpn/output_pool_rpn/output_pool_0_split_0
I0422 03:07:19.729976 24110 net.cpp:408] rpn_cls_score -> rpn_cls_score
I0422 03:07:19.732184 24110 net.cpp:150] Setting up rpn_cls_score
I0422 03:07:19.732199 24110 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 03:07:19.732203 24110 net.cpp:165] Memory required for data: 10172134332
I0422 03:07:19.732210 24110 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0422 03:07:19.732218 24110 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0422 03:07:19.732221 24110 net.cpp:434] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0422 03:07:19.732226 24110 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0422 03:07:19.732233 24110 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0422 03:07:19.732273 24110 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0422 03:07:19.732283 24110 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 03:07:19.732290 24110 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 03:07:19.732295 24110 net.cpp:165] Memory required for data: 10172191164
I0422 03:07:19.732300 24110 layer_factory.hpp:77] Creating layer rpn_twin_pred
I0422 03:07:19.732324 24110 net.cpp:100] Creating Layer rpn_twin_pred
I0422 03:07:19.732331 24110 net.cpp:434] rpn_twin_pred <- rpn/output_pool_rpn/output_pool_0_split_1
I0422 03:07:19.732342 24110 net.cpp:408] rpn_twin_pred -> rpn_twin_pred
I0422 03:07:19.734375 24110 net.cpp:150] Setting up rpn_twin_pred
I0422 03:07:19.734390 24110 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 03:07:19.734396 24110 net.cpp:165] Memory required for data: 10172219580
I0422 03:07:19.734405 24110 layer_factory.hpp:77] Creating layer rpn_twin_pred_rpn_twin_pred_0_split
I0422 03:07:19.734413 24110 net.cpp:100] Creating Layer rpn_twin_pred_rpn_twin_pred_0_split
I0422 03:07:19.734426 24110 net.cpp:434] rpn_twin_pred_rpn_twin_pred_0_split <- rpn_twin_pred
I0422 03:07:19.734437 24110 net.cpp:408] rpn_twin_pred_rpn_twin_pred_0_split -> rpn_twin_pred_rpn_twin_pred_0_split_0
I0422 03:07:19.734448 24110 net.cpp:408] rpn_twin_pred_rpn_twin_pred_0_split -> rpn_twin_pred_rpn_twin_pred_0_split_1
I0422 03:07:19.734494 24110 net.cpp:150] Setting up rpn_twin_pred_rpn_twin_pred_0_split
I0422 03:07:19.734503 24110 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 03:07:19.734510 24110 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 03:07:19.734516 24110 net.cpp:165] Memory required for data: 10172276412
I0422 03:07:19.734521 24110 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0422 03:07:19.734539 24110 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0422 03:07:19.734545 24110 net.cpp:434] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0422 03:07:19.734555 24110 net.cpp:408] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0422 03:07:19.734589 24110 net.cpp:150] Setting up rpn_cls_score_reshape
I0422 03:07:19.734599 24110 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 03:07:19.734604 24110 net.cpp:165] Memory required for data: 10172304828
I0422 03:07:19.734609 24110 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 03:07:19.734619 24110 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 03:07:19.734627 24110 net.cpp:434] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0422 03:07:19.734637 24110 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0422 03:07:19.734653 24110 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0422 03:07:19.734661 24110 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_2
I0422 03:07:19.734709 24110 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 03:07:19.734719 24110 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 03:07:19.734725 24110 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 03:07:19.734733 24110 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 03:07:19.734738 24110 net.cpp:165] Memory required for data: 10172390076
I0422 03:07:19.734745 24110 layer_factory.hpp:77] Creating layer rpn-data
I0422 03:07:19.735183 24110 net.cpp:100] Creating Layer rpn-data
I0422 03:07:19.735198 24110 net.cpp:434] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0422 03:07:19.735205 24110 net.cpp:434] rpn-data <- gt_boxes_data_1_split_0
I0422 03:07:19.735213 24110 net.cpp:434] rpn-data <- data_data_0_split_1
I0422 03:07:19.735221 24110 net.cpp:408] rpn-data -> rpn_labels
I0422 03:07:19.735234 24110 net.cpp:408] rpn-data -> rpn_twin_targets
I0422 03:07:19.735244 24110 net.cpp:408] rpn-data -> rpn_twin_inside_weights
I0422 03:07:19.735255 24110 net.cpp:408] rpn-data -> rpn_twin_outside_weights
I0422 03:07:19.737507 24110 net.cpp:150] Setting up rpn-data
I0422 03:07:19.737524 24110 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 03:07:19.737529 24110 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 03:07:19.737536 24110 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 03:07:19.737545 24110 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 03:07:19.737550 24110 net.cpp:165] Memory required for data: 10172489532
I0422 03:07:19.737556 24110 layer_factory.hpp:77] Creating layer rpn_labels_rpn-data_0_split
I0422 03:07:19.737565 24110 net.cpp:100] Creating Layer rpn_labels_rpn-data_0_split
I0422 03:07:19.737572 24110 net.cpp:434] rpn_labels_rpn-data_0_split <- rpn_labels
I0422 03:07:19.737581 24110 net.cpp:408] rpn_labels_rpn-data_0_split -> rpn_labels_rpn-data_0_split_0
I0422 03:07:19.737592 24110 net.cpp:408] rpn_labels_rpn-data_0_split -> rpn_labels_rpn-data_0_split_1
I0422 03:07:19.737633 24110 net.cpp:150] Setting up rpn_labels_rpn-data_0_split
I0422 03:07:19.737643 24110 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 03:07:19.737650 24110 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 03:07:19.737655 24110 net.cpp:165] Memory required for data: 10172517948
I0422 03:07:19.737663 24110 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0422 03:07:19.737675 24110 net.cpp:100] Creating Layer rpn_loss_cls
I0422 03:07:19.737681 24110 net.cpp:434] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0422 03:07:19.737689 24110 net.cpp:434] rpn_loss_cls <- rpn_labels_rpn-data_0_split_0
I0422 03:07:19.737697 24110 net.cpp:408] rpn_loss_cls -> rpn_cls_loss
I0422 03:07:19.737713 24110 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0422 03:07:19.738165 24110 net.cpp:150] Setting up rpn_loss_cls
I0422 03:07:19.738179 24110 net.cpp:157] Top shape: (1)
I0422 03:07:19.738184 24110 net.cpp:160]     with loss weight 1
I0422 03:07:19.738201 24110 net.cpp:165] Memory required for data: 10172517952
I0422 03:07:19.738207 24110 layer_factory.hpp:77] Creating layer rpn_loss_twin
I0422 03:07:19.738220 24110 net.cpp:100] Creating Layer rpn_loss_twin
I0422 03:07:19.738226 24110 net.cpp:434] rpn_loss_twin <- rpn_twin_pred_rpn_twin_pred_0_split_0
I0422 03:07:19.738234 24110 net.cpp:434] rpn_loss_twin <- rpn_twin_targets
I0422 03:07:19.738241 24110 net.cpp:434] rpn_loss_twin <- rpn_twin_inside_weights
I0422 03:07:19.738247 24110 net.cpp:434] rpn_loss_twin <- rpn_twin_outside_weights
I0422 03:07:19.738257 24110 net.cpp:408] rpn_loss_twin -> rpn_loss_twin
I0422 03:07:19.738346 24110 net.cpp:150] Setting up rpn_loss_twin
I0422 03:07:19.738358 24110 net.cpp:157] Top shape: (1)
I0422 03:07:19.738363 24110 net.cpp:160]     with loss weight 1
I0422 03:07:19.738370 24110 net.cpp:165] Memory required for data: 10172517956
I0422 03:07:19.738376 24110 layer_factory.hpp:77] Creating layer rpn_accuarcy
I0422 03:07:19.738390 24110 net.cpp:100] Creating Layer rpn_accuarcy
I0422 03:07:19.738399 24110 net.cpp:434] rpn_accuarcy <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0422 03:07:19.738405 24110 net.cpp:434] rpn_accuarcy <- rpn_labels_rpn-data_0_split_1
I0422 03:07:19.738414 24110 net.cpp:408] rpn_accuarcy -> rpn_accuarcy
I0422 03:07:19.738423 24110 net.cpp:408] rpn_accuarcy -> rpn_accuarcy_class
I0422 03:07:19.738468 24110 net.cpp:150] Setting up rpn_accuarcy
I0422 03:07:19.738477 24110 net.cpp:157] Top shape: (1)
I0422 03:07:19.738483 24110 net.cpp:157] Top shape: 2 (2)
I0422 03:07:19.738489 24110 net.cpp:165] Memory required for data: 10172517968
I0422 03:07:19.738495 24110 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0422 03:07:19.738503 24110 net.cpp:100] Creating Layer rpn_cls_prob
I0422 03:07:19.738510 24110 net.cpp:434] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_2
I0422 03:07:19.738518 24110 net.cpp:408] rpn_cls_prob -> rpn_cls_prob
I0422 03:07:19.738719 24110 net.cpp:150] Setting up rpn_cls_prob
I0422 03:07:19.738730 24110 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 03:07:19.738736 24110 net.cpp:165] Memory required for data: 10172546384
I0422 03:07:19.738742 24110 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0422 03:07:19.738752 24110 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0422 03:07:19.738759 24110 net.cpp:434] rpn_cls_prob_reshape <- rpn_cls_prob
I0422 03:07:19.738795 24110 net.cpp:408] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0422 03:07:19.738823 24110 net.cpp:150] Setting up rpn_cls_prob_reshape
I0422 03:07:19.738833 24110 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 03:07:19.738838 24110 net.cpp:165] Memory required for data: 10172574800
I0422 03:07:19.738842 24110 layer_factory.hpp:77] Creating layer proposal
I0422 03:07:19.739414 24110 net.cpp:100] Creating Layer proposal
I0422 03:07:19.739428 24110 net.cpp:434] proposal <- rpn_cls_prob_reshape
I0422 03:07:19.739435 24110 net.cpp:434] proposal <- rpn_twin_pred_rpn_twin_pred_0_split_1
I0422 03:07:19.739444 24110 net.cpp:408] proposal -> rpn_rois
I0422 03:07:19.741637 24110 net.cpp:150] Setting up proposal
I0422 03:07:19.741652 24110 net.cpp:157] Top shape: 1 3 (3)
I0422 03:07:19.741658 24110 net.cpp:165] Memory required for data: 10172574812
I0422 03:07:19.741664 24110 layer_factory.hpp:77] Creating layer roi-data
I0422 03:07:19.741806 24110 net.cpp:100] Creating Layer roi-data
I0422 03:07:19.741818 24110 net.cpp:434] roi-data <- rpn_rois
I0422 03:07:19.741825 24110 net.cpp:434] roi-data <- gt_boxes_data_1_split_1
I0422 03:07:19.741835 24110 net.cpp:408] roi-data -> rois
I0422 03:07:19.741847 24110 net.cpp:408] roi-data -> labels
I0422 03:07:19.741858 24110 net.cpp:408] roi-data -> twin_targets
I0422 03:07:19.741868 24110 net.cpp:408] roi-data -> twin_inside_weights
I0422 03:07:19.741876 24110 net.cpp:408] roi-data -> twin_outside_weights
('sampling method:', 'Random')
I0422 03:07:19.742210 24110 net.cpp:150] Setting up roi-data
I0422 03:07:19.742223 24110 net.cpp:157] Top shape: 1 3 (3)
I0422 03:07:19.742230 24110 net.cpp:157] Top shape: 1 200 (200)
I0422 03:07:19.742238 24110 net.cpp:157] Top shape: 1 400 (400)
I0422 03:07:19.742244 24110 net.cpp:157] Top shape: 1 400 (400)
I0422 03:07:19.742250 24110 net.cpp:157] Top shape: 1 400 (400)
I0422 03:07:19.742255 24110 net.cpp:165] Memory required for data: 10172580424
I0422 03:07:19.742262 24110 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0422 03:07:19.742270 24110 net.cpp:100] Creating Layer labels_roi-data_1_split
I0422 03:07:19.742277 24110 net.cpp:434] labels_roi-data_1_split <- labels
I0422 03:07:19.742285 24110 net.cpp:408] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0422 03:07:19.742297 24110 net.cpp:408] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0422 03:07:19.742336 24110 net.cpp:150] Setting up labels_roi-data_1_split
I0422 03:07:19.742344 24110 net.cpp:157] Top shape: 1 200 (200)
I0422 03:07:19.742350 24110 net.cpp:157] Top shape: 1 200 (200)
I0422 03:07:19.742357 24110 net.cpp:165] Memory required for data: 10172582024
I0422 03:07:19.742362 24110 layer_factory.hpp:77] Creating layer roi_pool5
I0422 03:07:19.742377 24110 net.cpp:100] Creating Layer roi_pool5
I0422 03:07:19.742383 24110 net.cpp:434] roi_pool5 <- conv5b_relu5b_0_split_1
I0422 03:07:19.742389 24110 net.cpp:434] roi_pool5 <- rois
I0422 03:07:19.742398 24110 net.cpp:408] roi_pool5 -> pool5
I0422 03:07:19.742410 24110 roi_pooling_layer.cpp:34] Temporal scale: 0.125
I0422 03:07:19.742419 24110 roi_pooling_layer.cpp:35] Spatial scale: 0.0625
I0422 03:07:19.742460 24110 net.cpp:150] Setting up roi_pool5
I0422 03:07:19.742468 24110 net.cpp:157] Top shape: 1 512 1 4 4 (8192)
I0422 03:07:19.742473 24110 net.cpp:165] Memory required for data: 10172614792
I0422 03:07:19.742480 24110 layer_factory.hpp:77] Creating layer fc6
I0422 03:07:19.742492 24110 net.cpp:100] Creating Layer fc6
I0422 03:07:19.742498 24110 net.cpp:434] fc6 <- pool5
I0422 03:07:19.742508 24110 net.cpp:408] fc6 -> fc6
I0422 03:07:20.765172 24110 net.cpp:150] Setting up fc6
I0422 03:07:20.765199 24110 net.cpp:157] Top shape: 1 4096 (4096)
I0422 03:07:20.765205 24110 net.cpp:165] Memory required for data: 10172631176
I0422 03:07:20.765218 24110 layer_factory.hpp:77] Creating layer relu6
I0422 03:07:20.765231 24110 net.cpp:100] Creating Layer relu6
I0422 03:07:20.765240 24110 net.cpp:434] relu6 <- fc6
I0422 03:07:20.765249 24110 net.cpp:395] relu6 -> fc6 (in-place)
I0422 03:07:20.765781 24110 net.cpp:150] Setting up relu6
I0422 03:07:20.765797 24110 net.cpp:157] Top shape: 1 4096 (4096)
I0422 03:07:20.765805 24110 net.cpp:165] Memory required for data: 10172647560
I0422 03:07:20.765812 24110 layer_factory.hpp:77] Creating layer drop6
I0422 03:07:20.765832 24110 net.cpp:100] Creating Layer drop6
I0422 03:07:20.765838 24110 net.cpp:434] drop6 <- fc6
I0422 03:07:20.765848 24110 net.cpp:395] drop6 -> fc6 (in-place)
I0422 03:07:20.765892 24110 net.cpp:150] Setting up drop6
I0422 03:07:20.765902 24110 net.cpp:157] Top shape: 1 4096 (4096)
I0422 03:07:20.765908 24110 net.cpp:165] Memory required for data: 10172663944
I0422 03:07:20.765913 24110 layer_factory.hpp:77] Creating layer fc6_drop6_0_split
I0422 03:07:20.765921 24110 net.cpp:100] Creating Layer fc6_drop6_0_split
I0422 03:07:20.765926 24110 net.cpp:434] fc6_drop6_0_split <- fc6
I0422 03:07:20.765934 24110 net.cpp:408] fc6_drop6_0_split -> fc6_drop6_0_split_0
I0422 03:07:20.765945 24110 net.cpp:408] fc6_drop6_0_split -> fc6_drop6_0_split_1
I0422 03:07:20.765990 24110 net.cpp:150] Setting up fc6_drop6_0_split
I0422 03:07:20.765998 24110 net.cpp:157] Top shape: 1 4096 (4096)
I0422 03:07:20.766005 24110 net.cpp:157] Top shape: 1 4096 (4096)
I0422 03:07:20.766011 24110 net.cpp:165] Memory required for data: 10172696712
I0422 03:07:20.766017 24110 layer_factory.hpp:77] Creating layer cls_score
I0422 03:07:20.766027 24110 net.cpp:100] Creating Layer cls_score
I0422 03:07:20.766033 24110 net.cpp:434] cls_score <- fc6_drop6_0_split_0
I0422 03:07:20.766043 24110 net.cpp:408] cls_score -> cls_score
I0422 03:07:20.790609 24110 net.cpp:150] Setting up cls_score
I0422 03:07:20.790637 24110 net.cpp:157] Top shape: 1 200 (200)
I0422 03:07:20.790642 24110 net.cpp:165] Memory required for data: 10172697512
I0422 03:07:20.790654 24110 layer_factory.hpp:77] Creating layer cls_score_cls_score_0_split
I0422 03:07:20.790670 24110 net.cpp:100] Creating Layer cls_score_cls_score_0_split
I0422 03:07:20.790678 24110 net.cpp:434] cls_score_cls_score_0_split <- cls_score
I0422 03:07:20.790688 24110 net.cpp:408] cls_score_cls_score_0_split -> cls_score_cls_score_0_split_0
I0422 03:07:20.790701 24110 net.cpp:408] cls_score_cls_score_0_split -> cls_score_cls_score_0_split_1
I0422 03:07:20.790745 24110 net.cpp:150] Setting up cls_score_cls_score_0_split
I0422 03:07:20.790755 24110 net.cpp:157] Top shape: 1 200 (200)
I0422 03:07:20.790791 24110 net.cpp:157] Top shape: 1 200 (200)
I0422 03:07:20.790798 24110 net.cpp:165] Memory required for data: 10172699112
I0422 03:07:20.790803 24110 layer_factory.hpp:77] Creating layer twin_pred
I0422 03:07:20.790817 24110 net.cpp:100] Creating Layer twin_pred
I0422 03:07:20.790823 24110 net.cpp:434] twin_pred <- fc6_drop6_0_split_1
I0422 03:07:20.790833 24110 net.cpp:408] twin_pred -> twin_pred
I0422 03:07:20.841786 24110 net.cpp:150] Setting up twin_pred
I0422 03:07:20.841845 24110 net.cpp:157] Top shape: 1 400 (400)
I0422 03:07:20.841861 24110 net.cpp:165] Memory required for data: 10172700712
I0422 03:07:20.841881 24110 layer_factory.hpp:77] Creating layer loss_cls
I0422 03:07:20.841908 24110 net.cpp:100] Creating Layer loss_cls
I0422 03:07:20.841924 24110 net.cpp:434] loss_cls <- cls_score_cls_score_0_split_0
I0422 03:07:20.841941 24110 net.cpp:434] loss_cls <- labels_roi-data_1_split_0
I0422 03:07:20.841959 24110 net.cpp:408] loss_cls -> loss_cls
I0422 03:07:20.842051 24110 net.cpp:150] Setting up loss_cls
I0422 03:07:20.842073 24110 net.cpp:157] Top shape: (1)
I0422 03:07:20.842098 24110 net.cpp:160]     with loss weight 1
I0422 03:07:20.842121 24110 net.cpp:165] Memory required for data: 10172700716
I0422 03:07:20.842135 24110 layer_factory.hpp:77] Creating layer loss_twin
I0422 03:07:20.842151 24110 net.cpp:100] Creating Layer loss_twin
I0422 03:07:20.842166 24110 net.cpp:434] loss_twin <- twin_pred
I0422 03:07:20.842181 24110 net.cpp:434] loss_twin <- twin_targets
I0422 03:07:20.842197 24110 net.cpp:434] loss_twin <- twin_inside_weights
I0422 03:07:20.842213 24110 net.cpp:434] loss_twin <- twin_outside_weights
I0422 03:07:20.842229 24110 net.cpp:408] loss_twin -> loss_twin
I0422 03:07:20.842370 24110 net.cpp:150] Setting up loss_twin
I0422 03:07:20.842396 24110 net.cpp:157] Top shape: (1)
I0422 03:07:20.842409 24110 net.cpp:160]     with loss weight 1
I0422 03:07:20.842425 24110 net.cpp:165] Memory required for data: 10172700720
I0422 03:07:20.842438 24110 layer_factory.hpp:77] Creating layer accuracy
I0422 03:07:20.842728 24110 net.cpp:100] Creating Layer accuracy
I0422 03:07:20.842756 24110 net.cpp:434] accuracy <- cls_score_cls_score_0_split_1
I0422 03:07:20.842814 24110 net.cpp:434] accuracy <- labels_roi-data_1_split_1
I0422 03:07:20.842835 24110 net.cpp:408] accuracy -> accuracy
I0422 03:07:20.842965 24110 net.cpp:150] Setting up accuracy
I0422 03:07:20.842993 24110 net.cpp:157] Top shape: 1 (1)
I0422 03:07:20.843006 24110 net.cpp:165] Memory required for data: 10172700724
I0422 03:07:20.843019 24110 net.cpp:228] accuracy does not need backward computation.
I0422 03:07:20.843032 24110 net.cpp:226] loss_twin needs backward computation.
I0422 03:07:20.843045 24110 net.cpp:226] loss_cls needs backward computation.
I0422 03:07:20.843060 24110 net.cpp:226] twin_pred needs backward computation.
I0422 03:07:20.843073 24110 net.cpp:226] cls_score_cls_score_0_split needs backward computation.
I0422 03:07:20.843087 24110 net.cpp:226] cls_score needs backward computation.
I0422 03:07:20.843101 24110 net.cpp:226] fc6_drop6_0_split needs backward computation.
I0422 03:07:20.843113 24110 net.cpp:226] drop6 needs backward computation.
I0422 03:07:20.843128 24110 net.cpp:226] relu6 needs backward computation.
I0422 03:07:20.843142 24110 net.cpp:226] fc6 needs backward computation.
I0422 03:07:20.843155 24110 net.cpp:226] roi_pool5 needs backward computation.
I0422 03:07:20.843170 24110 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0422 03:07:20.843185 24110 net.cpp:226] roi-data needs backward computation.
I0422 03:07:20.843199 24110 net.cpp:226] proposal needs backward computation.
I0422 03:07:20.843214 24110 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0422 03:07:20.843228 24110 net.cpp:226] rpn_cls_prob needs backward computation.
I0422 03:07:20.843242 24110 net.cpp:228] rpn_accuarcy does not need backward computation.
I0422 03:07:20.843256 24110 net.cpp:226] rpn_loss_twin needs backward computation.
I0422 03:07:20.843273 24110 net.cpp:226] rpn_loss_cls needs backward computation.
I0422 03:07:20.843288 24110 net.cpp:228] rpn_labels_rpn-data_0_split does not need backward computation.
I0422 03:07:20.843303 24110 net.cpp:226] rpn-data needs backward computation.
I0422 03:07:20.843319 24110 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0422 03:07:20.843331 24110 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0422 03:07:20.843344 24110 net.cpp:226] rpn_twin_pred_rpn_twin_pred_0_split needs backward computation.
I0422 03:07:20.843358 24110 net.cpp:226] rpn_twin_pred needs backward computation.
I0422 03:07:20.843372 24110 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0422 03:07:20.843387 24110 net.cpp:226] rpn_cls_score needs backward computation.
I0422 03:07:20.843401 24110 net.cpp:226] rpn/output_pool_rpn/output_pool_0_split needs backward computation.
I0422 03:07:20.843415 24110 net.cpp:226] rpn/output_pool needs backward computation.
I0422 03:07:20.843430 24110 net.cpp:226] rpn_relu/3x3_2 needs backward computation.
I0422 03:07:20.843447 24110 net.cpp:226] rpn_conv/3x3_2 needs backward computation.
I0422 03:07:20.843461 24110 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0422 03:07:20.843477 24110 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0422 03:07:20.843490 24110 net.cpp:226] conv5b_relu5b_0_split needs backward computation.
I0422 03:07:20.843504 24110 net.cpp:226] relu5b needs backward computation.
I0422 03:07:20.843516 24110 net.cpp:226] conv5b needs backward computation.
I0422 03:07:20.843528 24110 net.cpp:226] relu5a needs backward computation.
I0422 03:07:20.843541 24110 net.cpp:226] conv5a needs backward computation.
I0422 03:07:20.843554 24110 net.cpp:226] pool4 needs backward computation.
I0422 03:07:20.843566 24110 net.cpp:226] relu4b needs backward computation.
I0422 03:07:20.843578 24110 net.cpp:226] conv4b needs backward computation.
I0422 03:07:20.843590 24110 net.cpp:226] relu4a needs backward computation.
I0422 03:07:20.843603 24110 net.cpp:226] conv4a needs backward computation.
I0422 03:07:20.843616 24110 net.cpp:226] pool3 needs backward computation.
I0422 03:07:20.843628 24110 net.cpp:226] relu3b needs backward computation.
I0422 03:07:20.843641 24110 net.cpp:226] conv3b needs backward computation.
I0422 03:07:20.843657 24110 net.cpp:226] relu3a needs backward computation.
I0422 03:07:20.843669 24110 net.cpp:226] conv3a needs backward computation.
I0422 03:07:20.843681 24110 net.cpp:228] pool2 does not need backward computation.
I0422 03:07:20.843694 24110 net.cpp:228] relu2a does not need backward computation.
I0422 03:07:20.843708 24110 net.cpp:228] conv2a does not need backward computation.
I0422 03:07:20.843720 24110 net.cpp:228] pool1 does not need backward computation.
I0422 03:07:20.843732 24110 net.cpp:228] relu1a does not need backward computation.
I0422 03:07:20.843745 24110 net.cpp:228] conv1a does not need backward computation.
I0422 03:07:20.843760 24110 net.cpp:228] gt_boxes_data_1_split does not need backward computation.
I0422 03:07:20.843773 24110 net.cpp:228] data_data_0_split does not need backward computation.
I0422 03:07:20.843786 24110 net.cpp:228] data does not need backward computation.
I0422 03:07:20.843798 24110 net.cpp:270] This network produces output accuracy
I0422 03:07:20.843811 24110 net.cpp:270] This network produces output loss_cls
I0422 03:07:20.843824 24110 net.cpp:270] This network produces output loss_twin
I0422 03:07:20.843837 24110 net.cpp:270] This network produces output rpn_accuarcy
I0422 03:07:20.843849 24110 net.cpp:270] This network produces output rpn_accuarcy_class
I0422 03:07:20.843863 24110 net.cpp:270] This network produces output rpn_cls_loss
I0422 03:07:20.843875 24110 net.cpp:270] This network produces output rpn_loss_twin
I0422 03:07:20.843932 24110 net.cpp:283] Network initialization done.
I0422 03:07:20.844117 24110 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from ./pretrain/activitynet_iter_30000_3fps.caffemodel
I0422 03:07:24.524782 24110 net.cpp:761] Ignoring source layer pool5
I0422 03:07:24.547386 24110 net.cpp:761] Ignoring source layer fc7
I0422 03:07:24.547413 24110 net.cpp:761] Ignoring source layer relu7
I0422 03:07:24.547416 24110 net.cpp:761] Ignoring source layer drop7
I0422 03:07:24.547420 24110 net.cpp:761] Ignoring source layer fc8-200
I0422 03:07:24.547422 24110 net.cpp:761] Ignoring source layer loss
Solving...
rpn: num_positive 6
rpn: num_negative 58
I0422 03:07:27.958735 24110 accuracy_layer.cpp:96] Accuracy: 0.609375
I0422 03:07:27.958757 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.637931
I0422 03:07:27.958791 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 11
num bg: 26
('accuracy: ', 0.0)
I0422 03:07:28.014010 24110 solver.cpp:228] Iteration 0, loss = 161.478
I0422 03:07:28.014034 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:07:28.014044 24110 solver.cpp:244]     Train net output #1: loss_cls = 160.76 (* 1 = 160.76 loss)
I0422 03:07:28.014050 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:07:28.014053 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.609375
I0422 03:07:28.014057 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.637931
I0422 03:07:28.014060 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 03:07:28.014065 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.685242 (* 1 = 0.685242 loss)
I0422 03:07:28.014070 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0335409 (* 1 = 0.0335409 loss)
I0422 03:07:28.014078 24110 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:07:32.537178 24110 accuracy_layer.cpp:96] Accuracy: 0.71875
I0422 03:07:32.537200 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.706897
I0422 03:07:32.537205 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
num fg: 12
num bg: 24
('accuracy: ', 0.0)
I0422 03:07:32.555356 24110 solver.cpp:228] Iteration 1, loss = 149.393
I0422 03:07:32.555379 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:07:32.555388 24110 solver.cpp:244]     Train net output #1: loss_cls = 148.696 (* 1 = 148.696 loss)
I0422 03:07:32.555393 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:07:32.555398 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.71875
I0422 03:07:32.555402 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.706897
I0422 03:07:32.555407 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 03:07:32.555410 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.674564 (* 1 = 0.674564 loss)
I0422 03:07:32.555416 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0225683 (* 1 = 0.0225683 loss)
I0422 03:07:32.555421 24110 sgd_solver.cpp:106] Iteration 1, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:07:37.310644 24110 accuracy_layer.cpp:96] Accuracy: 0.640625
I0422 03:07:37.310665 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.655172
I0422 03:07:37.310669 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 10
num bg: 22
('accuracy: ', 0.0)
I0422 03:07:37.328683 24110 solver.cpp:228] Iteration 2, loss = 129.54
I0422 03:07:37.328701 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:07:37.328709 24110 solver.cpp:244]     Train net output #1: loss_cls = 128.837 (* 1 = 128.837 loss)
I0422 03:07:37.328716 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:07:37.328723 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.640625
I0422 03:07:37.328728 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.655172
I0422 03:07:37.328732 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 03:07:37.328740 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.674749 (* 1 = 0.674749 loss)
I0422 03:07:37.328745 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0283467 (* 1 = 0.0283467 loss)
I0422 03:07:37.328752 24110 sgd_solver.cpp:106] Iteration 2, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:07:41.844010 24110 accuracy_layer.cpp:96] Accuracy: 0.5
I0422 03:07:41.844033 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.482759
I0422 03:07:41.844038 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
num fg: 10
num bg: 24
('accuracy: ', 0.0)
I0422 03:07:41.861796 24110 solver.cpp:228] Iteration 3, loss = 96.06
I0422 03:07:41.861816 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:07:41.861825 24110 solver.cpp:244]     Train net output #1: loss_cls = 95.3071 (* 1 = 95.3071 loss)
I0422 03:07:41.861831 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:07:41.861840 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.5
I0422 03:07:41.861843 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.482759
I0422 03:07:41.861846 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 03:07:41.861855 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.715902 (* 1 = 0.715902 loss)
I0422 03:07:41.861860 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0370219 (* 1 = 0.0370219 loss)
I0422 03:07:41.861865 24110 sgd_solver.cpp:106] Iteration 3, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:07:46.656904 24110 accuracy_layer.cpp:96] Accuracy: 0.5625
I0422 03:07:46.656926 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.534483
I0422 03:07:46.656930 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
num fg: 10
num bg: 20
('accuracy: ', 0.0)
I0422 03:07:46.674868 24110 solver.cpp:228] Iteration 4, loss = 43.0684
I0422 03:07:46.674896 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:07:46.674903 24110 solver.cpp:244]     Train net output #1: loss_cls = 42.305 (* 1 = 42.305 loss)
I0422 03:07:46.674909 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:07:46.674914 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.5625
I0422 03:07:46.674918 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.534483
I0422 03:07:46.674923 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 03:07:46.674927 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.686657 (* 1 = 0.686657 loss)
I0422 03:07:46.674933 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0768207 (* 1 = 0.0768207 loss)
I0422 03:07:46.674939 24110 sgd_solver.cpp:106] Iteration 4, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:07:51.226522 24110 accuracy_layer.cpp:96] Accuracy: 0.4375
I0422 03:07:51.226547 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.396552
I0422 03:07:51.226550 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 03:07:51.281517 24110 solver.cpp:228] Iteration 5, loss = 6.48048
I0422 03:07:51.281539 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:07:51.281548 24110 solver.cpp:244]     Train net output #1: loss_cls = 5.32575 (* 1 = 5.32575 loss)
I0422 03:07:51.281553 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:07:51.281556 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.4375
I0422 03:07:51.281560 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.396552
I0422 03:07:51.281564 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 03:07:51.281569 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.965074 (* 1 = 0.965074 loss)
I0422 03:07:51.281574 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.189659 (* 1 = 0.189659 loss)
I0422 03:07:51.281579 24110 sgd_solver.cpp:106] Iteration 5, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 03:07:56.029913 24110 accuracy_layer.cpp:96] Accuracy: 0.484375
I0422 03:07:56.029935 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.45
I0422 03:07:56.029940 24110 accuracy_layer.cpp:101] Class 1 accuracy : 1
TRAIN
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 03:07:56.052311 24110 solver.cpp:228] Iteration 6, loss = 9.2607
I0422 03:07:56.052337 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:07:56.052345 24110 solver.cpp:244]     Train net output #1: loss_cls = 7.77738 (* 1 = 7.77738 loss)
I0422 03:07:56.052351 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:07:56.052356 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.484375
I0422 03:07:56.052359 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.45
I0422 03:07:56.052363 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 1
I0422 03:07:56.052367 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 1.17059 (* 1 = 1.17059 loss)
I0422 03:07:56.052372 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.312727 (* 1 = 0.312727 loss)
I0422 03:07:56.052378 24110 sgd_solver.cpp:106] Iteration 6, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:00.897358 24110 accuracy_layer.cpp:96] Accuracy: 0.53125
I0422 03:08:00.897387 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.568965
I0422 03:08:00.897392 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 6
num bg: 20
('accuracy: ', 0.0)
I0422 03:08:00.952136 24110 solver.cpp:228] Iteration 7, loss = 13.5209
I0422 03:08:00.952170 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:00.952179 24110 solver.cpp:244]     Train net output #1: loss_cls = 10.938 (* 1 = 10.938 loss)
I0422 03:08:00.952186 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:00.952190 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.53125
I0422 03:08:00.952194 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.568965
I0422 03:08:00.952198 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 03:08:00.952203 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 1.98372 (* 1 = 1.98372 loss)
I0422 03:08:00.952208 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.599169 (* 1 = 0.599169 loss)
I0422 03:08:00.952215 24110 sgd_solver.cpp:106] Iteration 7, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 03:08:05.722626 24110 accuracy_layer.cpp:96] Accuracy: 0.78125
I0422 03:08:05.722648 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.786885
I0422 03:08:05.722653 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
num fg: 7
num bg: 24
('accuracy: ', 0.0)
I0422 03:08:05.741585 24110 solver.cpp:228] Iteration 8, loss = 38.0113
I0422 03:08:05.741603 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:05.741611 24110 solver.cpp:244]     Train net output #1: loss_cls = 36.1794 (* 1 = 36.1794 loss)
I0422 03:08:05.741617 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:05.741621 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.78125
I0422 03:08:05.741626 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.786885
I0422 03:08:05.741629 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 03:08:05.741634 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 1.40041 (* 1 = 1.40041 loss)
I0422 03:08:05.741638 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.431554 (* 1 = 0.431554 loss)
I0422 03:08:05.741643 24110 sgd_solver.cpp:106] Iteration 8, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:10.761822 24110 accuracy_layer.cpp:96] Accuracy: 0.84375
I0422 03:08:10.761847 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.87931
I0422 03:08:10.761852 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 8
num bg: 23
('accuracy: ', 0.0)
I0422 03:08:10.780952 24110 solver.cpp:228] Iteration 9, loss = 53.0225
I0422 03:08:10.780975 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:10.780984 24110 solver.cpp:244]     Train net output #1: loss_cls = 52.1295 (* 1 = 52.1295 loss)
I0422 03:08:10.780990 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:10.780997 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.84375
I0422 03:08:10.781002 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.87931
I0422 03:08:10.781008 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 03:08:10.781011 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.589602 (* 1 = 0.589602 loss)
I0422 03:08:10.781018 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.303386 (* 1 = 0.303386 loss)
I0422 03:08:10.781024 24110 sgd_solver.cpp:106] Iteration 9, lr = 0.0001
speed: 4.621s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:15.441145 24110 accuracy_layer.cpp:96] Accuracy: 0.75
I0422 03:08:15.441165 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.775862
I0422 03:08:15.441169 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 11
num bg: 31
('accuracy: ', 0.0)
I0422 03:08:15.464612 24110 solver.cpp:228] Iteration 10, loss = 6.55835
I0422 03:08:15.464643 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:15.464651 24110 solver.cpp:244]     Train net output #1: loss_cls = 5.7503 (* 1 = 5.7503 loss)
I0422 03:08:15.464658 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:15.464661 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.75
I0422 03:08:15.464665 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.775862
I0422 03:08:15.464676 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 03:08:15.464681 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.661366 (* 1 = 0.661366 loss)
I0422 03:08:15.464689 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.146692 (* 1 = 0.146692 loss)
I0422 03:08:15.464694 24110 sgd_solver.cpp:106] Iteration 10, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:20.391551 24110 accuracy_layer.cpp:96] Accuracy: 0.6875
I0422 03:08:20.391572 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.724138
I0422 03:08:20.391577 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 03:08:20.410701 24110 solver.cpp:228] Iteration 11, loss = 3.53824
I0422 03:08:20.410718 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:20.410727 24110 solver.cpp:244]     Train net output #1: loss_cls = 3.01199 (* 1 = 3.01199 loss)
I0422 03:08:20.410732 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:20.410737 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.6875
I0422 03:08:20.410740 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.724138
I0422 03:08:20.410744 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 03:08:20.410754 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.501703 (* 1 = 0.501703 loss)
I0422 03:08:20.410775 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0245435 (* 1 = 0.0245435 loss)
I0422 03:08:20.410784 24110 sgd_solver.cpp:106] Iteration 11, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:25.031585 24110 accuracy_layer.cpp:96] Accuracy: 0.8125
I0422 03:08:25.031608 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.862069
I0422 03:08:25.031612 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 10
num bg: 28
('accuracy: ', 0.0)
I0422 03:08:25.053726 24110 solver.cpp:228] Iteration 12, loss = 6.91312
I0422 03:08:25.053751 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:25.053761 24110 solver.cpp:244]     Train net output #1: loss_cls = 6.29313 (* 1 = 6.29313 loss)
I0422 03:08:25.053766 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:25.053769 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.8125
I0422 03:08:25.053774 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.862069
I0422 03:08:25.053778 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 03:08:25.053782 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.602869 (* 1 = 0.602869 loss)
I0422 03:08:25.053787 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0171273 (* 1 = 0.0171273 loss)
I0422 03:08:25.053793 24110 sgd_solver.cpp:106] Iteration 12, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:29.944922 24110 accuracy_layer.cpp:96] Accuracy: 0.734375
I0422 03:08:29.944953 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.775862
I0422 03:08:29.944957 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 03:08:29.968394 24110 solver.cpp:228] Iteration 13, loss = 5.34009
I0422 03:08:29.968420 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:29.968428 24110 solver.cpp:244]     Train net output #1: loss_cls = 4.72953 (* 1 = 4.72953 loss)
I0422 03:08:29.968435 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:29.968438 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.734375
I0422 03:08:29.968443 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.775862
I0422 03:08:29.968446 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 03:08:29.968451 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.587988 (* 1 = 0.587988 loss)
I0422 03:08:29.968456 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0225693 (* 1 = 0.0225693 loss)
I0422 03:08:29.968467 24110 sgd_solver.cpp:106] Iteration 13, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:34.588928 24110 accuracy_layer.cpp:96] Accuracy: 0.8125
I0422 03:08:34.588949 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.87931
I0422 03:08:34.588953 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 10
num bg: 30
('accuracy: ', 0.0)
I0422 03:08:34.607969 24110 solver.cpp:228] Iteration 14, loss = 3.83273
I0422 03:08:34.607988 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:34.608002 24110 solver.cpp:244]     Train net output #1: loss_cls = 3.21909 (* 1 = 3.21909 loss)
I0422 03:08:34.608011 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:34.608016 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.8125
I0422 03:08:34.608021 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.87931
I0422 03:08:34.608024 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 03:08:34.608029 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.589317 (* 1 = 0.589317 loss)
I0422 03:08:34.608034 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0243256 (* 1 = 0.0243256 loss)
I0422 03:08:34.608044 24110 sgd_solver.cpp:106] Iteration 14, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:39.506974 24110 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 03:08:39.507017 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.913793
I0422 03:08:39.507025 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 7
num bg: 30
('accuracy: ', 0.0)
I0422 03:08:39.528198 24110 solver.cpp:228] Iteration 15, loss = 2.96237
I0422 03:08:39.528229 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:39.528241 24110 solver.cpp:244]     Train net output #1: loss_cls = 2.36643 (* 1 = 2.36643 loss)
I0422 03:08:39.528250 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:39.528257 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 03:08:39.528264 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.913793
I0422 03:08:39.528270 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 03:08:39.528278 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.570239 (* 1 = 0.570239 loss)
I0422 03:08:39.528286 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0257007 (* 1 = 0.0257007 loss)
I0422 03:08:39.528295 24110 sgd_solver.cpp:106] Iteration 15, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:44.142841 24110 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 03:08:44.142863 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.896552
I0422 03:08:44.142877 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
num fg: 13
num bg: 26
('accuracy: ', 0.0)
I0422 03:08:44.162112 24110 solver.cpp:228] Iteration 16, loss = 2.98962
I0422 03:08:44.162129 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:44.162148 24110 solver.cpp:244]     Train net output #1: loss_cls = 2.38377 (* 1 = 2.38377 loss)
I0422 03:08:44.162153 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:44.162158 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 03:08:44.162163 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.896552
I0422 03:08:44.162165 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 03:08:44.162169 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.558207 (* 1 = 0.558207 loss)
I0422 03:08:44.162175 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0476429 (* 1 = 0.0476429 loss)
I0422 03:08:44.162180 24110 sgd_solver.cpp:106] Iteration 16, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:49.068819 24110 accuracy_layer.cpp:96] Accuracy: 0.890625
I0422 03:08:49.068845 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.931035
I0422 03:08:49.068848 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 13
num bg: 28
('accuracy: ', 0.0)
I0422 03:08:49.088912 24110 solver.cpp:228] Iteration 17, loss = 4.29298
I0422 03:08:49.088933 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:49.088943 24110 solver.cpp:244]     Train net output #1: loss_cls = 3.75183 (* 1 = 3.75183 loss)
I0422 03:08:49.088948 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:49.088953 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.890625
I0422 03:08:49.088958 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.931035
I0422 03:08:49.088963 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 03:08:49.088968 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.493672 (* 1 = 0.493672 loss)
I0422 03:08:49.088973 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0474773 (* 1 = 0.0474773 loss)
I0422 03:08:49.088979 24110 sgd_solver.cpp:106] Iteration 17, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:53.706753 24110 accuracy_layer.cpp:96] Accuracy: 0.828125
I0422 03:08:53.706802 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.862069
I0422 03:08:53.706809 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 03:08:53.725824 24110 solver.cpp:228] Iteration 18, loss = 2.76976
I0422 03:08:53.725843 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:53.725852 24110 solver.cpp:244]     Train net output #1: loss_cls = 2.21844 (* 1 = 2.21844 loss)
I0422 03:08:53.725857 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:53.725860 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.828125
I0422 03:08:53.725864 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.862069
I0422 03:08:53.725869 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 03:08:53.725873 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.494782 (* 1 = 0.494782 loss)
I0422 03:08:53.725879 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0565383 (* 1 = 0.0565383 loss)
I0422 03:08:53.725884 24110 sgd_solver.cpp:106] Iteration 18, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:08:58.616511 24110 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 03:08:58.616534 24110 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 03:08:58.616541 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 03:08:58.635951 24110 solver.cpp:228] Iteration 19, loss = 3.5302
I0422 03:08:58.635984 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:08:58.635996 24110 solver.cpp:244]     Train net output #1: loss_cls = 2.98832 (* 1 = 2.98832 loss)
I0422 03:08:58.636005 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:08:58.636016 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 03:08:58.636027 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 03:08:58.636037 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 03:08:58.636049 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.469314 (* 1 = 0.469314 loss)
I0422 03:08:58.636061 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.072566 (* 1 = 0.072566 loss)
I0422 03:08:58.636072 24110 sgd_solver.cpp:106] Iteration 19, lr = 0.0001
speed: 4.703s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 03:09:03.238234 24110 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 03:09:03.238256 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.913793
I0422 03:09:03.238260 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 03:09:03.256639 24110 solver.cpp:228] Iteration 20, loss = 3.17523
I0422 03:09:03.256656 24110 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 03:09:03.256664 24110 solver.cpp:244]     Train net output #1: loss_cls = 2.64682 (* 1 = 2.64682 loss)
I0422 03:09:03.256669 24110 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 03:09:03.256677 24110 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 03:09:03.256681 24110 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.913793
I0422 03:09:03.256685 24110 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 03:09:03.256690 24110 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.480471 (* 1 = 0.480471 loss)
I0422 03:09:03.256696 24110 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0479318 (* 1 = 0.0479318 loss)
I0422 03:09:03.256702 24110 sgd_solver.cpp:106] Iteration 20, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 03:09:08.133554 24110 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 03:09:08.133579 24110 accuracy_layer.cpp:101] Class 0 accuracy : 0.965517
I0422 03:09:08.133584 24110 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
Traceback (most recent call last):
  File "./experiments/activitynet/train_net.py", line 97, in <module>
    max_iters=args.max_iters)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/tdcnn/train.py", line 125, in train_net
    model_paths = sw.train_model(max_iters)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/tdcnn/train.py", line 102, in train_model
    self.solver.step(1)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/rpn/proposal_target_layer.py", line 84, in forward
    rois_per_image, self._num_classes)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/rpn/proposal_target_layer.py", line 225, in _sample_rois
    _get_twin_regression_labels(twin_target_data, num_classes)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/rpn/proposal_target_layer.py", line 157, in _get_twin_regression_labels
    twin_targets[ind, start:end] = twin_target_data[ind, 1:]
ValueError: could not broadcast input array from shape (201) into shape (2)

real	1m52.293s
user	0m26.421s
sys	1m26.272s
Called with args:
Namespace(cfg_file='./experiments/activitynet/td_cnn_end2end.yml', gpu_id=0, max_iters=350000, pretrained_model='./pretrain/activitynet_iter_30000_3fps.caffemodel', randomize=False, set_cfgs=None, solver='./experiments/activitynet/solver.prototxt')
Using config:
{'DEDUP_BOXES': 0.125,
 'EPS': 1e-14,
 'FPS': 25,
 'GPU_ID': 0,
 'INPUT': 'video',
 'NUM_CLASSES': 201,
 'PIXEL_MEANS': array([[[ 90,  98, 102]]]),
 'PIXEL_MEANS_FLOW': array([128]),
 'RNG_SEED': 3,
 'TEST': {'CROP_SIZE': 112,
          'FRAME_SIZE': [128, 171],
          'HAS_RPN': True,
          'LENGTH': [768],
          'MAX_SIZE': 1000,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.9,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SVM': False,
          'TWIN_REG': True},
 'TRAIN': {'BATCH_SIZE': 128,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.1,
           'CINPUT': False,
           'CROP_SIZE': 112,
           'FG_FRACTION': 0.5,
           'FG_THRESH': 0.5,
           'FRAME_SIZE': [128, 171],
           'HAS_RPN': True,
           'LENGTH': [768],
           'OHEM_LOSS_ONLY_CLASSIFICATION': False,
           'OHEM_LOSS_ONLY_LOCALIZATION': False,
           'OHEM_NMS_THRESH': 0.7,
           'OHEM_USE_NMS': True,
           'PROPOSAL_METHOD': 'gt',
           'RANDOM': False,
           'RPN_BATCHSIZE': 64,
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.8,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'RPN_TWIN_INSIDE_WEIGHTS': [1.0, 1.0],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 1000,
           'TWIN_INSIDE_WEIGHTS': [1.0, 1.0],
           'TWIN_NORMALIZE_MEANS': [0.0, 0.0],
           'TWIN_NORMALIZE_STDS': [0.1, 0.2],
           'TWIN_NORMALIZE_TARGETS': False,
           'TWIN_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'TWIN_REG': True,
           'TWIN_THRESH': 0.5,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False,
           'VIDEO_BATCH': 1},
 'USE_GPU_NMS': True}
45074 roidb entries
Output will be saved to `./experiments/best_activitynet/snapshot/`
Computing bounding-box regression targets...
precimputed
twin target means:
twin target stdevs:
NOT normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0422 14:31:42.234464  3756 solver.cpp:48] Initializing solver from parameters: 
train_net: "./experiments/activitynet/train.prototxt"
base_lr: 0.0001
display: 1
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 350000
snapshot: 0
snapshot_prefix: "./experiments/activitynet/snapshot/activitynet"
average_loss: 100
iter_size: 1
I0422 14:31:42.234496  3756 solver.cpp:81] Creating training net from train_net file: ./experiments/activitynet/train.prototxt
I0422 14:31:42.235546  3756 net.cpp:58] Initializing net from parameters: 
name: "activitynet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 200"
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    kernel_size: 2
    kernel_size: 2
    stride: 1
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv2a"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv3a"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "conv3b"
  type: "Convolution"
  bottom: "conv3a"
  top: "conv3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3b"
  type: "ReLU"
  bottom: "conv3b"
  top: "conv3b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv4a"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "conv4b"
  type: "Convolution"
  bottom: "conv4a"
  top: "conv4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4b"
  type: "ReLU"
  bottom: "conv4b"
  top: "conv4b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv5a"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "conv5b"
  type: "Convolution"
  bottom: "conv5a"
  top: "conv5b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5b"
  type: "ReLU"
  bottom: "conv5b"
  top: "conv5b"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5b"
  top: "rpn/output"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_conv/3x3_2"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn/output_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3_2"
  type: "ReLU"
  bottom: "rpn/output_2"
  top: "rpn/output_2"
}
layer {
  name: "rpn/output_pool"
  type: "Pooling"
  bottom: "rpn/output_2"
  top: "rpn/output_pool"
  pooling_param {
    pool: MAX
    kernel_size: 1
    kernel_size: 2
    kernel_size: 2
  }
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output_pool"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 74
    kernel_size: 1
    kernel_size: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_twin_pred"
  type: "Convolution"
  bottom: "rpn/output_pool"
  top: "rpn_twin_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 74
    kernel_size: 1
    kernel_size: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_twin_targets"
  top: "rpn_twin_inside_weights"
  top: "rpn_twin_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 8 \n\'scales\': !!python/tuple [1,1.25, 1.5,1.75, 2,2.5, 3,3.5, 4,4.5, 5,5.5, 6,7, 8,9,10,11,12,14,16,18,20,22,24,28,32,36,40,44,52,60,68,76,84,92,100]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_twin"
  type: "SmoothL1Loss"
  bottom: "rpn_twin_pred"
  bottom: "rpn_twin_targets"
  bottom: "rpn_twin_inside_weights"
  bottom: "rpn_twin_outside_weights"
  top: "rpn_loss_twin"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_accuarcy"
  type: "Accuracy"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_accuarcy"
  top: "rpn_accuarcy_class"
  propagate_down: false
  propagate_down: false
  accuracy_param {
    ignore_label: -1
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 74
      dim: -1
      dim: 0
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_twin_pred"
  top: "rpn_rois"
  include {
    phase: TRAIN
  }
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 8 \n\'scales\': !!python/tuple [1,1.25, 1.5,1.75, 2,2.5, 3,3.5, 4,4.5, 5,5.5, 6,7, 8,9,10,11,12,14,16,18,20,22,24,28,32,36,40,44,52,60,68,76,84,92,100]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  top: "rois"
  top: "labels"
  top: "twin_targets"
  top: "twin_inside_weights"
  top: "twin_outside_weights"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 200"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5b"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 4
    pooled_w: 4
    spatial_scale: 0.0625
    pooled_l: 1
    temporal_scale: 0.125
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc6"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 200
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "twin_pred"
  type: "InnerProduct"
  bottom: "fc6"
  top: "twin_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 400
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SigmoidCrossEntropyLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_twin"
  type: "SmoothL1Loss"
  bottom: "twin_pred"
  bottom: "twin_targets"
  bottom: "twin_inside_weights"
  bottom: "twin_outside_weights"
  top: "loss_twin"
  loss_weight: 1
}
layer {
  name: "accuracy"
  type: "Python"
  bottom: "cls_score"
  bottom: "labels"
  top: "accuracy"
  python_param {
    module: "utils.accuracy_layer"
    layer: "AccuracyLayer"
    param_str: "{\"top_k\": 2}"
  }
}
I0422 14:31:42.235752  3756 layer_factory.hpp:77] Creating layer data
I0422 14:31:42.259459  3756 net.cpp:100] Creating Layer data
I0422 14:31:42.259480  3756 net.cpp:408] data -> data
I0422 14:31:42.259492  3756 net.cpp:408] data -> gt_boxes
setting up
has rpn
RoiDataLayer: name_to_top: {'gt_windows': 1, 'data': 0}
I0422 14:31:42.272526  3756 net.cpp:150] Setting up data
I0422 14:31:42.272547  3756 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 14:31:42.272553  3756 net.cpp:157] Top shape: 1 101 (101)
I0422 14:31:42.272557  3756 net.cpp:165] Memory required for data: 115605908
I0422 14:31:42.272567  3756 layer_factory.hpp:77] Creating layer data_data_0_split
I0422 14:31:42.272578  3756 net.cpp:100] Creating Layer data_data_0_split
I0422 14:31:42.272583  3756 net.cpp:434] data_data_0_split <- data
I0422 14:31:42.272589  3756 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0422 14:31:42.272600  3756 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0422 14:31:42.272630  3756 net.cpp:150] Setting up data_data_0_split
I0422 14:31:42.272639  3756 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 14:31:42.272642  3756 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 14:31:42.272645  3756 net.cpp:165] Memory required for data: 346816916
I0422 14:31:42.272650  3756 layer_factory.hpp:77] Creating layer gt_boxes_data_1_split
I0422 14:31:42.272655  3756 net.cpp:100] Creating Layer gt_boxes_data_1_split
I0422 14:31:42.272658  3756 net.cpp:434] gt_boxes_data_1_split <- gt_boxes
I0422 14:31:42.272662  3756 net.cpp:408] gt_boxes_data_1_split -> gt_boxes_data_1_split_0
I0422 14:31:42.272671  3756 net.cpp:408] gt_boxes_data_1_split -> gt_boxes_data_1_split_1
I0422 14:31:42.272696  3756 net.cpp:150] Setting up gt_boxes_data_1_split
I0422 14:31:42.272702  3756 net.cpp:157] Top shape: 1 101 (101)
I0422 14:31:42.272707  3756 net.cpp:157] Top shape: 1 101 (101)
I0422 14:31:42.272711  3756 net.cpp:165] Memory required for data: 346817724
I0422 14:31:42.272714  3756 layer_factory.hpp:77] Creating layer conv1a
I0422 14:31:42.272730  3756 net.cpp:100] Creating Layer conv1a
I0422 14:31:42.272735  3756 net.cpp:434] conv1a <- data_data_0_split_0
I0422 14:31:42.272740  3756 net.cpp:408] conv1a -> conv1a
I0422 14:31:42.451506  3756 net.cpp:150] Setting up conv1a
I0422 14:31:42.451539  3756 net.cpp:157] Top shape: 1 64 768 112 112 (616562688)
I0422 14:31:42.451544  3756 net.cpp:165] Memory required for data: 2813068476
I0422 14:31:42.451561  3756 layer_factory.hpp:77] Creating layer relu1a
I0422 14:31:42.451575  3756 net.cpp:100] Creating Layer relu1a
I0422 14:31:42.451578  3756 net.cpp:434] relu1a <- conv1a
I0422 14:31:42.451584  3756 net.cpp:395] relu1a -> conv1a (in-place)
I0422 14:31:42.451994  3756 net.cpp:150] Setting up relu1a
I0422 14:31:42.452006  3756 net.cpp:157] Top shape: 1 64 768 112 112 (616562688)
I0422 14:31:42.452009  3756 net.cpp:165] Memory required for data: 5279319228
I0422 14:31:42.452013  3756 layer_factory.hpp:77] Creating layer pool1
I0422 14:31:42.452023  3756 net.cpp:100] Creating Layer pool1
I0422 14:31:42.452026  3756 net.cpp:434] pool1 <- conv1a
I0422 14:31:42.452031  3756 net.cpp:408] pool1 -> pool1
I0422 14:31:42.452203  3756 net.cpp:150] Setting up pool1
I0422 14:31:42.452213  3756 net.cpp:157] Top shape: 1 64 768 56 56 (154140672)
I0422 14:31:42.452215  3756 net.cpp:165] Memory required for data: 5895881916
I0422 14:31:42.452219  3756 layer_factory.hpp:77] Creating layer conv2a
I0422 14:31:42.452230  3756 net.cpp:100] Creating Layer conv2a
I0422 14:31:42.452234  3756 net.cpp:434] conv2a <- pool1
I0422 14:31:42.452239  3756 net.cpp:408] conv2a -> conv2a
I0422 14:31:42.463008  3756 net.cpp:150] Setting up conv2a
I0422 14:31:42.463027  3756 net.cpp:157] Top shape: 1 128 768 56 56 (308281344)
I0422 14:31:42.463032  3756 net.cpp:165] Memory required for data: 7129007292
I0422 14:31:42.463042  3756 layer_factory.hpp:77] Creating layer relu2a
I0422 14:31:42.463052  3756 net.cpp:100] Creating Layer relu2a
I0422 14:31:42.463058  3756 net.cpp:434] relu2a <- conv2a
I0422 14:31:42.463063  3756 net.cpp:395] relu2a -> conv2a (in-place)
I0422 14:31:42.463364  3756 net.cpp:150] Setting up relu2a
I0422 14:31:42.463378  3756 net.cpp:157] Top shape: 1 128 768 56 56 (308281344)
I0422 14:31:42.463382  3756 net.cpp:165] Memory required for data: 8362132668
I0422 14:31:42.463385  3756 layer_factory.hpp:77] Creating layer pool2
I0422 14:31:42.463394  3756 net.cpp:100] Creating Layer pool2
I0422 14:31:42.463397  3756 net.cpp:434] pool2 <- conv2a
I0422 14:31:42.463404  3756 net.cpp:408] pool2 -> pool2
I0422 14:31:42.463577  3756 net.cpp:150] Setting up pool2
I0422 14:31:42.463588  3756 net.cpp:157] Top shape: 1 128 384 28 28 (38535168)
I0422 14:31:42.463591  3756 net.cpp:165] Memory required for data: 8516273340
I0422 14:31:42.463595  3756 layer_factory.hpp:77] Creating layer conv3a
I0422 14:31:42.463605  3756 net.cpp:100] Creating Layer conv3a
I0422 14:31:42.463608  3756 net.cpp:434] conv3a <- pool2
I0422 14:31:42.463615  3756 net.cpp:408] conv3a -> conv3a
I0422 14:31:42.487864  3756 net.cpp:150] Setting up conv3a
I0422 14:31:42.487879  3756 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 14:31:42.487884  3756 net.cpp:165] Memory required for data: 8824554684
I0422 14:31:42.487893  3756 layer_factory.hpp:77] Creating layer relu3a
I0422 14:31:42.487900  3756 net.cpp:100] Creating Layer relu3a
I0422 14:31:42.487903  3756 net.cpp:434] relu3a <- conv3a
I0422 14:31:42.487908  3756 net.cpp:395] relu3a -> conv3a (in-place)
I0422 14:31:42.488195  3756 net.cpp:150] Setting up relu3a
I0422 14:31:42.488209  3756 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 14:31:42.488212  3756 net.cpp:165] Memory required for data: 9132836028
I0422 14:31:42.488216  3756 layer_factory.hpp:77] Creating layer conv3b
I0422 14:31:42.488227  3756 net.cpp:100] Creating Layer conv3b
I0422 14:31:42.488236  3756 net.cpp:434] conv3b <- conv3a
I0422 14:31:42.488241  3756 net.cpp:408] conv3b -> conv3b
I0422 14:31:42.535112  3756 net.cpp:150] Setting up conv3b
I0422 14:31:42.535133  3756 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 14:31:42.535136  3756 net.cpp:165] Memory required for data: 9441117372
I0422 14:31:42.535145  3756 layer_factory.hpp:77] Creating layer relu3b
I0422 14:31:42.535156  3756 net.cpp:100] Creating Layer relu3b
I0422 14:31:42.535159  3756 net.cpp:434] relu3b <- conv3b
I0422 14:31:42.535166  3756 net.cpp:395] relu3b -> conv3b (in-place)
I0422 14:31:42.535473  3756 net.cpp:150] Setting up relu3b
I0422 14:31:42.535495  3756 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 14:31:42.535498  3756 net.cpp:165] Memory required for data: 9749398716
I0422 14:31:42.535502  3756 layer_factory.hpp:77] Creating layer pool3
I0422 14:31:42.535509  3756 net.cpp:100] Creating Layer pool3
I0422 14:31:42.535512  3756 net.cpp:434] pool3 <- conv3b
I0422 14:31:42.535519  3756 net.cpp:408] pool3 -> pool3
I0422 14:31:42.535699  3756 net.cpp:150] Setting up pool3
I0422 14:31:42.535711  3756 net.cpp:157] Top shape: 1 256 192 14 14 (9633792)
I0422 14:31:42.535714  3756 net.cpp:165] Memory required for data: 9787933884
I0422 14:31:42.535718  3756 layer_factory.hpp:77] Creating layer conv4a
I0422 14:31:42.535728  3756 net.cpp:100] Creating Layer conv4a
I0422 14:31:42.535732  3756 net.cpp:434] conv4a <- pool3
I0422 14:31:42.535739  3756 net.cpp:408] conv4a -> conv4a
I0422 14:31:42.629078  3756 net.cpp:150] Setting up conv4a
I0422 14:31:42.629102  3756 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 14:31:42.629106  3756 net.cpp:165] Memory required for data: 9865004220
I0422 14:31:42.629122  3756 layer_factory.hpp:77] Creating layer relu4a
I0422 14:31:42.629130  3756 net.cpp:100] Creating Layer relu4a
I0422 14:31:42.629134  3756 net.cpp:434] relu4a <- conv4a
I0422 14:31:42.629140  3756 net.cpp:395] relu4a -> conv4a (in-place)
I0422 14:31:42.629434  3756 net.cpp:150] Setting up relu4a
I0422 14:31:42.629446  3756 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 14:31:42.629451  3756 net.cpp:165] Memory required for data: 9942074556
I0422 14:31:42.629454  3756 layer_factory.hpp:77] Creating layer conv4b
I0422 14:31:42.629467  3756 net.cpp:100] Creating Layer conv4b
I0422 14:31:42.629470  3756 net.cpp:434] conv4b <- conv4a
I0422 14:31:42.629477  3756 net.cpp:408] conv4b -> conv4b
I0422 14:31:42.813938  3756 net.cpp:150] Setting up conv4b
I0422 14:31:42.813961  3756 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 14:31:42.813966  3756 net.cpp:165] Memory required for data: 10019144892
I0422 14:31:42.813974  3756 layer_factory.hpp:77] Creating layer relu4b
I0422 14:31:42.813982  3756 net.cpp:100] Creating Layer relu4b
I0422 14:31:42.813987  3756 net.cpp:434] relu4b <- conv4b
I0422 14:31:42.813994  3756 net.cpp:395] relu4b -> conv4b (in-place)
I0422 14:31:42.814144  3756 net.cpp:150] Setting up relu4b
I0422 14:31:42.814154  3756 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 14:31:42.814157  3756 net.cpp:165] Memory required for data: 10096215228
I0422 14:31:42.814162  3756 layer_factory.hpp:77] Creating layer pool4
I0422 14:31:42.814169  3756 net.cpp:100] Creating Layer pool4
I0422 14:31:42.814172  3756 net.cpp:434] pool4 <- conv4b
I0422 14:31:42.814177  3756 net.cpp:408] pool4 -> pool4
I0422 14:31:42.814491  3756 net.cpp:150] Setting up pool4
I0422 14:31:42.814503  3756 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:31:42.814507  3756 net.cpp:165] Memory required for data: 10105849020
I0422 14:31:42.814512  3756 layer_factory.hpp:77] Creating layer conv5a
I0422 14:31:42.814522  3756 net.cpp:100] Creating Layer conv5a
I0422 14:31:42.814525  3756 net.cpp:434] conv5a <- pool4
I0422 14:31:42.814532  3756 net.cpp:408] conv5a -> conv5a
I0422 14:31:42.999409  3756 net.cpp:150] Setting up conv5a
I0422 14:31:42.999434  3756 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:31:42.999439  3756 net.cpp:165] Memory required for data: 10115482812
I0422 14:31:42.999446  3756 layer_factory.hpp:77] Creating layer relu5a
I0422 14:31:42.999455  3756 net.cpp:100] Creating Layer relu5a
I0422 14:31:42.999460  3756 net.cpp:434] relu5a <- conv5a
I0422 14:31:42.999478  3756 net.cpp:395] relu5a -> conv5a (in-place)
I0422 14:31:42.999891  3756 net.cpp:150] Setting up relu5a
I0422 14:31:42.999903  3756 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:31:42.999907  3756 net.cpp:165] Memory required for data: 10125116604
I0422 14:31:42.999912  3756 layer_factory.hpp:77] Creating layer conv5b
I0422 14:31:42.999923  3756 net.cpp:100] Creating Layer conv5b
I0422 14:31:42.999927  3756 net.cpp:434] conv5b <- conv5a
I0422 14:31:42.999934  3756 net.cpp:408] conv5b -> conv5b
I0422 14:31:43.186990  3756 net.cpp:150] Setting up conv5b
I0422 14:31:43.187012  3756 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:31:43.187016  3756 net.cpp:165] Memory required for data: 10134750396
I0422 14:31:43.187026  3756 layer_factory.hpp:77] Creating layer relu5b
I0422 14:31:43.187036  3756 net.cpp:100] Creating Layer relu5b
I0422 14:31:43.187041  3756 net.cpp:434] relu5b <- conv5b
I0422 14:31:43.187047  3756 net.cpp:395] relu5b -> conv5b (in-place)
I0422 14:31:43.187206  3756 net.cpp:150] Setting up relu5b
I0422 14:31:43.187217  3756 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:31:43.187222  3756 net.cpp:165] Memory required for data: 10144384188
I0422 14:31:43.187225  3756 layer_factory.hpp:77] Creating layer conv5b_relu5b_0_split
I0422 14:31:43.187233  3756 net.cpp:100] Creating Layer conv5b_relu5b_0_split
I0422 14:31:43.187237  3756 net.cpp:434] conv5b_relu5b_0_split <- conv5b
I0422 14:31:43.187243  3756 net.cpp:408] conv5b_relu5b_0_split -> conv5b_relu5b_0_split_0
I0422 14:31:43.187250  3756 net.cpp:408] conv5b_relu5b_0_split -> conv5b_relu5b_0_split_1
I0422 14:31:43.187292  3756 net.cpp:150] Setting up conv5b_relu5b_0_split
I0422 14:31:43.187301  3756 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:31:43.187306  3756 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:31:43.187309  3756 net.cpp:165] Memory required for data: 10163651772
I0422 14:31:43.187314  3756 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0422 14:31:43.187325  3756 net.cpp:100] Creating Layer rpn_conv/3x3
I0422 14:31:43.187331  3756 net.cpp:434] rpn_conv/3x3 <- conv5b_relu5b_0_split_0
I0422 14:31:43.187340  3756 net.cpp:408] rpn_conv/3x3 -> rpn/output
I0422 14:31:43.372665  3756 net.cpp:150] Setting up rpn_conv/3x3
I0422 14:31:43.372689  3756 net.cpp:157] Top shape: 1 512 96 4 4 (786432)
I0422 14:31:43.372694  3756 net.cpp:165] Memory required for data: 10166797500
I0422 14:31:43.372707  3756 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0422 14:31:43.372716  3756 net.cpp:100] Creating Layer rpn_relu/3x3
I0422 14:31:43.372721  3756 net.cpp:434] rpn_relu/3x3 <- rpn/output
I0422 14:31:43.372728  3756 net.cpp:395] rpn_relu/3x3 -> rpn/output (in-place)
I0422 14:31:43.373034  3756 net.cpp:150] Setting up rpn_relu/3x3
I0422 14:31:43.373059  3756 net.cpp:157] Top shape: 1 512 96 4 4 (786432)
I0422 14:31:43.373061  3756 net.cpp:165] Memory required for data: 10169943228
I0422 14:31:43.373065  3756 layer_factory.hpp:77] Creating layer rpn_conv/3x3_2
I0422 14:31:43.373076  3756 net.cpp:100] Creating Layer rpn_conv/3x3_2
I0422 14:31:43.373080  3756 net.cpp:434] rpn_conv/3x3_2 <- rpn/output
I0422 14:31:43.373086  3756 net.cpp:408] rpn_conv/3x3_2 -> rpn/output_2
I0422 14:31:43.557391  3756 net.cpp:150] Setting up rpn_conv/3x3_2
I0422 14:31:43.557415  3756 net.cpp:157] Top shape: 1 512 96 2 2 (196608)
I0422 14:31:43.557420  3756 net.cpp:165] Memory required for data: 10170729660
I0422 14:31:43.557428  3756 layer_factory.hpp:77] Creating layer rpn_relu/3x3_2
I0422 14:31:43.557437  3756 net.cpp:100] Creating Layer rpn_relu/3x3_2
I0422 14:31:43.557441  3756 net.cpp:434] rpn_relu/3x3_2 <- rpn/output_2
I0422 14:31:43.557447  3756 net.cpp:395] rpn_relu/3x3_2 -> rpn/output_2 (in-place)
I0422 14:31:43.557744  3756 net.cpp:150] Setting up rpn_relu/3x3_2
I0422 14:31:43.557759  3756 net.cpp:157] Top shape: 1 512 96 2 2 (196608)
I0422 14:31:43.557761  3756 net.cpp:165] Memory required for data: 10171516092
I0422 14:31:43.557766  3756 layer_factory.hpp:77] Creating layer rpn/output_pool
I0422 14:31:43.557772  3756 net.cpp:100] Creating Layer rpn/output_pool
I0422 14:31:43.557777  3756 net.cpp:434] rpn/output_pool <- rpn/output_2
I0422 14:31:43.557782  3756 net.cpp:408] rpn/output_pool -> rpn/output_pool
I0422 14:31:43.557955  3756 net.cpp:150] Setting up rpn/output_pool
I0422 14:31:43.557966  3756 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 14:31:43.557971  3756 net.cpp:165] Memory required for data: 10171712700
I0422 14:31:43.557973  3756 layer_factory.hpp:77] Creating layer rpn/output_pool_rpn/output_pool_0_split
I0422 14:31:43.557981  3756 net.cpp:100] Creating Layer rpn/output_pool_rpn/output_pool_0_split
I0422 14:31:43.557983  3756 net.cpp:434] rpn/output_pool_rpn/output_pool_0_split <- rpn/output_pool
I0422 14:31:43.557988  3756 net.cpp:408] rpn/output_pool_rpn/output_pool_0_split -> rpn/output_pool_rpn/output_pool_0_split_0
I0422 14:31:43.557993  3756 net.cpp:408] rpn/output_pool_rpn/output_pool_0_split -> rpn/output_pool_rpn/output_pool_0_split_1
I0422 14:31:43.558025  3756 net.cpp:150] Setting up rpn/output_pool_rpn/output_pool_0_split
I0422 14:31:43.558032  3756 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 14:31:43.558037  3756 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 14:31:43.558040  3756 net.cpp:165] Memory required for data: 10172105916
I0422 14:31:43.558043  3756 layer_factory.hpp:77] Creating layer rpn_cls_score
I0422 14:31:43.558053  3756 net.cpp:100] Creating Layer rpn_cls_score
I0422 14:31:43.558060  3756 net.cpp:434] rpn_cls_score <- rpn/output_pool_rpn/output_pool_0_split_0
I0422 14:31:43.558068  3756 net.cpp:408] rpn_cls_score -> rpn_cls_score
I0422 14:31:43.560122  3756 net.cpp:150] Setting up rpn_cls_score
I0422 14:31:43.560133  3756 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:31:43.560137  3756 net.cpp:165] Memory required for data: 10172134332
I0422 14:31:43.560143  3756 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0422 14:31:43.560149  3756 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0422 14:31:43.560153  3756 net.cpp:434] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0422 14:31:43.560158  3756 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0422 14:31:43.560168  3756 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0422 14:31:43.560206  3756 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0422 14:31:43.560214  3756 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:31:43.560217  3756 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:31:43.560220  3756 net.cpp:165] Memory required for data: 10172191164
I0422 14:31:43.560223  3756 layer_factory.hpp:77] Creating layer rpn_twin_pred
I0422 14:31:43.560236  3756 net.cpp:100] Creating Layer rpn_twin_pred
I0422 14:31:43.560241  3756 net.cpp:434] rpn_twin_pred <- rpn/output_pool_rpn/output_pool_0_split_1
I0422 14:31:43.560246  3756 net.cpp:408] rpn_twin_pred -> rpn_twin_pred
I0422 14:31:43.562186  3756 net.cpp:150] Setting up rpn_twin_pred
I0422 14:31:43.562201  3756 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:31:43.562203  3756 net.cpp:165] Memory required for data: 10172219580
I0422 14:31:43.562209  3756 layer_factory.hpp:77] Creating layer rpn_twin_pred_rpn_twin_pred_0_split
I0422 14:31:43.562216  3756 net.cpp:100] Creating Layer rpn_twin_pred_rpn_twin_pred_0_split
I0422 14:31:43.562218  3756 net.cpp:434] rpn_twin_pred_rpn_twin_pred_0_split <- rpn_twin_pred
I0422 14:31:43.562223  3756 net.cpp:408] rpn_twin_pred_rpn_twin_pred_0_split -> rpn_twin_pred_rpn_twin_pred_0_split_0
I0422 14:31:43.562229  3756 net.cpp:408] rpn_twin_pred_rpn_twin_pred_0_split -> rpn_twin_pred_rpn_twin_pred_0_split_1
I0422 14:31:43.562264  3756 net.cpp:150] Setting up rpn_twin_pred_rpn_twin_pred_0_split
I0422 14:31:43.562271  3756 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:31:43.562275  3756 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:31:43.562279  3756 net.cpp:165] Memory required for data: 10172276412
I0422 14:31:43.562283  3756 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0422 14:31:43.562294  3756 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0422 14:31:43.562299  3756 net.cpp:434] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0422 14:31:43.562304  3756 net.cpp:408] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0422 14:31:43.562330  3756 net.cpp:150] Setting up rpn_cls_score_reshape
I0422 14:31:43.562348  3756 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 14:31:43.562352  3756 net.cpp:165] Memory required for data: 10172304828
I0422 14:31:43.562355  3756 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 14:31:43.562361  3756 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 14:31:43.562363  3756 net.cpp:434] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0422 14:31:43.562369  3756 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0422 14:31:43.562376  3756 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0422 14:31:43.562381  3756 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_2
I0422 14:31:43.562422  3756 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 14:31:43.562430  3756 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 14:31:43.562434  3756 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 14:31:43.562438  3756 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 14:31:43.562441  3756 net.cpp:165] Memory required for data: 10172390076
I0422 14:31:43.562444  3756 layer_factory.hpp:77] Creating layer rpn-data
I0422 14:31:43.562868  3756 net.cpp:100] Creating Layer rpn-data
I0422 14:31:43.562880  3756 net.cpp:434] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0422 14:31:43.562886  3756 net.cpp:434] rpn-data <- gt_boxes_data_1_split_0
I0422 14:31:43.562891  3756 net.cpp:434] rpn-data <- data_data_0_split_1
I0422 14:31:43.562896  3756 net.cpp:408] rpn-data -> rpn_labels
I0422 14:31:43.562903  3756 net.cpp:408] rpn-data -> rpn_twin_targets
I0422 14:31:43.562909  3756 net.cpp:408] rpn-data -> rpn_twin_inside_weights
I0422 14:31:43.562914  3756 net.cpp:408] rpn-data -> rpn_twin_outside_weights
I0422 14:31:43.565270  3756 net.cpp:150] Setting up rpn-data
I0422 14:31:43.565284  3756 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 14:31:43.565289  3756 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:31:43.565294  3756 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:31:43.565297  3756 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:31:43.565300  3756 net.cpp:165] Memory required for data: 10172489532
I0422 14:31:43.565305  3756 layer_factory.hpp:77] Creating layer rpn_labels_rpn-data_0_split
I0422 14:31:43.565311  3756 net.cpp:100] Creating Layer rpn_labels_rpn-data_0_split
I0422 14:31:43.565315  3756 net.cpp:434] rpn_labels_rpn-data_0_split <- rpn_labels
I0422 14:31:43.565320  3756 net.cpp:408] rpn_labels_rpn-data_0_split -> rpn_labels_rpn-data_0_split_0
I0422 14:31:43.565326  3756 net.cpp:408] rpn_labels_rpn-data_0_split -> rpn_labels_rpn-data_0_split_1
I0422 14:31:43.565358  3756 net.cpp:150] Setting up rpn_labels_rpn-data_0_split
I0422 14:31:43.565366  3756 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 14:31:43.565371  3756 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 14:31:43.565373  3756 net.cpp:165] Memory required for data: 10172517948
I0422 14:31:43.565388  3756 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0422 14:31:43.565397  3756 net.cpp:100] Creating Layer rpn_loss_cls
I0422 14:31:43.565402  3756 net.cpp:434] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0422 14:31:43.565407  3756 net.cpp:434] rpn_loss_cls <- rpn_labels_rpn-data_0_split_0
I0422 14:31:43.565412  3756 net.cpp:408] rpn_loss_cls -> rpn_cls_loss
I0422 14:31:43.565420  3756 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0422 14:31:43.565798  3756 net.cpp:150] Setting up rpn_loss_cls
I0422 14:31:43.565810  3756 net.cpp:157] Top shape: (1)
I0422 14:31:43.565814  3756 net.cpp:160]     with loss weight 1
I0422 14:31:43.565826  3756 net.cpp:165] Memory required for data: 10172517952
I0422 14:31:43.565830  3756 layer_factory.hpp:77] Creating layer rpn_loss_twin
I0422 14:31:43.565840  3756 net.cpp:100] Creating Layer rpn_loss_twin
I0422 14:31:43.565843  3756 net.cpp:434] rpn_loss_twin <- rpn_twin_pred_rpn_twin_pred_0_split_0
I0422 14:31:43.565847  3756 net.cpp:434] rpn_loss_twin <- rpn_twin_targets
I0422 14:31:43.565852  3756 net.cpp:434] rpn_loss_twin <- rpn_twin_inside_weights
I0422 14:31:43.565855  3756 net.cpp:434] rpn_loss_twin <- rpn_twin_outside_weights
I0422 14:31:43.565860  3756 net.cpp:408] rpn_loss_twin -> rpn_loss_twin
I0422 14:31:43.565932  3756 net.cpp:150] Setting up rpn_loss_twin
I0422 14:31:43.565942  3756 net.cpp:157] Top shape: (1)
I0422 14:31:43.565945  3756 net.cpp:160]     with loss weight 1
I0422 14:31:43.565950  3756 net.cpp:165] Memory required for data: 10172517956
I0422 14:31:43.565953  3756 layer_factory.hpp:77] Creating layer rpn_accuarcy
I0422 14:31:43.565961  3756 net.cpp:100] Creating Layer rpn_accuarcy
I0422 14:31:43.565966  3756 net.cpp:434] rpn_accuarcy <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0422 14:31:43.565971  3756 net.cpp:434] rpn_accuarcy <- rpn_labels_rpn-data_0_split_1
I0422 14:31:43.565977  3756 net.cpp:408] rpn_accuarcy -> rpn_accuarcy
I0422 14:31:43.565989  3756 net.cpp:408] rpn_accuarcy -> rpn_accuarcy_class
I0422 14:31:43.566025  3756 net.cpp:150] Setting up rpn_accuarcy
I0422 14:31:43.566032  3756 net.cpp:157] Top shape: (1)
I0422 14:31:43.566036  3756 net.cpp:157] Top shape: 2 (2)
I0422 14:31:43.566040  3756 net.cpp:165] Memory required for data: 10172517968
I0422 14:31:43.566045  3756 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0422 14:31:43.566048  3756 net.cpp:100] Creating Layer rpn_cls_prob
I0422 14:31:43.566052  3756 net.cpp:434] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_2
I0422 14:31:43.566056  3756 net.cpp:408] rpn_cls_prob -> rpn_cls_prob
I0422 14:31:43.566246  3756 net.cpp:150] Setting up rpn_cls_prob
I0422 14:31:43.566256  3756 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 14:31:43.566259  3756 net.cpp:165] Memory required for data: 10172546384
I0422 14:31:43.566263  3756 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0422 14:31:43.566270  3756 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0422 14:31:43.566274  3756 net.cpp:434] rpn_cls_prob_reshape <- rpn_cls_prob
I0422 14:31:43.566279  3756 net.cpp:408] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0422 14:31:43.566304  3756 net.cpp:150] Setting up rpn_cls_prob_reshape
I0422 14:31:43.566311  3756 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:31:43.566314  3756 net.cpp:165] Memory required for data: 10172574800
I0422 14:31:43.566318  3756 layer_factory.hpp:77] Creating layer proposal
I0422 14:31:43.566890  3756 net.cpp:100] Creating Layer proposal
I0422 14:31:43.566903  3756 net.cpp:434] proposal <- rpn_cls_prob_reshape
I0422 14:31:43.566910  3756 net.cpp:434] proposal <- rpn_twin_pred_rpn_twin_pred_0_split_1
I0422 14:31:43.566915  3756 net.cpp:408] proposal -> rpn_rois
I0422 14:31:43.569041  3756 net.cpp:150] Setting up proposal
I0422 14:31:43.569056  3756 net.cpp:157] Top shape: 1 3 (3)
I0422 14:31:43.569059  3756 net.cpp:165] Memory required for data: 10172574812
I0422 14:31:43.569063  3756 layer_factory.hpp:77] Creating layer roi-data
I0422 14:31:43.569192  3756 net.cpp:100] Creating Layer roi-data
I0422 14:31:43.569203  3756 net.cpp:434] roi-data <- rpn_rois
I0422 14:31:43.569209  3756 net.cpp:434] roi-data <- gt_boxes_data_1_split_1
I0422 14:31:43.569214  3756 net.cpp:408] roi-data -> rois
I0422 14:31:43.569221  3756 net.cpp:408] roi-data -> labels
I0422 14:31:43.569227  3756 net.cpp:408] roi-data -> twin_targets
I0422 14:31:43.569232  3756 net.cpp:408] roi-data -> twin_inside_weights
I0422 14:31:43.569238  3756 net.cpp:408] roi-data -> twin_outside_weights
('sampling method:', 'Random')
I0422 14:31:43.569556  3756 net.cpp:150] Setting up roi-data
I0422 14:31:43.569571  3756 net.cpp:157] Top shape: 1 3 (3)
I0422 14:31:43.569574  3756 net.cpp:157] Top shape: 1 200 (200)
I0422 14:31:43.569578  3756 net.cpp:157] Top shape: 1 400 (400)
I0422 14:31:43.569582  3756 net.cpp:157] Top shape: 1 400 (400)
I0422 14:31:43.569586  3756 net.cpp:157] Top shape: 1 400 (400)
I0422 14:31:43.569591  3756 net.cpp:165] Memory required for data: 10172580424
I0422 14:31:43.569594  3756 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0422 14:31:43.569599  3756 net.cpp:100] Creating Layer labels_roi-data_1_split
I0422 14:31:43.569603  3756 net.cpp:434] labels_roi-data_1_split <- labels
I0422 14:31:43.569608  3756 net.cpp:408] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0422 14:31:43.569615  3756 net.cpp:408] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0422 14:31:43.569646  3756 net.cpp:150] Setting up labels_roi-data_1_split
I0422 14:31:43.569654  3756 net.cpp:157] Top shape: 1 200 (200)
I0422 14:31:43.569658  3756 net.cpp:157] Top shape: 1 200 (200)
I0422 14:31:43.569661  3756 net.cpp:165] Memory required for data: 10172582024
I0422 14:31:43.569664  3756 layer_factory.hpp:77] Creating layer roi_pool5
I0422 14:31:43.569674  3756 net.cpp:100] Creating Layer roi_pool5
I0422 14:31:43.569679  3756 net.cpp:434] roi_pool5 <- conv5b_relu5b_0_split_1
I0422 14:31:43.569684  3756 net.cpp:434] roi_pool5 <- rois
I0422 14:31:43.569689  3756 net.cpp:408] roi_pool5 -> pool5
I0422 14:31:43.569696  3756 roi_pooling_layer.cpp:34] Temporal scale: 0.125
I0422 14:31:43.569705  3756 roi_pooling_layer.cpp:35] Spatial scale: 0.0625
I0422 14:31:43.569737  3756 net.cpp:150] Setting up roi_pool5
I0422 14:31:43.569744  3756 net.cpp:157] Top shape: 1 512 1 4 4 (8192)
I0422 14:31:43.569748  3756 net.cpp:165] Memory required for data: 10172614792
I0422 14:31:43.569751  3756 layer_factory.hpp:77] Creating layer fc6
I0422 14:31:43.569761  3756 net.cpp:100] Creating Layer fc6
I0422 14:31:43.569766  3756 net.cpp:434] fc6 <- pool5
I0422 14:31:43.569770  3756 net.cpp:408] fc6 -> fc6
I0422 14:31:44.438472  3756 net.cpp:150] Setting up fc6
I0422 14:31:44.438496  3756 net.cpp:157] Top shape: 1 4096 (4096)
I0422 14:31:44.438500  3756 net.cpp:165] Memory required for data: 10172631176
I0422 14:31:44.438509  3756 layer_factory.hpp:77] Creating layer relu6
I0422 14:31:44.438519  3756 net.cpp:100] Creating Layer relu6
I0422 14:31:44.438535  3756 net.cpp:434] relu6 <- fc6
I0422 14:31:44.438544  3756 net.cpp:395] relu6 -> fc6 (in-place)
I0422 14:31:44.438954  3756 net.cpp:150] Setting up relu6
I0422 14:31:44.438966  3756 net.cpp:157] Top shape: 1 4096 (4096)
I0422 14:31:44.438971  3756 net.cpp:165] Memory required for data: 10172647560
I0422 14:31:44.438974  3756 layer_factory.hpp:77] Creating layer drop6
I0422 14:31:44.438994  3756 net.cpp:100] Creating Layer drop6
I0422 14:31:44.438998  3756 net.cpp:434] drop6 <- fc6
I0422 14:31:44.439003  3756 net.cpp:395] drop6 -> fc6 (in-place)
I0422 14:31:44.439031  3756 net.cpp:150] Setting up drop6
I0422 14:31:44.439036  3756 net.cpp:157] Top shape: 1 4096 (4096)
I0422 14:31:44.439039  3756 net.cpp:165] Memory required for data: 10172663944
I0422 14:31:44.439043  3756 layer_factory.hpp:77] Creating layer fc6_drop6_0_split
I0422 14:31:44.439049  3756 net.cpp:100] Creating Layer fc6_drop6_0_split
I0422 14:31:44.439051  3756 net.cpp:434] fc6_drop6_0_split <- fc6
I0422 14:31:44.439056  3756 net.cpp:408] fc6_drop6_0_split -> fc6_drop6_0_split_0
I0422 14:31:44.439062  3756 net.cpp:408] fc6_drop6_0_split -> fc6_drop6_0_split_1
I0422 14:31:44.439092  3756 net.cpp:150] Setting up fc6_drop6_0_split
I0422 14:31:44.439098  3756 net.cpp:157] Top shape: 1 4096 (4096)
I0422 14:31:44.439102  3756 net.cpp:157] Top shape: 1 4096 (4096)
I0422 14:31:44.439105  3756 net.cpp:165] Memory required for data: 10172696712
I0422 14:31:44.439108  3756 layer_factory.hpp:77] Creating layer cls_score
I0422 14:31:44.439116  3756 net.cpp:100] Creating Layer cls_score
I0422 14:31:44.439118  3756 net.cpp:434] cls_score <- fc6_drop6_0_split_0
I0422 14:31:44.439126  3756 net.cpp:408] cls_score -> cls_score
I0422 14:31:44.460217  3756 net.cpp:150] Setting up cls_score
I0422 14:31:44.460232  3756 net.cpp:157] Top shape: 1 200 (200)
I0422 14:31:44.460235  3756 net.cpp:165] Memory required for data: 10172697512
I0422 14:31:44.460242  3756 layer_factory.hpp:77] Creating layer cls_score_cls_score_0_split
I0422 14:31:44.460248  3756 net.cpp:100] Creating Layer cls_score_cls_score_0_split
I0422 14:31:44.460254  3756 net.cpp:434] cls_score_cls_score_0_split <- cls_score
I0422 14:31:44.460259  3756 net.cpp:408] cls_score_cls_score_0_split -> cls_score_cls_score_0_split_0
I0422 14:31:44.460266  3756 net.cpp:408] cls_score_cls_score_0_split -> cls_score_cls_score_0_split_1
I0422 14:31:44.460299  3756 net.cpp:150] Setting up cls_score_cls_score_0_split
I0422 14:31:44.460304  3756 net.cpp:157] Top shape: 1 200 (200)
I0422 14:31:44.460307  3756 net.cpp:157] Top shape: 1 200 (200)
I0422 14:31:44.460310  3756 net.cpp:165] Memory required for data: 10172699112
I0422 14:31:44.460314  3756 layer_factory.hpp:77] Creating layer twin_pred
I0422 14:31:44.460320  3756 net.cpp:100] Creating Layer twin_pred
I0422 14:31:44.460324  3756 net.cpp:434] twin_pred <- fc6_drop6_0_split_1
I0422 14:31:44.460330  3756 net.cpp:408] twin_pred -> twin_pred
I0422 14:31:44.502868  3756 net.cpp:150] Setting up twin_pred
I0422 14:31:44.502890  3756 net.cpp:157] Top shape: 1 400 (400)
I0422 14:31:44.502893  3756 net.cpp:165] Memory required for data: 10172700712
I0422 14:31:44.502902  3756 layer_factory.hpp:77] Creating layer loss_cls
I0422 14:31:44.502916  3756 net.cpp:100] Creating Layer loss_cls
I0422 14:31:44.502921  3756 net.cpp:434] loss_cls <- cls_score_cls_score_0_split_0
I0422 14:31:44.502928  3756 net.cpp:434] loss_cls <- labels_roi-data_1_split_0
I0422 14:31:44.502931  3756 net.cpp:408] loss_cls -> loss_cls
I0422 14:31:44.502988  3756 net.cpp:150] Setting up loss_cls
I0422 14:31:44.502996  3756 net.cpp:157] Top shape: (1)
I0422 14:31:44.503000  3756 net.cpp:160]     with loss weight 1
I0422 14:31:44.503013  3756 net.cpp:165] Memory required for data: 10172700716
I0422 14:31:44.503016  3756 layer_factory.hpp:77] Creating layer loss_twin
I0422 14:31:44.503022  3756 net.cpp:100] Creating Layer loss_twin
I0422 14:31:44.503026  3756 net.cpp:434] loss_twin <- twin_pred
I0422 14:31:44.503031  3756 net.cpp:434] loss_twin <- twin_targets
I0422 14:31:44.503034  3756 net.cpp:434] loss_twin <- twin_inside_weights
I0422 14:31:44.503038  3756 net.cpp:434] loss_twin <- twin_outside_weights
I0422 14:31:44.503042  3756 net.cpp:408] loss_twin -> loss_twin
I0422 14:31:44.503118  3756 net.cpp:150] Setting up loss_twin
I0422 14:31:44.503125  3756 net.cpp:157] Top shape: (1)
I0422 14:31:44.503129  3756 net.cpp:160]     with loss weight 1
I0422 14:31:44.503134  3756 net.cpp:165] Memory required for data: 10172700720
I0422 14:31:44.503136  3756 layer_factory.hpp:77] Creating layer accuracy
I0422 14:31:44.503338  3756 net.cpp:100] Creating Layer accuracy
I0422 14:31:44.503348  3756 net.cpp:434] accuracy <- cls_score_cls_score_0_split_1
I0422 14:31:44.503353  3756 net.cpp:434] accuracy <- labels_roi-data_1_split_1
I0422 14:31:44.503360  3756 net.cpp:408] accuracy -> accuracy
I0422 14:31:44.503435  3756 net.cpp:150] Setting up accuracy
I0422 14:31:44.503446  3756 net.cpp:157] Top shape: 1 (1)
I0422 14:31:44.503451  3756 net.cpp:165] Memory required for data: 10172700724
I0422 14:31:44.503455  3756 net.cpp:228] accuracy does not need backward computation.
I0422 14:31:44.503459  3756 net.cpp:226] loss_twin needs backward computation.
I0422 14:31:44.503464  3756 net.cpp:226] loss_cls needs backward computation.
I0422 14:31:44.503468  3756 net.cpp:226] twin_pred needs backward computation.
I0422 14:31:44.503473  3756 net.cpp:226] cls_score_cls_score_0_split needs backward computation.
I0422 14:31:44.503476  3756 net.cpp:226] cls_score needs backward computation.
I0422 14:31:44.503480  3756 net.cpp:226] fc6_drop6_0_split needs backward computation.
I0422 14:31:44.503484  3756 net.cpp:226] drop6 needs backward computation.
I0422 14:31:44.503489  3756 net.cpp:226] relu6 needs backward computation.
I0422 14:31:44.503491  3756 net.cpp:226] fc6 needs backward computation.
I0422 14:31:44.503494  3756 net.cpp:226] roi_pool5 needs backward computation.
I0422 14:31:44.503499  3756 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0422 14:31:44.503504  3756 net.cpp:226] roi-data needs backward computation.
I0422 14:31:44.503509  3756 net.cpp:226] proposal needs backward computation.
I0422 14:31:44.503512  3756 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0422 14:31:44.503516  3756 net.cpp:226] rpn_cls_prob needs backward computation.
I0422 14:31:44.503520  3756 net.cpp:228] rpn_accuarcy does not need backward computation.
I0422 14:31:44.503525  3756 net.cpp:226] rpn_loss_twin needs backward computation.
I0422 14:31:44.503530  3756 net.cpp:226] rpn_loss_cls needs backward computation.
I0422 14:31:44.503535  3756 net.cpp:228] rpn_labels_rpn-data_0_split does not need backward computation.
I0422 14:31:44.503540  3756 net.cpp:226] rpn-data needs backward computation.
I0422 14:31:44.503545  3756 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0422 14:31:44.503549  3756 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0422 14:31:44.503553  3756 net.cpp:226] rpn_twin_pred_rpn_twin_pred_0_split needs backward computation.
I0422 14:31:44.503557  3756 net.cpp:226] rpn_twin_pred needs backward computation.
I0422 14:31:44.503561  3756 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0422 14:31:44.503566  3756 net.cpp:226] rpn_cls_score needs backward computation.
I0422 14:31:44.503569  3756 net.cpp:226] rpn/output_pool_rpn/output_pool_0_split needs backward computation.
I0422 14:31:44.503573  3756 net.cpp:226] rpn/output_pool needs backward computation.
I0422 14:31:44.503577  3756 net.cpp:226] rpn_relu/3x3_2 needs backward computation.
I0422 14:31:44.503581  3756 net.cpp:226] rpn_conv/3x3_2 needs backward computation.
I0422 14:31:44.503585  3756 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0422 14:31:44.503588  3756 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0422 14:31:44.503592  3756 net.cpp:226] conv5b_relu5b_0_split needs backward computation.
I0422 14:31:44.503597  3756 net.cpp:226] relu5b needs backward computation.
I0422 14:31:44.503600  3756 net.cpp:226] conv5b needs backward computation.
I0422 14:31:44.503603  3756 net.cpp:226] relu5a needs backward computation.
I0422 14:31:44.503608  3756 net.cpp:226] conv5a needs backward computation.
I0422 14:31:44.503612  3756 net.cpp:226] pool4 needs backward computation.
I0422 14:31:44.503615  3756 net.cpp:226] relu4b needs backward computation.
I0422 14:31:44.503619  3756 net.cpp:226] conv4b needs backward computation.
I0422 14:31:44.503623  3756 net.cpp:226] relu4a needs backward computation.
I0422 14:31:44.503626  3756 net.cpp:226] conv4a needs backward computation.
I0422 14:31:44.503631  3756 net.cpp:226] pool3 needs backward computation.
I0422 14:31:44.503634  3756 net.cpp:226] relu3b needs backward computation.
I0422 14:31:44.503638  3756 net.cpp:226] conv3b needs backward computation.
I0422 14:31:44.503643  3756 net.cpp:226] relu3a needs backward computation.
I0422 14:31:44.503645  3756 net.cpp:226] conv3a needs backward computation.
I0422 14:31:44.503649  3756 net.cpp:228] pool2 does not need backward computation.
I0422 14:31:44.503654  3756 net.cpp:228] relu2a does not need backward computation.
I0422 14:31:44.503657  3756 net.cpp:228] conv2a does not need backward computation.
I0422 14:31:44.503661  3756 net.cpp:228] pool1 does not need backward computation.
I0422 14:31:44.503664  3756 net.cpp:228] relu1a does not need backward computation.
I0422 14:31:44.503669  3756 net.cpp:228] conv1a does not need backward computation.
I0422 14:31:44.503674  3756 net.cpp:228] gt_boxes_data_1_split does not need backward computation.
I0422 14:31:44.503679  3756 net.cpp:228] data_data_0_split does not need backward computation.
I0422 14:31:44.503684  3756 net.cpp:228] data does not need backward computation.
I0422 14:31:44.503688  3756 net.cpp:270] This network produces output accuracy
I0422 14:31:44.503692  3756 net.cpp:270] This network produces output loss_cls
I0422 14:31:44.503696  3756 net.cpp:270] This network produces output loss_twin
I0422 14:31:44.503700  3756 net.cpp:270] This network produces output rpn_accuarcy
I0422 14:31:44.503705  3756 net.cpp:270] This network produces output rpn_accuarcy_class
I0422 14:31:44.503708  3756 net.cpp:270] This network produces output rpn_cls_loss
I0422 14:31:44.503711  3756 net.cpp:270] This network produces output rpn_loss_twin
I0422 14:31:44.503746  3756 net.cpp:283] Network initialization done.
I0422 14:31:44.503876  3756 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from ./pretrain/activitynet_iter_30000_3fps.caffemodel
I0422 14:31:45.465873  3756 net.cpp:761] Ignoring source layer pool5
I0422 14:31:45.486292  3756 net.cpp:761] Ignoring source layer fc7
I0422 14:31:45.486315  3756 net.cpp:761] Ignoring source layer relu7
I0422 14:31:45.486317  3756 net.cpp:761] Ignoring source layer drop7
I0422 14:31:45.486322  3756 net.cpp:761] Ignoring source layer fc8-200
I0422 14:31:45.486325  3756 net.cpp:761] Ignoring source layer loss
Solving...
rpn: num_positive 6
rpn: num_negative 58
I0422 14:31:47.375524  3756 accuracy_layer.cpp:96] Accuracy: 0.390625
I0422 14:31:47.375546  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.344828
I0422 14:31:47.375551  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
num fg: 10
num bg: 25
('accuracy: ', 0.0)
I0422 14:31:47.433490  3756 solver.cpp:228] Iteration 0, loss = 168.252
I0422 14:31:47.433540  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:31:47.433550  3756 solver.cpp:244]     Train net output #1: loss_cls = 167.511 (* 1 = 167.511 loss)
I0422 14:31:47.433557  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:31:47.433562  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.390625
I0422 14:31:47.433568  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.344828
I0422 14:31:47.433571  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 14:31:47.433576  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.711967 (* 1 = 0.711967 loss)
I0422 14:31:47.433583  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0290697 (* 1 = 0.0290697 loss)
I0422 14:31:47.433590  3756 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:31:51.658118  3756 accuracy_layer.cpp:96] Accuracy: 0.515625
I0422 14:31:51.658141  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.5
I0422 14:31:51.658146  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.75
TRAIN
num fg: 8
num bg: 12
('accuracy: ', 0.0)
I0422 14:31:51.672894  3756 solver.cpp:228] Iteration 1, loss = 139.961
I0422 14:31:51.672911  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:31:51.672919  3756 solver.cpp:244]     Train net output #1: loss_cls = 139.252 (* 1 = 139.252 loss)
I0422 14:31:51.672924  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:31:51.672929  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.515625
I0422 14:31:51.672932  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.5
I0422 14:31:51.672935  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.75
I0422 14:31:51.672940  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.694252 (* 1 = 0.694252 loss)
I0422 14:31:51.672945  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0142117 (* 1 = 0.0142117 loss)
I0422 14:31:51.672950  3756 sgd_solver.cpp:106] Iteration 1, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:31:55.901669  3756 accuracy_layer.cpp:96] Accuracy: 0.421875
I0422 14:31:55.901690  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.37931
I0422 14:31:55.901695  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
num fg: 9
num bg: 24
('accuracy: ', 0.0)
I0422 14:31:55.916746  3756 solver.cpp:228] Iteration 2, loss = 121.195
I0422 14:31:55.916766  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:31:55.916774  3756 solver.cpp:244]     Train net output #1: loss_cls = 120.468 (* 1 = 120.468 loss)
I0422 14:31:55.916779  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:31:55.916784  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.421875
I0422 14:31:55.916787  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.37931
I0422 14:31:55.916790  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 14:31:55.916796  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.706309 (* 1 = 0.706309 loss)
I0422 14:31:55.916800  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0207997 (* 1 = 0.0207997 loss)
I0422 14:31:55.916806  3756 sgd_solver.cpp:106] Iteration 2, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:32:00.145406  3756 accuracy_layer.cpp:96] Accuracy: 0.4375
I0422 14:32:00.145427  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.419355
I0422 14:32:00.145432  3756 accuracy_layer.cpp:101] Class 1 accuracy : 1
TRAIN
num fg: 9
num bg: 16
('accuracy: ', 0.0)
I0422 14:32:00.160745  3756 solver.cpp:228] Iteration 3, loss = 99.0933
I0422 14:32:00.160763  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:00.160771  3756 solver.cpp:244]     Train net output #1: loss_cls = 98.3854 (* 1 = 98.3854 loss)
I0422 14:32:00.160776  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:00.160781  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.4375
I0422 14:32:00.160784  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.419355
I0422 14:32:00.160789  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 1
I0422 14:32:00.160792  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.704422 (* 1 = 0.704422 loss)
I0422 14:32:00.160802  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0034403 (* 1 = 0.0034403 loss)
I0422 14:32:00.160809  3756 sgd_solver.cpp:106] Iteration 3, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:32:04.393234  3756 accuracy_layer.cpp:96] Accuracy: 0.5
I0422 14:32:04.393255  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.5
I0422 14:32:04.393260  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:32:04.411396  3756 solver.cpp:228] Iteration 4, loss = 57.0111
I0422 14:32:04.411415  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:04.411423  3756 solver.cpp:244]     Train net output #1: loss_cls = 56.2702 (* 1 = 56.2702 loss)
I0422 14:32:04.411429  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:04.411433  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.5
I0422 14:32:04.411438  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.5
I0422 14:32:04.411442  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 14:32:04.411447  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.701073 (* 1 = 0.701073 loss)
I0422 14:32:04.411453  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.03982 (* 1 = 0.03982 loss)
I0422 14:32:04.411458  3756 sgd_solver.cpp:106] Iteration 4, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:32:08.645891  3756 accuracy_layer.cpp:96] Accuracy: 0.5625
I0422 14:32:08.645915  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.568965
I0422 14:32:08.645920  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:32:08.661202  3756 solver.cpp:228] Iteration 5, loss = 17.673
I0422 14:32:08.661221  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:08.661228  3756 solver.cpp:244]     Train net output #1: loss_cls = 16.7848 (* 1 = 16.7848 loss)
I0422 14:32:08.661234  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:08.661238  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.5625
I0422 14:32:08.661242  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.568965
I0422 14:32:08.661245  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 14:32:08.661250  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.819099 (* 1 = 0.819099 loss)
I0422 14:32:08.661255  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0690532 (* 1 = 0.0690532 loss)
I0422 14:32:08.661262  3756 sgd_solver.cpp:106] Iteration 5, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:32:12.898721  3756 accuracy_layer.cpp:96] Accuracy: 0.53125
I0422 14:32:12.898742  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.52381
I0422 14:32:12.898747  3756 accuracy_layer.cpp:101] Class 1 accuracy : 1
TRAIN
num fg: 7
num bg: 18
('accuracy: ', 0.0)
I0422 14:32:12.914070  3756 solver.cpp:228] Iteration 6, loss = 6.08655
I0422 14:32:12.914098  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:12.914106  3756 solver.cpp:244]     Train net output #1: loss_cls = 4.94797 (* 1 = 4.94797 loss)
I0422 14:32:12.914113  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:12.914115  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.53125
I0422 14:32:12.914120  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.52381
I0422 14:32:12.914124  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 1
I0422 14:32:12.914129  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 1.101 (* 1 = 1.101 loss)
I0422 14:32:12.914134  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0375781 (* 1 = 0.0375781 loss)
I0422 14:32:12.914139  3756 sgd_solver.cpp:106] Iteration 6, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:32:17.162986  3756 accuracy_layer.cpp:96] Accuracy: 0.703125
I0422 14:32:17.163008  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.698413
I0422 14:32:17.163012  3756 accuracy_layer.cpp:101] Class 1 accuracy : 1
TRAIN
num fg: 2
num bg: 15
('accuracy: ', 0.0)
I0422 14:32:17.176918  3756 solver.cpp:228] Iteration 7, loss = 6.85914
I0422 14:32:17.176936  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:17.176944  3756 solver.cpp:244]     Train net output #1: loss_cls = 5.86461 (* 1 = 5.86461 loss)
I0422 14:32:17.176949  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:17.176954  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.703125
I0422 14:32:17.176957  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.698413
I0422 14:32:17.176961  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 1
I0422 14:32:17.176965  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.933051 (* 1 = 0.933051 loss)
I0422 14:32:17.176970  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0614761 (* 1 = 0.0614761 loss)
I0422 14:32:17.176975  3756 sgd_solver.cpp:106] Iteration 7, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:32:21.430104  3756 accuracy_layer.cpp:96] Accuracy: 0.734375
I0422 14:32:21.430126  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.775862
I0422 14:32:21.430131  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 6
num bg: 20
('accuracy: ', 0.0)
I0422 14:32:21.445668  3756 solver.cpp:228] Iteration 8, loss = 16.2535
I0422 14:32:21.445686  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:21.445694  3756 solver.cpp:244]     Train net output #1: loss_cls = 14.0529 (* 1 = 14.0529 loss)
I0422 14:32:21.445700  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:21.445704  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.734375
I0422 14:32:21.445708  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.775862
I0422 14:32:21.445713  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 14:32:21.445716  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 1.60663 (* 1 = 1.60663 loss)
I0422 14:32:21.445721  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.593972 (* 1 = 0.593972 loss)
I0422 14:32:21.445726  3756 sgd_solver.cpp:106] Iteration 8, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:32:25.760829  3756 accuracy_layer.cpp:96] Accuracy: 0.6875
I0422 14:32:25.760850  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.741379
I0422 14:32:25.760865  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 5
num bg: 33
('accuracy: ', 0.0)
I0422 14:32:25.780122  3756 solver.cpp:228] Iteration 9, loss = 27.4538
I0422 14:32:25.780143  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:25.780151  3756 solver.cpp:244]     Train net output #1: loss_cls = 25.7056 (* 1 = 25.7056 loss)
I0422 14:32:25.780158  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:25.780161  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.6875
I0422 14:32:25.780166  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.741379
I0422 14:32:25.780170  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:32:25.780175  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 1.32022 (* 1 = 1.32022 loss)
I0422 14:32:25.780180  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.42797 (* 1 = 0.42797 loss)
I0422 14:32:25.780187  3756 sgd_solver.cpp:106] Iteration 9, lr = 0.0001
speed: 4.027s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:32:30.258072  3756 accuracy_layer.cpp:96] Accuracy: 0.859375
I0422 14:32:30.258095  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.913793
I0422 14:32:30.258100  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:32:30.275312  3756 solver.cpp:228] Iteration 10, loss = 10.458
I0422 14:32:30.275332  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:30.275341  3756 solver.cpp:244]     Train net output #1: loss_cls = 9.84742 (* 1 = 9.84742 loss)
I0422 14:32:30.275346  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:30.275351  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.859375
I0422 14:32:30.275354  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.913793
I0422 14:32:30.275358  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 14:32:30.275362  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.498051 (* 1 = 0.498051 loss)
I0422 14:32:30.275374  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.112545 (* 1 = 0.112545 loss)
I0422 14:32:30.275379  3756 sgd_solver.cpp:106] Iteration 10, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:32:34.723748  3756 accuracy_layer.cpp:96] Accuracy: 0.859375
I0422 14:32:34.723774  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.887097
I0422 14:32:34.723779  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 36
('accuracy: ', 0.0)
I0422 14:32:34.743316  3756 solver.cpp:228] Iteration 11, loss = 23.4815
I0422 14:32:34.743333  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:34.743341  3756 solver.cpp:244]     Train net output #1: loss_cls = 22.8696 (* 1 = 22.8696 loss)
I0422 14:32:34.743347  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:34.743351  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.859375
I0422 14:32:34.743355  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.887097
I0422 14:32:34.743360  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:32:34.743366  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.489534 (* 1 = 0.489534 loss)
I0422 14:32:34.743371  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.122333 (* 1 = 0.122333 loss)
I0422 14:32:34.743376  3756 sgd_solver.cpp:106] Iteration 11, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:32:39.137745  3756 accuracy_layer.cpp:96] Accuracy: 0.78125
I0422 14:32:39.137766  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.793103
I0422 14:32:39.137771  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 14:32:39.154116  3756 solver.cpp:228] Iteration 12, loss = 12.3255
I0422 14:32:39.154135  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:39.154144  3756 solver.cpp:244]     Train net output #1: loss_cls = 11.8376 (* 1 = 11.8376 loss)
I0422 14:32:39.154150  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:39.154153  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.78125
I0422 14:32:39.154157  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.793103
I0422 14:32:39.154161  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 14:32:39.154166  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.411582 (* 1 = 0.411582 loss)
I0422 14:32:39.154171  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0763091 (* 1 = 0.0763091 loss)
I0422 14:32:39.154176  3756 sgd_solver.cpp:106] Iteration 12, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:32:43.522547  3756 accuracy_layer.cpp:96] Accuracy: 0.8125
I0422 14:32:43.522568  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.810345
I0422 14:32:43.522572  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:32:43.538709  3756 solver.cpp:228] Iteration 13, loss = 5.23888
I0422 14:32:43.538725  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:43.538733  3756 solver.cpp:244]     Train net output #1: loss_cls = 4.76261 (* 1 = 4.76261 loss)
I0422 14:32:43.538739  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:43.538743  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.8125
I0422 14:32:43.538746  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.810345
I0422 14:32:43.538750  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 14:32:43.538755  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.446922 (* 1 = 0.446922 loss)
I0422 14:32:43.538777  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.029345 (* 1 = 0.029345 loss)
I0422 14:32:43.538785  3756 sgd_solver.cpp:106] Iteration 13, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:32:47.903605  3756 accuracy_layer.cpp:96] Accuracy: 0.859375
I0422 14:32:47.903633  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.896552
I0422 14:32:47.903637  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:32:47.921165  3756 solver.cpp:228] Iteration 14, loss = 4.43992
I0422 14:32:47.921185  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:47.921193  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.88168 (* 1 = 3.88168 loss)
I0422 14:32:47.921200  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:47.921203  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.859375
I0422 14:32:47.921207  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.896552
I0422 14:32:47.921212  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 14:32:47.921217  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.546584 (* 1 = 0.546584 loss)
I0422 14:32:47.921228  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0116563 (* 1 = 0.0116563 loss)
I0422 14:32:47.921236  3756 sgd_solver.cpp:106] Iteration 14, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:32:52.252835  3756 accuracy_layer.cpp:96] Accuracy: 0.890625
I0422 14:32:52.252864  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.913793
I0422 14:32:52.252881  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
num fg: 9
num bg: 24
('accuracy: ', 0.0)
I0422 14:32:52.268335  3756 solver.cpp:228] Iteration 15, loss = 4.4089
I0422 14:32:52.268363  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:52.268373  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.83295 (* 1 = 3.83295 loss)
I0422 14:32:52.268378  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:52.268381  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.890625
I0422 14:32:52.268385  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.913793
I0422 14:32:52.268389  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 14:32:52.268394  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.560516 (* 1 = 0.560516 loss)
I0422 14:32:52.268399  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0154305 (* 1 = 0.0154305 loss)
I0422 14:32:52.268404  3756 sgd_solver.cpp:106] Iteration 15, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:32:56.634075  3756 accuracy_layer.cpp:96] Accuracy: 0.828125
I0422 14:32:56.634104  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.844828
I0422 14:32:56.634114  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:32:56.651552  3756 solver.cpp:228] Iteration 16, loss = 2.94635
I0422 14:32:56.651574  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:32:56.651583  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.35733 (* 1 = 2.35733 loss)
I0422 14:32:56.651588  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:32:56.651592  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.828125
I0422 14:32:56.651597  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.844828
I0422 14:32:56.651600  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 14:32:56.651605  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.575625 (* 1 = 0.575625 loss)
I0422 14:32:56.651610  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0134 (* 1 = 0.0134 loss)
I0422 14:32:56.651617  3756 sgd_solver.cpp:106] Iteration 16, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:33:01.019327  3756 accuracy_layer.cpp:96] Accuracy: 0.8125
I0422 14:33:01.019361  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.827586
I0422 14:33:01.019366  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:33:01.035241  3756 solver.cpp:228] Iteration 17, loss = 3.30651
I0422 14:33:01.035259  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:01.035267  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.71064 (* 1 = 2.71064 loss)
I0422 14:33:01.035272  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:01.035276  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.8125
I0422 14:33:01.035280  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.827586
I0422 14:33:01.035284  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 14:33:01.035290  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.583889 (* 1 = 0.583889 loss)
I0422 14:33:01.035293  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0119798 (* 1 = 0.0119798 loss)
I0422 14:33:01.035300  3756 sgd_solver.cpp:106] Iteration 17, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:33:05.367517  3756 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 14:33:05.367539  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.862069
I0422 14:33:05.367543  3756 accuracy_layer.cpp:101] Class 1 accuracy : 1
TRAIN
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 14:33:05.383159  3756 solver.cpp:228] Iteration 18, loss = 3.15334
I0422 14:33:05.383177  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:05.383185  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.59003 (* 1 = 2.59003 loss)
I0422 14:33:05.383190  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:05.383194  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 14:33:05.383198  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.862069
I0422 14:33:05.383203  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 1
I0422 14:33:05.383206  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.536513 (* 1 = 0.536513 loss)
I0422 14:33:05.383211  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0267922 (* 1 = 0.0267922 loss)
I0422 14:33:05.383218  3756 sgd_solver.cpp:106] Iteration 18, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:33:09.736771  3756 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 14:33:09.736793  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.87931
I0422 14:33:09.736796  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
num fg: 10
num bg: 26
('accuracy: ', 0.0)
I0422 14:33:09.754467  3756 solver.cpp:228] Iteration 19, loss = 3.48611
I0422 14:33:09.754492  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:09.754500  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.96964 (* 1 = 2.96964 loss)
I0422 14:33:09.754505  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:09.754510  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 14:33:09.754514  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.87931
I0422 14:33:09.754518  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 14:33:09.754524  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.469186 (* 1 = 0.469186 loss)
I0422 14:33:09.754529  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0472842 (* 1 = 0.0472842 loss)
I0422 14:33:09.754536  3756 sgd_solver.cpp:106] Iteration 19, lr = 0.0001
speed: 4.212s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:33:14.118288  3756 accuracy_layer.cpp:96] Accuracy: 0.796875
I0422 14:33:14.118319  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.810345
I0422 14:33:14.118324  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 14:33:14.134235  3756 solver.cpp:228] Iteration 20, loss = 3.59994
I0422 14:33:14.134253  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:14.134261  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.08199 (* 1 = 3.08199 loss)
I0422 14:33:14.134266  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:14.134270  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.796875
I0422 14:33:14.134274  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.810345
I0422 14:33:14.134277  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 14:33:14.134282  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.456731 (* 1 = 0.456731 loss)
I0422 14:33:14.134287  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0612242 (* 1 = 0.0612242 loss)
I0422 14:33:14.134294  3756 sgd_solver.cpp:106] Iteration 20, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:33:18.473697  3756 accuracy_layer.cpp:96] Accuracy: 0.75
I0422 14:33:18.473721  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.758065
I0422 14:33:18.473724  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 8
num bg: 22
('accuracy: ', 0.0)
I0422 14:33:18.489573  3756 solver.cpp:228] Iteration 21, loss = 3.79971
I0422 14:33:18.489589  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:18.489596  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.31527 (* 1 = 3.31527 loss)
I0422 14:33:18.489601  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:18.489605  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.75
I0422 14:33:18.489609  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.758065
I0422 14:33:18.489612  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 14:33:18.489616  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.463948 (* 1 = 0.463948 loss)
I0422 14:33:18.489621  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0204876 (* 1 = 0.0204876 loss)
I0422 14:33:18.489627  3756 sgd_solver.cpp:106] Iteration 21, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:33:22.820484  3756 accuracy_layer.cpp:96] Accuracy: 0.890625
I0422 14:33:22.820507  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.904762
I0422 14:33:22.820513  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 5
num bg: 23
('accuracy: ', 0.0)
I0422 14:33:22.836467  3756 solver.cpp:228] Iteration 22, loss = 2.13943
I0422 14:33:22.836486  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:22.836494  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.62676 (* 1 = 1.62676 loss)
I0422 14:33:22.836499  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:22.836505  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.890625
I0422 14:33:22.836509  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.904762
I0422 14:33:22.836514  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:33:22.836520  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.502582 (* 1 = 0.502582 loss)
I0422 14:33:22.836525  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0100859 (* 1 = 0.0100859 loss)
I0422 14:33:22.836541  3756 sgd_solver.cpp:106] Iteration 22, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:33:27.193534  3756 accuracy_layer.cpp:96] Accuracy: 0.8125
I0422 14:33:27.193557  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.844828
I0422 14:33:27.193572  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 7
num bg: 28
('accuracy: ', 0.0)
I0422 14:33:27.209436  3756 solver.cpp:228] Iteration 23, loss = 3.62046
I0422 14:33:27.209452  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:27.209460  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.06147 (* 1 = 3.06147 loss)
I0422 14:33:27.209465  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:27.209468  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.8125
I0422 14:33:27.209471  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.844828
I0422 14:33:27.209475  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 14:33:27.209481  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.527039 (* 1 = 0.527039 loss)
I0422 14:33:27.209486  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0319583 (* 1 = 0.0319583 loss)
I0422 14:33:27.209491  3756 sgd_solver.cpp:106] Iteration 23, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:33:31.538262  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:33:31.538285  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.966667
I0422 14:33:31.538290  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 21
('accuracy: ', 0.0)
I0422 14:33:31.554105  3756 solver.cpp:228] Iteration 24, loss = 3.46933
I0422 14:33:31.554122  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:31.554131  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.92423 (* 1 = 2.92423 loss)
I0422 14:33:31.554136  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:31.554139  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:33:31.554143  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.966667
I0422 14:33:31.554147  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:33:31.554152  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.519936 (* 1 = 0.519936 loss)
I0422 14:33:31.554157  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0251685 (* 1 = 0.0251685 loss)
I0422 14:33:31.554162  3756 sgd_solver.cpp:106] Iteration 24, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:33:35.883657  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:33:35.883678  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.920635
I0422 14:33:35.883683  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 4
num bg: 24
('accuracy: ', 0.0)
I0422 14:33:35.902648  3756 solver.cpp:228] Iteration 25, loss = 1.81567
I0422 14:33:35.902676  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:35.902686  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.30092 (* 1 = 1.30092 loss)
I0422 14:33:35.902694  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:35.902700  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:33:35.902705  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.920635
I0422 14:33:35.902711  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:33:35.902717  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.503536 (* 1 = 0.503536 loss)
I0422 14:33:35.902724  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0112187 (* 1 = 0.0112187 loss)
I0422 14:33:35.902730  3756 sgd_solver.cpp:106] Iteration 25, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:33:40.231897  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:33:40.231919  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.918033
I0422 14:33:40.231923  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
num fg: 7
num bg: 24
('accuracy: ', 0.0)
I0422 14:33:40.250280  3756 solver.cpp:228] Iteration 26, loss = 2.84477
I0422 14:33:40.250303  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:40.250311  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.32016 (* 1 = 2.32016 loss)
I0422 14:33:40.250316  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:40.250320  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:33:40.250325  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.918033
I0422 14:33:40.250329  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 14:33:40.250334  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.507739 (* 1 = 0.507739 loss)
I0422 14:33:40.250339  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0168626 (* 1 = 0.0168626 loss)
I0422 14:33:40.250345  3756 sgd_solver.cpp:106] Iteration 26, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:33:44.599344  3756 accuracy_layer.cpp:96] Accuracy: 0.84375
I0422 14:33:44.599366  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.896552
I0422 14:33:44.599370  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 9
num bg: 22
('accuracy: ', 0.0)
I0422 14:33:44.615339  3756 solver.cpp:228] Iteration 27, loss = 3.95425
I0422 14:33:44.615356  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:44.615363  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.48311 (* 1 = 3.48311 loss)
I0422 14:33:44.615368  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:44.615372  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.84375
I0422 14:33:44.615376  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.896552
I0422 14:33:44.615380  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 14:33:44.615384  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.362079 (* 1 = 0.362079 loss)
I0422 14:33:44.615389  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.109064 (* 1 = 0.109064 loss)
I0422 14:33:44.615394  3756 sgd_solver.cpp:106] Iteration 27, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:33:48.956498  3756 accuracy_layer.cpp:96] Accuracy: 0.859375
I0422 14:33:48.956521  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.931035
I0422 14:33:48.956526  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 11
num bg: 25
('accuracy: ', 0.0)
I0422 14:33:48.972975  3756 solver.cpp:228] Iteration 28, loss = 3.21409
I0422 14:33:48.972995  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:48.973002  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.75805 (* 1 = 2.75805 loss)
I0422 14:33:48.973007  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:48.973011  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.859375
I0422 14:33:48.973016  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.931035
I0422 14:33:48.973019  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:33:48.973024  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.384244 (* 1 = 0.384244 loss)
I0422 14:33:48.973029  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0717959 (* 1 = 0.0717959 loss)
I0422 14:33:48.973034  3756 sgd_solver.cpp:106] Iteration 28, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:33:53.285147  3756 accuracy_layer.cpp:96] Accuracy: 0.84375
I0422 14:33:53.285169  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.913793
I0422 14:33:53.285184  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 14:33:53.302014  3756 solver.cpp:228] Iteration 29, loss = 2.23209
I0422 14:33:53.302037  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:53.302045  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.765 (* 1 = 1.765 loss)
I0422 14:33:53.302050  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:53.302055  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.84375
I0422 14:33:53.302059  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.913793
I0422 14:33:53.302064  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:33:53.302069  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.398014 (* 1 = 0.398014 loss)
I0422 14:33:53.302075  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0690745 (* 1 = 0.0690745 loss)
I0422 14:33:53.302081  3756 sgd_solver.cpp:106] Iteration 29, lr = 0.0001
speed: 4.260s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:33:57.638800  3756 accuracy_layer.cpp:96] Accuracy: 0.890625
I0422 14:33:57.638823  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.965517
I0422 14:33:57.638830  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 7
num bg: 27
('accuracy: ', 0.0)
I0422 14:33:57.654613  3756 solver.cpp:228] Iteration 30, loss = 2.8677
I0422 14:33:57.654644  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:33:57.654651  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.41998 (* 1 = 2.41998 loss)
I0422 14:33:57.654656  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:33:57.654660  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.890625
I0422 14:33:57.654665  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.965517
I0422 14:33:57.654669  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:33:57.654675  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.398912 (* 1 = 0.398912 loss)
I0422 14:33:57.654678  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0488065 (* 1 = 0.0488065 loss)
I0422 14:33:57.654690  3756 sgd_solver.cpp:106] Iteration 30, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:34:01.982954  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:34:01.982975  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.967213
I0422 14:34:01.982980  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 15
('accuracy: ', 0.0)
I0422 14:34:01.998572  3756 solver.cpp:228] Iteration 31, loss = 3.35422
I0422 14:34:01.998591  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:01.998600  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.87848 (* 1 = 2.87848 loss)
I0422 14:34:01.998605  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:01.998610  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:34:01.998613  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.967213
I0422 14:34:01.998617  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:34:01.998622  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.456367 (* 1 = 0.456367 loss)
I0422 14:34:01.998627  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0193775 (* 1 = 0.0193775 loss)
I0422 14:34:01.998632  3756 sgd_solver.cpp:106] Iteration 31, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:34:06.358969  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:34:06.358990  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.983333
I0422 14:34:06.358995  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 26
('accuracy: ', 0.0)
I0422 14:34:06.375546  3756 solver.cpp:228] Iteration 32, loss = 3.8606
I0422 14:34:06.375566  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:06.375572  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.36075 (* 1 = 3.36075 loss)
I0422 14:34:06.375577  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:06.375581  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:34:06.375586  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.983333
I0422 14:34:06.375588  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:34:06.375594  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.477778 (* 1 = 0.477778 loss)
I0422 14:34:06.375599  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0220654 (* 1 = 0.0220654 loss)
I0422 14:34:06.375604  3756 sgd_solver.cpp:106] Iteration 32, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:34:10.691033  3756 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 14:34:10.691056  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.965517
I0422 14:34:10.691061  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 14:34:10.706333  3756 solver.cpp:228] Iteration 33, loss = 3.74488
I0422 14:34:10.706351  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:10.706359  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.17447 (* 1 = 3.17447 loss)
I0422 14:34:10.706364  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:10.706368  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 14:34:10.706372  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.965517
I0422 14:34:10.706377  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:34:10.706380  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.557893 (* 1 = 0.557893 loss)
I0422 14:34:10.706385  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0125164 (* 1 = 0.0125164 loss)
I0422 14:34:10.706390  3756 sgd_solver.cpp:106] Iteration 33, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:34:15.020882  3756 accuracy_layer.cpp:96] Accuracy: 0.859375
I0422 14:34:15.020905  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.931035
I0422 14:34:15.020915  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 11
num bg: 24
('accuracy: ', 0.0)
I0422 14:34:15.036648  3756 solver.cpp:228] Iteration 34, loss = 4.17028
I0422 14:34:15.036665  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:15.036674  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.65504 (* 1 = 3.65504 loss)
I0422 14:34:15.036680  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:15.036684  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.859375
I0422 14:34:15.036690  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.931035
I0422 14:34:15.036695  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:34:15.036700  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.502285 (* 1 = 0.502285 loss)
I0422 14:34:15.036705  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0129497 (* 1 = 0.0129497 loss)
I0422 14:34:15.036710  3756 sgd_solver.cpp:106] Iteration 34, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:34:19.360471  3756 accuracy_layer.cpp:96] Accuracy: 0.890625
I0422 14:34:19.360493  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.934426
I0422 14:34:19.360497  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 16
('accuracy: ', 0.0)
I0422 14:34:19.376090  3756 solver.cpp:228] Iteration 35, loss = 3.42576
I0422 14:34:19.376106  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:19.376114  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.93212 (* 1 = 2.93212 loss)
I0422 14:34:19.376121  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:19.376124  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.890625
I0422 14:34:19.376128  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.934426
I0422 14:34:19.376132  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:34:19.376137  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.480982 (* 1 = 0.480982 loss)
I0422 14:34:19.376142  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0126506 (* 1 = 0.0126506 loss)
I0422 14:34:19.376147  3756 sgd_solver.cpp:106] Iteration 35, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:34:23.716002  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:34:23.716027  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:34:23.716030  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 10
num bg: 28
('accuracy: ', 0.0)
I0422 14:34:23.731884  3756 solver.cpp:228] Iteration 36, loss = 2.48331
I0422 14:34:23.731901  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:23.731909  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.99255 (* 1 = 1.99255 loss)
I0422 14:34:23.731914  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:23.731919  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:34:23.731922  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:34:23.731926  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:34:23.731931  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.476524 (* 1 = 0.476524 loss)
I0422 14:34:23.731936  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0142373 (* 1 = 0.0142373 loss)
I0422 14:34:23.731941  3756 sgd_solver.cpp:106] Iteration 36, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:34:28.082026  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:34:28.082047  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:34:28.082052  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 22
('accuracy: ', 0.0)
I0422 14:34:28.097980  3756 solver.cpp:228] Iteration 37, loss = 3.76535
I0422 14:34:28.097997  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:28.098006  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.30778 (* 1 = 3.30778 loss)
I0422 14:34:28.098011  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:28.098016  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:34:28.098019  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:34:28.098022  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:34:28.098027  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.419863 (* 1 = 0.419863 loss)
I0422 14:34:28.098032  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0377136 (* 1 = 0.0377136 loss)
I0422 14:34:28.098037  3756 sgd_solver.cpp:106] Iteration 37, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:34:32.396113  3756 accuracy_layer.cpp:96] Accuracy: 0.890625
I0422 14:34:32.396136  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.965517
I0422 14:34:32.396140  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:34:32.411468  3756 solver.cpp:228] Iteration 38, loss = 2.57448
I0422 14:34:32.411495  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:32.411504  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.08888 (* 1 = 2.08888 loss)
I0422 14:34:32.411509  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:32.411512  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.890625
I0422 14:34:32.411522  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.965517
I0422 14:34:32.411525  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:34:32.411532  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.450982 (* 1 = 0.450982 loss)
I0422 14:34:32.411538  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0346199 (* 1 = 0.0346199 loss)
I0422 14:34:32.411545  3756 sgd_solver.cpp:106] Iteration 38, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:34:36.740499  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:34:36.740520  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.95082
I0422 14:34:36.740525  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 23
('accuracy: ', 0.0)
I0422 14:34:36.756489  3756 solver.cpp:228] Iteration 39, loss = 2.74641
I0422 14:34:36.756516  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:36.756536  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.25536 (* 1 = 2.25536 loss)
I0422 14:34:36.756541  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:36.756544  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:34:36.756548  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.95082
I0422 14:34:36.756552  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:34:36.756557  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.483297 (* 1 = 0.483297 loss)
I0422 14:34:36.756562  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00775261 (* 1 = 0.00775261 loss)
I0422 14:34:36.756568  3756 sgd_solver.cpp:106] Iteration 39, lr = 0.0001
speed: 4.281s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:34:41.085552  3756 accuracy_layer.cpp:96] Accuracy: 0.890625
I0422 14:34:41.085575  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.965517
I0422 14:34:41.085580  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:34:41.101377  3756 solver.cpp:228] Iteration 40, loss = 2.29937
I0422 14:34:41.101395  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:41.101402  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.81727 (* 1 = 1.81727 loss)
I0422 14:34:41.101408  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:41.101413  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.890625
I0422 14:34:41.101416  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.965517
I0422 14:34:41.101420  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:34:41.101424  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.469282 (* 1 = 0.469282 loss)
I0422 14:34:41.101429  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0128092 (* 1 = 0.0128092 loss)
I0422 14:34:41.101435  3756 sgd_solver.cpp:106] Iteration 40, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:34:45.449252  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:34:45.449275  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.936508
I0422 14:34:45.449280  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 17
('accuracy: ', 0.0)
I0422 14:34:45.465039  3756 solver.cpp:228] Iteration 41, loss = 3.55885
I0422 14:34:45.465057  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:45.465065  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.07852 (* 1 = 3.07852 loss)
I0422 14:34:45.465070  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:45.465075  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:34:45.465078  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.936508
I0422 14:34:45.465082  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:34:45.465086  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.471831 (* 1 = 0.471831 loss)
I0422 14:34:45.465091  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0084967 (* 1 = 0.0084967 loss)
I0422 14:34:45.465096  3756 sgd_solver.cpp:106] Iteration 41, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:34:49.789947  3756 accuracy_layer.cpp:96] Accuracy: 0.890625
I0422 14:34:49.789968  3756 accuracy_layer.cpp:101] Class 0 accuracy : 0.965517
I0422 14:34:49.789973  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 14:34:49.805613  3756 solver.cpp:228] Iteration 42, loss = 2.82626
I0422 14:34:49.805629  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:49.805637  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.33554 (* 1 = 2.33554 loss)
I0422 14:34:49.805642  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:49.805646  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.890625
I0422 14:34:49.805650  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.965517
I0422 14:34:49.805655  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:34:49.805658  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.480114 (* 1 = 0.480114 loss)
I0422 14:34:49.805663  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0106053 (* 1 = 0.0106053 loss)
I0422 14:34:49.805670  3756 sgd_solver.cpp:106] Iteration 42, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:34:54.120438  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:34:54.120461  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:34:54.120465  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 14:34:54.136205  3756 solver.cpp:228] Iteration 43, loss = 2.37717
I0422 14:34:54.136227  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:54.136235  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.88477 (* 1 = 1.88477 loss)
I0422 14:34:54.136241  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:54.136245  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:34:54.136250  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:34:54.136252  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:34:54.136257  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.48067 (* 1 = 0.48067 loss)
I0422 14:34:54.136262  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0117345 (* 1 = 0.0117345 loss)
I0422 14:34:54.136267  3756 sgd_solver.cpp:106] Iteration 43, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:34:58.470007  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:34:58.470029  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:34:58.470036  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 24
('accuracy: ', 0.0)
I0422 14:34:58.485968  3756 solver.cpp:228] Iteration 44, loss = 3.4901
I0422 14:34:58.485985  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:34:58.486003  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.9925 (* 1 = 2.9925 loss)
I0422 14:34:58.486009  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:34:58.486013  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:34:58.486017  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:34:58.486021  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:34:58.486026  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.486916 (* 1 = 0.486916 loss)
I0422 14:34:58.486030  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0106768 (* 1 = 0.0106768 loss)
I0422 14:34:58.486040  3756 sgd_solver.cpp:106] Iteration 44, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:02.812955  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:02.812976  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:02.812981  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 26
('accuracy: ', 0.0)
I0422 14:35:02.828755  3756 solver.cpp:228] Iteration 45, loss = 1.72105
I0422 14:35:02.828775  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:02.828784  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.32522 (* 1 = 1.32522 loss)
I0422 14:35:02.828790  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:02.828794  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:02.828799  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:02.828801  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:02.828806  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.38294 (* 1 = 0.38294 loss)
I0422 14:35:02.828811  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0128905 (* 1 = 0.0128905 loss)
I0422 14:35:02.828817  3756 sgd_solver.cpp:106] Iteration 45, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:07.131342  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:07.131363  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:07.131368  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:35:07.147089  3756 solver.cpp:228] Iteration 46, loss = 2.93257
I0422 14:35:07.147105  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:07.147125  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.4699 (* 1 = 2.4699 loss)
I0422 14:35:07.147130  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:07.147135  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:07.147140  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:07.147142  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:07.147147  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.447616 (* 1 = 0.447616 loss)
I0422 14:35:07.147151  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0150562 (* 1 = 0.0150562 loss)
I0422 14:35:07.147157  3756 sgd_solver.cpp:106] Iteration 46, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:11.485096  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:11.485118  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:11.485123  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:35:11.501081  3756 solver.cpp:228] Iteration 47, loss = 3.32086
I0422 14:35:11.501098  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:11.501107  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.94071 (* 1 = 2.94071 loss)
I0422 14:35:11.501112  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:11.501116  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:11.501121  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:11.501123  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:11.501128  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.369825 (* 1 = 0.369825 loss)
I0422 14:35:11.501133  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0103192 (* 1 = 0.0103192 loss)
I0422 14:35:11.501139  3756 sgd_solver.cpp:106] Iteration 47, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:15.841881  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:15.841902  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:15.841908  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 25
('accuracy: ', 0.0)
I0422 14:35:15.859938  3756 solver.cpp:228] Iteration 48, loss = 1.87543
I0422 14:35:15.859961  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:15.859969  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.49672 (* 1 = 1.49672 loss)
I0422 14:35:15.859975  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:15.859980  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:15.859985  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:15.859989  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:15.859995  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.366639 (* 1 = 0.366639 loss)
I0422 14:35:15.860002  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0120725 (* 1 = 0.0120725 loss)
I0422 14:35:15.860008  3756 sgd_solver.cpp:106] Iteration 48, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:35:20.159307  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:35:20.159329  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:20.159333  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 22
('accuracy: ', 0.0)
I0422 14:35:20.174921  3756 solver.cpp:228] Iteration 49, loss = 3.00489
I0422 14:35:20.174939  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:20.174947  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.5878 (* 1 = 2.5878 loss)
I0422 14:35:20.174952  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:20.174955  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:35:20.174959  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:20.174963  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:20.174968  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.390743 (* 1 = 0.390743 loss)
I0422 14:35:20.174973  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0263461 (* 1 = 0.0263461 loss)
I0422 14:35:20.174978  3756 sgd_solver.cpp:106] Iteration 49, lr = 0.0001
speed: 4.293s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:24.489266  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:24.489297  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:24.489301  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 14:35:24.504954  3756 solver.cpp:228] Iteration 50, loss = 2.39987
I0422 14:35:24.504986  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:24.504993  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.00302 (* 1 = 2.00302 loss)
I0422 14:35:24.504998  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:24.505002  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:24.505007  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:24.505010  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:24.505015  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.386037 (* 1 = 0.386037 loss)
I0422 14:35:24.505019  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0108116 (* 1 = 0.0108116 loss)
I0422 14:35:24.505025  3756 sgd_solver.cpp:106] Iteration 50, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:28.836887  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:28.836910  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:28.836915  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 25
('accuracy: ', 0.0)
I0422 14:35:28.853194  3756 solver.cpp:228] Iteration 51, loss = 3.38426
I0422 14:35:28.853221  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:28.853235  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.00267 (* 1 = 3.00267 loss)
I0422 14:35:28.853246  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:28.853255  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:28.853272  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:28.853281  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:28.853289  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.370034 (* 1 = 0.370034 loss)
I0422 14:35:28.853305  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0115553 (* 1 = 0.0115553 loss)
I0422 14:35:28.853322  3756 sgd_solver.cpp:106] Iteration 51, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:33.165948  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:33.165971  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:33.165974  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 14:35:33.181706  3756 solver.cpp:228] Iteration 52, loss = 2.77361
I0422 14:35:33.181725  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:33.181732  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.39768 (* 1 = 2.39768 loss)
I0422 14:35:33.181737  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:33.181741  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:33.181746  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:33.181749  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:33.181753  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.366855 (* 1 = 0.366855 loss)
I0422 14:35:33.181758  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00907428 (* 1 = 0.00907428 loss)
I0422 14:35:33.181766  3756 sgd_solver.cpp:106] Iteration 52, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:37.488353  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:37.488375  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:37.488380  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 24
('accuracy: ', 0.0)
I0422 14:35:37.503945  3756 solver.cpp:228] Iteration 53, loss = 2.96255
I0422 14:35:37.503963  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:37.503971  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.53492 (* 1 = 2.53492 loss)
I0422 14:35:37.503976  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:37.503980  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:37.503984  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:37.503988  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:37.503993  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.421573 (* 1 = 0.421573 loss)
I0422 14:35:37.503998  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00605422 (* 1 = 0.00605422 loss)
I0422 14:35:37.504004  3756 sgd_solver.cpp:106] Iteration 53, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:41.809562  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:41.809583  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:41.809597  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 23
('accuracy: ', 0.0)
I0422 14:35:41.827491  3756 solver.cpp:228] Iteration 54, loss = 2.9474
I0422 14:35:41.827514  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:41.827523  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.51483 (* 1 = 2.51483 loss)
I0422 14:35:41.827530  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:41.827534  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:41.827539  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:41.827543  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:41.827549  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.424536 (* 1 = 0.424536 loss)
I0422 14:35:41.827555  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00803183 (* 1 = 0.00803183 loss)
I0422 14:35:41.827561  3756 sgd_solver.cpp:106] Iteration 54, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:46.157558  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:46.157579  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:46.157583  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 23
('accuracy: ', 0.0)
I0422 14:35:46.173295  3756 solver.cpp:228] Iteration 55, loss = 2.78573
I0422 14:35:46.173322  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:46.173331  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.33764 (* 1 = 2.33764 loss)
I0422 14:35:46.173336  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:46.173341  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:46.173344  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:46.173347  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:46.173352  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.4392 (* 1 = 0.4392 loss)
I0422 14:35:46.173357  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00889509 (* 1 = 0.00889509 loss)
I0422 14:35:46.173362  3756 sgd_solver.cpp:106] Iteration 55, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:35:50.477737  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:35:50.477758  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:50.477762  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 21
('accuracy: ', 0.0)
I0422 14:35:50.493932  3756 solver.cpp:228] Iteration 56, loss = 2.93355
I0422 14:35:50.493952  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:50.493960  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.48361 (* 1 = 2.48361 loss)
I0422 14:35:50.493966  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:50.493970  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:35:50.493974  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:50.493978  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:50.493983  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.437747 (* 1 = 0.437747 loss)
I0422 14:35:50.493988  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0121904 (* 1 = 0.0121904 loss)
I0422 14:35:50.493993  3756 sgd_solver.cpp:106] Iteration 56, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:54.815101  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:54.815124  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:54.815129  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 21
('accuracy: ', 0.0)
I0422 14:35:54.831112  3756 solver.cpp:228] Iteration 57, loss = 3.31924
I0422 14:35:54.831130  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:54.831138  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.84858 (* 1 = 2.84858 loss)
I0422 14:35:54.831143  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:54.831147  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:54.831151  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:54.831156  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:54.831161  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.46214 (* 1 = 0.46214 loss)
I0422 14:35:54.831166  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00852694 (* 1 = 0.00852694 loss)
I0422 14:35:54.831171  3756 sgd_solver.cpp:106] Iteration 57, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:35:59.173099  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:35:59.173120  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:35:59.173125  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 28
('accuracy: ', 0.0)
I0422 14:35:59.189277  3756 solver.cpp:228] Iteration 58, loss = 2.37091
I0422 14:35:59.189297  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:35:59.189306  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.93295 (* 1 = 1.93295 loss)
I0422 14:35:59.189311  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:35:59.189314  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:35:59.189318  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:35:59.189321  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:35:59.189327  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.429199 (* 1 = 0.429199 loss)
I0422 14:35:59.189332  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00876145 (* 1 = 0.00876145 loss)
I0422 14:35:59.189337  3756 sgd_solver.cpp:106] Iteration 58, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:36:03.501606  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:36:03.501628  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:03.501633  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 12
num bg: 26
('accuracy: ', 0.0)
I0422 14:36:03.517418  3756 solver.cpp:228] Iteration 59, loss = 3.16011
I0422 14:36:03.517436  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:03.517443  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.78917 (* 1 = 2.78917 loss)
I0422 14:36:03.517448  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:03.517452  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:36:03.517455  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:03.517458  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:03.517463  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.3649 (* 1 = 0.3649 loss)
I0422 14:36:03.517468  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00604077 (* 1 = 0.00604077 loss)
I0422 14:36:03.517473  3756 sgd_solver.cpp:106] Iteration 59, lr = 0.0001
speed: 4.300s / iter
rpn: num_positive 5
rpn: num_negative 59
I0422 14:36:07.810446  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:36:07.810468  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:07.810473  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 22
('accuracy: ', 0.0)
I0422 14:36:07.825949  3756 solver.cpp:228] Iteration 60, loss = 2.73735
I0422 14:36:07.825975  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:07.825984  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.39787 (* 1 = 2.39787 loss)
I0422 14:36:07.825989  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:07.825994  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:36:07.825997  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:07.826000  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:07.826005  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.31889 (* 1 = 0.31889 loss)
I0422 14:36:07.826010  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0205897 (* 1 = 0.0205897 loss)
I0422 14:36:07.826035  3756 sgd_solver.cpp:106] Iteration 60, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:36:12.117558  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:36:12.117590  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:12.117595  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 14:36:12.133116  3756 solver.cpp:228] Iteration 61, loss = 2.83873
I0422 14:36:12.133146  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:12.133153  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.55744 (* 1 = 2.55744 loss)
I0422 14:36:12.133158  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:12.133163  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:36:12.133167  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:12.133172  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:12.133175  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.270858 (* 1 = 0.270858 loss)
I0422 14:36:12.133180  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0104324 (* 1 = 0.0104324 loss)
I0422 14:36:12.133188  3756 sgd_solver.cpp:106] Iteration 61, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:36:16.432742  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:36:16.432763  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:16.432768  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 14:36:16.448272  3756 solver.cpp:228] Iteration 62, loss = 2.72584
I0422 14:36:16.448292  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:16.448299  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.47266 (* 1 = 2.47266 loss)
I0422 14:36:16.448304  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:16.448308  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:36:16.448312  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:16.448315  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:16.448320  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.242516 (* 1 = 0.242516 loss)
I0422 14:36:16.448325  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0106648 (* 1 = 0.0106648 loss)
I0422 14:36:16.448331  3756 sgd_solver.cpp:106] Iteration 62, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:36:20.769731  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:36:20.769752  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:20.769757  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 14:36:20.785284  3756 solver.cpp:228] Iteration 63, loss = 3.50006
I0422 14:36:20.785301  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:20.785310  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.1991 (* 1 = 3.1991 loss)
I0422 14:36:20.785315  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:20.785317  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:36:20.785321  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:20.785326  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:20.785329  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.296454 (* 1 = 0.296454 loss)
I0422 14:36:20.785339  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00450644 (* 1 = 0.00450644 loss)
I0422 14:36:20.785344  3756 sgd_solver.cpp:106] Iteration 63, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:36:25.118690  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:36:25.118712  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:25.118716  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:36:25.134747  3756 solver.cpp:228] Iteration 64, loss = 9.80607
I0422 14:36:25.134790  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:25.134801  3756 solver.cpp:244]     Train net output #1: loss_cls = 9.50957 (* 1 = 9.50957 loss)
I0422 14:36:25.134807  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:25.134811  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:36:25.134819  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:25.134824  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:25.134832  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.291136 (* 1 = 0.291136 loss)
I0422 14:36:25.134837  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00536036 (* 1 = 0.00536036 loss)
I0422 14:36:25.134845  3756 sgd_solver.cpp:106] Iteration 64, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:36:29.448822  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:36:29.448844  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:29.448849  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 17
('accuracy: ', 0.0)
I0422 14:36:29.464416  3756 solver.cpp:228] Iteration 65, loss = 2.98647
I0422 14:36:29.464442  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:29.464452  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.65627 (* 1 = 2.65627 loss)
I0422 14:36:29.464457  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:29.464462  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:36:29.464467  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:29.464469  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:29.464474  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.325781 (* 1 = 0.325781 loss)
I0422 14:36:29.464479  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0044178 (* 1 = 0.0044178 loss)
I0422 14:36:29.464485  3756 sgd_solver.cpp:106] Iteration 65, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:36:33.740072  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:36:33.740093  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:33.740100  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 11
('accuracy: ', 0.0)
I0422 14:36:33.755391  3756 solver.cpp:228] Iteration 66, loss = 3.58311
I0422 14:36:33.755414  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:33.755422  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.20019 (* 1 = 3.20019 loss)
I0422 14:36:33.755429  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:33.755431  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:36:33.755435  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:33.755439  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:33.755444  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.374134 (* 1 = 0.374134 loss)
I0422 14:36:33.755448  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0087829 (* 1 = 0.0087829 loss)
I0422 14:36:33.755455  3756 sgd_solver.cpp:106] Iteration 66, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:36:38.064213  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:36:38.064235  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:38.064251  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 14:36:38.080142  3756 solver.cpp:228] Iteration 67, loss = 3.04523
I0422 14:36:38.080163  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:38.080170  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.61168 (* 1 = 2.61168 loss)
I0422 14:36:38.080175  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:38.080179  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:36:38.080184  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:38.080188  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:38.080193  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.424136 (* 1 = 0.424136 loss)
I0422 14:36:38.080198  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00941413 (* 1 = 0.00941413 loss)
I0422 14:36:38.080205  3756 sgd_solver.cpp:106] Iteration 67, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:36:42.405972  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:36:42.405992  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:42.405997  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 26
('accuracy: ', 0.0)
I0422 14:36:42.421869  3756 solver.cpp:228] Iteration 68, loss = 3.3954
I0422 14:36:42.421896  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:42.421905  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.97981 (* 1 = 2.97981 loss)
I0422 14:36:42.421911  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:42.421913  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:36:42.421918  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:42.421922  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:42.421926  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.407372 (* 1 = 0.407372 loss)
I0422 14:36:42.421932  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00821989 (* 1 = 0.00821989 loss)
I0422 14:36:42.421937  3756 sgd_solver.cpp:106] Iteration 68, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:36:46.720521  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:36:46.720546  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:46.720551  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 24
('accuracy: ', 0.0)
I0422 14:36:46.736099  3756 solver.cpp:228] Iteration 69, loss = 3.78361
I0422 14:36:46.736120  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:46.736129  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.37078 (* 1 = 3.37078 loss)
I0422 14:36:46.736135  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:46.736138  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:36:46.736142  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:46.736145  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:46.736150  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.404308 (* 1 = 0.404308 loss)
I0422 14:36:46.736155  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00851993 (* 1 = 0.00851993 loss)
I0422 14:36:46.736161  3756 sgd_solver.cpp:106] Iteration 69, lr = 0.0001
speed: 4.303s / iter
rpn: num_positive 4
rpn: num_negative 60
I0422 14:36:51.025192  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:36:51.025214  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:51.025218  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 12
num bg: 24
('accuracy: ', 0.0)
I0422 14:36:51.040850  3756 solver.cpp:228] Iteration 70, loss = 2.84148
I0422 14:36:51.040870  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:51.040879  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.51378 (* 1 = 2.51378 loss)
I0422 14:36:51.040884  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:51.040889  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:36:51.040891  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:51.040895  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:51.040900  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.315827 (* 1 = 0.315827 loss)
I0422 14:36:51.040905  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0118736 (* 1 = 0.0118736 loss)
I0422 14:36:51.040911  3756 sgd_solver.cpp:106] Iteration 70, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:36:55.329169  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:36:55.329190  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:55.329195  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:36:55.344645  3756 solver.cpp:228] Iteration 71, loss = 2.40943
I0422 14:36:55.344662  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:55.344671  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.14181 (* 1 = 2.14181 loss)
I0422 14:36:55.344676  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:55.344679  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:36:55.344683  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:55.344686  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:55.344691  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.25971 (* 1 = 0.25971 loss)
I0422 14:36:55.344696  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00791144 (* 1 = 0.00791144 loss)
I0422 14:36:55.344702  3756 sgd_solver.cpp:106] Iteration 71, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:36:59.634202  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:36:59.634223  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:36:59.634228  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 14:36:59.649845  3756 solver.cpp:228] Iteration 72, loss = 2.59468
I0422 14:36:59.649863  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:36:59.649886  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.3305 (* 1 = 2.3305 loss)
I0422 14:36:59.649893  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:36:59.649896  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:36:59.649900  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:36:59.649904  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:36:59.649919  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.255365 (* 1 = 0.255365 loss)
I0422 14:36:59.649924  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00881643 (* 1 = 0.00881643 loss)
I0422 14:36:59.649930  3756 sgd_solver.cpp:106] Iteration 72, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:37:03.967218  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:37:03.967250  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:03.967255  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 28
('accuracy: ', 0.0)
I0422 14:37:03.982998  3756 solver.cpp:228] Iteration 73, loss = 2.64216
I0422 14:37:03.983022  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:03.983031  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.40999 (* 1 = 2.40999 loss)
I0422 14:37:03.983036  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:03.983041  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:37:03.983044  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:03.983047  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:03.983052  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.2133 (* 1 = 0.2133 loss)
I0422 14:37:03.983057  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.018876 (* 1 = 0.018876 loss)
I0422 14:37:03.983063  3756 sgd_solver.cpp:106] Iteration 73, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:37:08.277856  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:37:08.277878  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:08.277882  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 31
('accuracy: ', 0.0)
I0422 14:37:08.293556  3756 solver.cpp:228] Iteration 74, loss = 2.34934
I0422 14:37:08.293577  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:08.293586  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.10789 (* 1 = 2.10789 loss)
I0422 14:37:08.293592  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:08.293596  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:37:08.293601  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:08.293604  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:08.293608  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.230326 (* 1 = 0.230326 loss)
I0422 14:37:08.293613  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0111215 (* 1 = 0.0111215 loss)
I0422 14:37:08.293619  3756 sgd_solver.cpp:106] Iteration 74, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:37:12.597031  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:37:12.597054  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:12.597059  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:37:12.612869  3756 solver.cpp:228] Iteration 75, loss = 2.03348
I0422 14:37:12.612886  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:12.612895  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.79136 (* 1 = 1.79136 loss)
I0422 14:37:12.612900  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:12.612903  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:37:12.612907  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:12.612911  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:12.612922  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.22066 (* 1 = 0.22066 loss)
I0422 14:37:12.612927  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0214599 (* 1 = 0.0214599 loss)
I0422 14:37:12.612934  3756 sgd_solver.cpp:106] Iteration 75, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:37:16.914629  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:37:16.914650  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:16.914654  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 28
('accuracy: ', 0.0)
I0422 14:37:16.931794  3756 solver.cpp:228] Iteration 76, loss = 2.42879
I0422 14:37:16.931814  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:16.931823  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.1999 (* 1 = 2.1999 loss)
I0422 14:37:16.931828  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:16.931831  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:37:16.931835  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:16.931838  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:16.931843  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.215706 (* 1 = 0.215706 loss)
I0422 14:37:16.931854  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0131866 (* 1 = 0.0131866 loss)
I0422 14:37:16.931860  3756 sgd_solver.cpp:106] Iteration 76, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:37:21.203356  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:37:21.203378  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:21.203394  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 20
('accuracy: ', 0.0)
I0422 14:37:21.219230  3756 solver.cpp:228] Iteration 77, loss = 2.98584
I0422 14:37:21.219249  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:21.219257  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.77206 (* 1 = 2.77206 loss)
I0422 14:37:21.219262  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:21.219266  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:37:21.219270  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:21.219274  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:21.219278  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.211214 (* 1 = 0.211214 loss)
I0422 14:37:21.219283  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00255797 (* 1 = 0.00255797 loss)
I0422 14:37:21.219290  3756 sgd_solver.cpp:106] Iteration 77, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:37:25.518304  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:37:25.518327  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:25.518332  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 14:37:25.533975  3756 solver.cpp:228] Iteration 78, loss = 3.07369
I0422 14:37:25.533993  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:25.534000  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.86947 (* 1 = 2.86947 loss)
I0422 14:37:25.534006  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:25.534010  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:37:25.534014  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:25.534018  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:25.534023  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.198006 (* 1 = 0.198006 loss)
I0422 14:37:25.534027  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00621103 (* 1 = 0.00621103 loss)
I0422 14:37:25.534034  3756 sgd_solver.cpp:106] Iteration 78, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:37:29.832993  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:37:29.833014  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:29.833019  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:37:29.848870  3756 solver.cpp:228] Iteration 79, loss = 2.52252
I0422 14:37:29.848889  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:29.848897  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.24709 (* 1 = 2.24709 loss)
I0422 14:37:29.848904  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:29.848908  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:37:29.848912  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:29.848917  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:29.848920  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.269432 (* 1 = 0.269432 loss)
I0422 14:37:29.848927  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00600129 (* 1 = 0.00600129 loss)
I0422 14:37:29.848933  3756 sgd_solver.cpp:106] Iteration 79, lr = 0.0001
speed: 4.304s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:37:34.138897  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:37:34.138919  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:34.138924  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 30
('accuracy: ', 0.0)
I0422 14:37:34.154737  3756 solver.cpp:228] Iteration 80, loss = 1.93342
I0422 14:37:34.154754  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:34.154777  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.68936 (* 1 = 1.68936 loss)
I0422 14:37:34.154785  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:34.154789  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:37:34.154793  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:34.154798  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:34.154801  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.238762 (* 1 = 0.238762 loss)
I0422 14:37:34.154806  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00530092 (* 1 = 0.00530092 loss)
I0422 14:37:34.154812  3756 sgd_solver.cpp:106] Iteration 80, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:37:38.478137  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:37:38.478157  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:38.478173  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 14
('accuracy: ', 0.0)
I0422 14:37:38.493621  3756 solver.cpp:228] Iteration 81, loss = 2.72457
I0422 14:37:38.493638  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:38.493656  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.51888 (* 1 = 2.51888 loss)
I0422 14:37:38.493661  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:38.493665  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:37:38.493669  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:38.493674  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:38.493683  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.196516 (* 1 = 0.196516 loss)
I0422 14:37:38.493688  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00917717 (* 1 = 0.00917717 loss)
I0422 14:37:38.493697  3756 sgd_solver.cpp:106] Iteration 81, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:37:42.792645  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:37:42.792666  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:42.792671  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:37:42.808295  3756 solver.cpp:228] Iteration 82, loss = 3.00724
I0422 14:37:42.808313  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:42.808321  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.7234 (* 1 = 2.7234 loss)
I0422 14:37:42.808326  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:42.808331  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:37:42.808334  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:42.808338  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:42.808342  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.276357 (* 1 = 0.276357 loss)
I0422 14:37:42.808347  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00748128 (* 1 = 0.00748128 loss)
I0422 14:37:42.808353  3756 sgd_solver.cpp:106] Iteration 82, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:37:47.106065  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:37:47.106087  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:47.106092  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 14:37:47.123015  3756 solver.cpp:228] Iteration 83, loss = 2.49177
I0422 14:37:47.123041  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:47.123050  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.25701 (* 1 = 2.25701 loss)
I0422 14:37:47.123055  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:47.123064  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:37:47.123067  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:47.123071  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:47.123076  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.229083 (* 1 = 0.229083 loss)
I0422 14:37:47.123085  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00568026 (* 1 = 0.00568026 loss)
I0422 14:37:47.123090  3756 sgd_solver.cpp:106] Iteration 83, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:37:51.426534  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:37:51.426556  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:51.426561  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 3
num bg: 8
('accuracy: ', 0.0)
I0422 14:37:51.437202  3756 solver.cpp:228] Iteration 84, loss = 2.40621
I0422 14:37:51.437219  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:51.437227  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.20886 (* 1 = 2.20886 loss)
I0422 14:37:51.437232  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:51.437237  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:37:51.437240  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:51.437244  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:51.437248  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.195499 (* 1 = 0.195499 loss)
I0422 14:37:51.437254  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00185162 (* 1 = 0.00185162 loss)
I0422 14:37:51.437260  3756 sgd_solver.cpp:106] Iteration 84, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:37:55.722265  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:37:55.722286  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:37:55.722290  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 5
num bg: 20
('accuracy: ', 0.0)
I0422 14:37:55.739464  3756 solver.cpp:228] Iteration 85, loss = 2.12201
I0422 14:37:55.739486  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:37:55.739495  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.82213 (* 1 = 1.82213 loss)
I0422 14:37:55.739500  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:37:55.739504  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:37:55.739507  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:37:55.739511  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:37:55.739516  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.291547 (* 1 = 0.291547 loss)
I0422 14:37:55.739521  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00832699 (* 1 = 0.00832699 loss)
I0422 14:37:55.739526  3756 sgd_solver.cpp:106] Iteration 85, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:38:00.008862  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:38:00.008884  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:00.008889  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 28
('accuracy: ', 0.0)
I0422 14:38:00.024194  3756 solver.cpp:228] Iteration 86, loss = 2.16654
I0422 14:38:00.024211  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:00.024230  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.93957 (* 1 = 1.93957 loss)
I0422 14:38:00.024235  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:00.024240  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:38:00.024243  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:00.024248  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:00.024253  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.220656 (* 1 = 0.220656 loss)
I0422 14:38:00.024258  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00631377 (* 1 = 0.00631377 loss)
I0422 14:38:00.024263  3756 sgd_solver.cpp:106] Iteration 86, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:38:04.321362  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:38:04.321385  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:04.321389  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 13
num bg: 25
('accuracy: ', 0.0)
I0422 14:38:04.337054  3756 solver.cpp:228] Iteration 87, loss = 3.06481
I0422 14:38:04.337072  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:04.337080  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.92864 (* 1 = 2.92864 loss)
I0422 14:38:04.337085  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:04.337090  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:38:04.337093  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:04.337097  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:04.337101  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.119246 (* 1 = 0.119246 loss)
I0422 14:38:04.337111  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0169204 (* 1 = 0.0169204 loss)
I0422 14:38:04.337117  3756 sgd_solver.cpp:106] Iteration 87, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:38:08.629245  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:38:08.629266  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:08.629271  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 19
('accuracy: ', 0.0)
I0422 14:38:08.644634  3756 solver.cpp:228] Iteration 88, loss = 3.04822
I0422 14:38:08.644652  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:08.644660  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.84488 (* 1 = 2.84488 loss)
I0422 14:38:08.644665  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:08.644670  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:38:08.644673  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:08.644676  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:08.644681  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.175826 (* 1 = 0.175826 loss)
I0422 14:38:08.644686  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0275175 (* 1 = 0.0275175 loss)
I0422 14:38:08.644691  3756 sgd_solver.cpp:106] Iteration 88, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:38:12.928874  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:38:12.928896  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:12.928900  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 14:38:12.944865  3756 solver.cpp:228] Iteration 89, loss = 2.38724
I0422 14:38:12.944886  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:12.944895  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.21427 (* 1 = 2.21427 loss)
I0422 14:38:12.944900  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:12.944905  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:38:12.944908  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:12.944912  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:12.944916  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.166809 (* 1 = 0.166809 loss)
I0422 14:38:12.944921  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00615986 (* 1 = 0.00615986 loss)
I0422 14:38:12.944927  3756 sgd_solver.cpp:106] Iteration 89, lr = 0.0001
speed: 4.305s / iter
rpn: num_positive 2
rpn: num_negative 62
I0422 14:38:17.233405  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:38:17.233428  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:17.233431  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 14:38:17.248838  3756 solver.cpp:228] Iteration 90, loss = 2.37934
I0422 14:38:17.248857  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:17.248864  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.27335 (* 1 = 2.27335 loss)
I0422 14:38:17.248869  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:17.248873  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:38:17.248878  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:17.248881  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:17.248886  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.10226 (* 1 = 0.10226 loss)
I0422 14:38:17.248891  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00373789 (* 1 = 0.00373789 loss)
I0422 14:38:17.248896  3756 sgd_solver.cpp:106] Iteration 90, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:38:21.549048  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:38:21.549072  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:21.549077  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 6
num bg: 24
('accuracy: ', 0.0)
I0422 14:38:21.564621  3756 solver.cpp:228] Iteration 91, loss = 2.02475
I0422 14:38:21.564640  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:21.564647  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.88221 (* 1 = 1.88221 loss)
I0422 14:38:21.564652  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:21.564656  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:38:21.564661  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:21.564664  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:21.564668  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.132554 (* 1 = 0.132554 loss)
I0422 14:38:21.564673  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00998541 (* 1 = 0.00998541 loss)
I0422 14:38:21.564679  3756 sgd_solver.cpp:106] Iteration 91, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:38:25.849030  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:38:25.849051  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:25.849067  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 30
('accuracy: ', 0.0)
I0422 14:38:25.865216  3756 solver.cpp:228] Iteration 92, loss = 2.83019
I0422 14:38:25.865234  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:25.865242  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.63958 (* 1 = 2.63958 loss)
I0422 14:38:25.865248  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:25.865252  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:38:25.865257  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:25.865260  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:25.865264  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.186607 (* 1 = 0.186607 loss)
I0422 14:38:25.865269  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0040106 (* 1 = 0.0040106 loss)
I0422 14:38:25.865275  3756 sgd_solver.cpp:106] Iteration 92, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 14:38:30.152145  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:38:30.152168  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:30.152173  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 26
('accuracy: ', 0.0)
I0422 14:38:30.167546  3756 solver.cpp:228] Iteration 93, loss = 3.0966
I0422 14:38:30.167564  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:30.167572  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.80172 (* 1 = 2.80172 loss)
I0422 14:38:30.167577  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:30.167582  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:38:30.167587  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:30.167589  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:30.167594  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.280597 (* 1 = 0.280597 loss)
I0422 14:38:30.167599  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0142878 (* 1 = 0.0142878 loss)
I0422 14:38:30.167604  3756 sgd_solver.cpp:106] Iteration 93, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:38:34.461030  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:38:34.461057  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:34.461064  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 14:38:34.476508  3756 solver.cpp:228] Iteration 94, loss = 2.05605
I0422 14:38:34.476526  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:34.476536  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.88367 (* 1 = 1.88367 loss)
I0422 14:38:34.476541  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:34.476544  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:38:34.476547  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:34.476552  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:34.476557  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.165931 (* 1 = 0.165931 loss)
I0422 14:38:34.476562  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00645056 (* 1 = 0.00645056 loss)
I0422 14:38:34.476567  3756 sgd_solver.cpp:106] Iteration 94, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:38:38.785094  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:38:38.785115  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:38.785120  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:38:38.800739  3756 solver.cpp:228] Iteration 95, loss = 2.90535
I0422 14:38:38.800757  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:38.800765  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.67967 (* 1 = 2.67967 loss)
I0422 14:38:38.800770  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:38.800774  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:38:38.800784  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:38.800788  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:38.800793  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.205296 (* 1 = 0.205296 loss)
I0422 14:38:38.800799  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0203864 (* 1 = 0.0203864 loss)
I0422 14:38:38.800804  3756 sgd_solver.cpp:106] Iteration 95, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:38:43.100407  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:38:43.100440  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:43.100445  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 28
('accuracy: ', 0.0)
I0422 14:38:43.115802  3756 solver.cpp:228] Iteration 96, loss = 2.08779
I0422 14:38:43.115830  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:43.115839  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.85651 (* 1 = 1.85651 loss)
I0422 14:38:43.115844  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:43.115846  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:38:43.115851  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:43.115854  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:43.115859  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.224148 (* 1 = 0.224148 loss)
I0422 14:38:43.115864  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00713524 (* 1 = 0.00713524 loss)
I0422 14:38:43.115869  3756 sgd_solver.cpp:106] Iteration 96, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:38:47.396705  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:38:47.396726  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:47.396731  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:38:47.412255  3756 solver.cpp:228] Iteration 97, loss = 2.33455
I0422 14:38:47.412273  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:47.412281  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.18639 (* 1 = 2.18639 loss)
I0422 14:38:47.412287  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:47.412291  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:38:47.412294  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:47.412298  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:47.412303  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.145202 (* 1 = 0.145202 loss)
I0422 14:38:47.412314  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00295476 (* 1 = 0.00295476 loss)
I0422 14:38:47.412320  3756 sgd_solver.cpp:106] Iteration 97, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:38:51.693408  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:38:51.693430  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:51.693435  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:38:51.709172  3756 solver.cpp:228] Iteration 98, loss = 2.33934
I0422 14:38:51.709192  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:51.709199  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.10966 (* 1 = 2.10966 loss)
I0422 14:38:51.709204  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:51.709208  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:38:51.709213  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:51.709216  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:51.709221  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.223133 (* 1 = 0.223133 loss)
I0422 14:38:51.709226  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00654887 (* 1 = 0.00654887 loss)
I0422 14:38:51.709233  3756 sgd_solver.cpp:106] Iteration 98, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:38:56.010639  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:38:56.010671  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:38:56.010676  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 14:38:56.025894  3756 solver.cpp:228] Iteration 99, loss = 2.46375
I0422 14:38:56.025921  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:38:56.025929  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.22057 (* 1 = 2.22057 loss)
I0422 14:38:56.025934  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:38:56.025938  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:38:56.025943  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:38:56.025946  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:38:56.025950  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.23678 (* 1 = 0.23678 loss)
I0422 14:38:56.025955  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00639737 (* 1 = 0.00639737 loss)
I0422 14:38:56.025961  3756 sgd_solver.cpp:106] Iteration 99, lr = 0.0001
speed: 4.305s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:00.333313  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:00.333343  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:00.333349  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 14:39:00.349695  3756 solver.cpp:228] Iteration 100, loss = 2.35857
I0422 14:39:00.349712  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:00.349720  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.13267 (* 1 = 2.13267 loss)
I0422 14:39:00.349725  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:00.349730  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:00.349733  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:00.349737  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:00.349741  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.218984 (* 1 = 0.218984 loss)
I0422 14:39:00.349746  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00691534 (* 1 = 0.00691534 loss)
I0422 14:39:00.349752  3756 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:04.635022  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:04.635049  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:04.635058  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 14:39:04.650494  3756 solver.cpp:228] Iteration 101, loss = 2.34481
I0422 14:39:04.650512  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:04.650521  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.1613 (* 1 = 2.1613 loss)
I0422 14:39:04.650526  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:04.650529  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:04.650534  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:04.650537  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:04.650542  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.17809 (* 1 = 0.17809 loss)
I0422 14:39:04.650547  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00541451 (* 1 = 0.00541451 loss)
I0422 14:39:04.650552  3756 sgd_solver.cpp:106] Iteration 101, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:08.919625  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:08.919646  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:08.919651  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 28
('accuracy: ', 0.0)
I0422 14:39:08.935308  3756 solver.cpp:228] Iteration 102, loss = 1.62838
I0422 14:39:08.935333  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:08.935344  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.42638 (* 1 = 1.42638 loss)
I0422 14:39:08.935354  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:08.935360  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:08.935366  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:08.935372  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:08.935379  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.198059 (* 1 = 0.198059 loss)
I0422 14:39:08.935387  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00393653 (* 1 = 0.00393653 loss)
I0422 14:39:08.935396  3756 sgd_solver.cpp:106] Iteration 102, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:13.216751  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:13.216773  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:13.216778  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 14:39:13.232362  3756 solver.cpp:228] Iteration 103, loss = 2.33899
I0422 14:39:13.232380  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:13.232388  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.19197 (* 1 = 2.19197 loss)
I0422 14:39:13.232394  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:13.232398  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:13.232403  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:13.232405  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:13.232410  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.141965 (* 1 = 0.141965 loss)
I0422 14:39:13.232415  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00505649 (* 1 = 0.00505649 loss)
I0422 14:39:13.232420  3756 sgd_solver.cpp:106] Iteration 103, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:17.522426  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:17.522447  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:17.522452  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 14:39:17.538341  3756 solver.cpp:228] Iteration 104, loss = 2.48011
I0422 14:39:17.538362  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:17.538369  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.33297 (* 1 = 2.33297 loss)
I0422 14:39:17.538375  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:17.538378  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:17.538383  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:17.538386  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:17.538391  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.141444 (* 1 = 0.141444 loss)
I0422 14:39:17.538396  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00568659 (* 1 = 0.00568659 loss)
I0422 14:39:17.538401  3756 sgd_solver.cpp:106] Iteration 104, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:21.820575  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:21.820597  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:21.820601  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:39:21.836063  3756 solver.cpp:228] Iteration 105, loss = 1.98894
I0422 14:39:21.836082  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:21.836091  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.80713 (* 1 = 1.80713 loss)
I0422 14:39:21.836096  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:21.836099  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:21.836103  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:21.836107  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:21.836112  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.177571 (* 1 = 0.177571 loss)
I0422 14:39:21.836117  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00423315 (* 1 = 0.00423315 loss)
I0422 14:39:21.836122  3756 sgd_solver.cpp:106] Iteration 105, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:39:26.118789  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:39:26.118810  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:26.118814  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 6
num bg: 22
('accuracy: ', 0.0)
I0422 14:39:26.134217  3756 solver.cpp:228] Iteration 106, loss = 2.18086
I0422 14:39:26.134235  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:26.134243  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.08125 (* 1 = 2.08125 loss)
I0422 14:39:26.134249  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:26.134253  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:39:26.134258  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:26.134261  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:26.134274  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0917264 (* 1 = 0.0917264 loss)
I0422 14:39:26.134279  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0078885 (* 1 = 0.0078885 loss)
I0422 14:39:26.134284  3756 sgd_solver.cpp:106] Iteration 106, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:39:30.440943  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:39:30.440970  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:30.440975  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 21
('accuracy: ', 0.0)
I0422 14:39:30.456799  3756 solver.cpp:228] Iteration 107, loss = 2.46416
I0422 14:39:30.456817  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:30.456825  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.37172 (* 1 = 2.37172 loss)
I0422 14:39:30.456830  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:30.456835  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:39:30.456838  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:30.456842  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:30.456853  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0817967 (* 1 = 0.0817967 loss)
I0422 14:39:30.456859  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0106432 (* 1 = 0.0106432 loss)
I0422 14:39:30.456866  3756 sgd_solver.cpp:106] Iteration 107, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:34.749766  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:34.749786  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:34.749791  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:39:34.766976  3756 solver.cpp:228] Iteration 108, loss = 2.14783
I0422 14:39:34.766997  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:34.767006  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.97255 (* 1 = 1.97255 loss)
I0422 14:39:34.767011  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:34.767016  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:34.767020  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:34.767024  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:34.767030  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.171336 (* 1 = 0.171336 loss)
I0422 14:39:34.767035  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00393958 (* 1 = 0.00393958 loss)
I0422 14:39:34.767041  3756 sgd_solver.cpp:106] Iteration 108, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:39.061287  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:39.061309  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:39.061313  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:39:39.076915  3756 solver.cpp:228] Iteration 109, loss = 1.99391
I0422 14:39:39.076933  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:39.076941  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.83953 (* 1 = 1.83953 loss)
I0422 14:39:39.076946  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:39.076951  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:39.076954  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:39.076957  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:39.076963  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.150044 (* 1 = 0.150044 loss)
I0422 14:39:39.076968  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00434128 (* 1 = 0.00434128 loss)
I0422 14:39:39.076974  3756 sgd_solver.cpp:106] Iteration 109, lr = 0.0001
speed: 4.305s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:43.363306  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:43.363327  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:43.363332  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:39:43.378795  3756 solver.cpp:228] Iteration 110, loss = 1.96369
I0422 14:39:43.378813  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:43.378819  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.74499 (* 1 = 1.74499 loss)
I0422 14:39:43.378825  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:43.378829  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:43.378832  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:43.378836  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:43.378840  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.211563 (* 1 = 0.211563 loss)
I0422 14:39:43.378846  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00713827 (* 1 = 0.00713827 loss)
I0422 14:39:43.378851  3756 sgd_solver.cpp:106] Iteration 110, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:47.649065  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:47.649088  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:47.649093  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 14:39:47.665225  3756 solver.cpp:228] Iteration 111, loss = 2.34989
I0422 14:39:47.665248  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:47.665257  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.1239 (* 1 = 2.1239 loss)
I0422 14:39:47.665262  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:47.665266  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:47.665271  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:47.665274  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:47.665279  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.221283 (* 1 = 0.221283 loss)
I0422 14:39:47.665284  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00470914 (* 1 = 0.00470914 loss)
I0422 14:39:47.665293  3756 sgd_solver.cpp:106] Iteration 111, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:39:51.939661  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:39:51.939684  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:51.939688  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:39:51.955577  3756 solver.cpp:228] Iteration 112, loss = 2.18413
I0422 14:39:51.955608  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:51.955616  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.03691 (* 1 = 2.03691 loss)
I0422 14:39:51.955622  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:51.955626  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:39:51.955631  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:51.955636  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:51.955641  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.143309 (* 1 = 0.143309 loss)
I0422 14:39:51.955647  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00391028 (* 1 = 0.00391028 loss)
I0422 14:39:51.955653  3756 sgd_solver.cpp:106] Iteration 112, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:39:56.251576  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:39:56.251598  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:39:56.251603  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 3
num bg: 5
('accuracy: ', 0.0)
I0422 14:39:56.264375  3756 solver.cpp:228] Iteration 113, loss = 3.38307
I0422 14:39:56.264415  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:39:56.264436  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.20274 (* 1 = 3.20274 loss)
I0422 14:39:56.264453  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:39:56.264466  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:39:56.264484  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:39:56.264493  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:39:56.264505  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.16672 (* 1 = 0.16672 loss)
I0422 14:39:56.264520  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0136078 (* 1 = 0.0136078 loss)
I0422 14:39:56.264534  3756 sgd_solver.cpp:106] Iteration 113, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:40:00.546555  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:40:00.546576  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:00.546581  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 14:40:00.562196  3756 solver.cpp:228] Iteration 114, loss = 2.25118
I0422 14:40:00.562214  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:00.562222  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.0441 (* 1 = 2.0441 loss)
I0422 14:40:00.562227  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:00.562232  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:40:00.562235  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:00.562239  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:00.562243  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.203312 (* 1 = 0.203312 loss)
I0422 14:40:00.562248  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00377542 (* 1 = 0.00377542 loss)
I0422 14:40:00.562254  3756 sgd_solver.cpp:106] Iteration 114, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:40:04.846448  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:40:04.846470  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:04.846475  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 4
num bg: 13
('accuracy: ', 0.0)
I0422 14:40:04.860657  3756 solver.cpp:228] Iteration 115, loss = 2.12515
I0422 14:40:04.860673  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:04.860682  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.03137 (* 1 = 2.03137 loss)
I0422 14:40:04.860687  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:04.860692  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:40:04.860694  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:04.860698  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:04.860703  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0892635 (* 1 = 0.0892635 loss)
I0422 14:40:04.860707  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00451768 (* 1 = 0.00451768 loss)
I0422 14:40:04.860713  3756 sgd_solver.cpp:106] Iteration 115, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:40:09.139336  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:40:09.139358  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:09.139362  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 24
('accuracy: ', 0.0)
I0422 14:40:09.156097  3756 solver.cpp:228] Iteration 116, loss = 2.69761
I0422 14:40:09.156119  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:09.156128  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.55149 (* 1 = 2.55149 loss)
I0422 14:40:09.156133  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:09.156137  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:40:09.156141  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:09.156146  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:09.156149  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.127633 (* 1 = 0.127633 loss)
I0422 14:40:09.156154  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0184816 (* 1 = 0.0184816 loss)
I0422 14:40:09.156160  3756 sgd_solver.cpp:106] Iteration 116, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 14:40:13.437214  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:40:13.437237  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:13.437240  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 21
('accuracy: ', 0.0)
I0422 14:40:13.452930  3756 solver.cpp:228] Iteration 117, loss = 2.76915
I0422 14:40:13.452949  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:13.452956  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.54251 (* 1 = 2.54251 loss)
I0422 14:40:13.452961  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:13.452965  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:40:13.452970  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:13.452972  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:13.452977  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.19547 (* 1 = 0.19547 loss)
I0422 14:40:13.452981  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0311681 (* 1 = 0.0311681 loss)
I0422 14:40:13.452987  3756 sgd_solver.cpp:106] Iteration 117, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:40:17.732834  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:40:17.732856  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:17.732861  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:40:17.748734  3756 solver.cpp:228] Iteration 118, loss = 1.88651
I0422 14:40:17.748754  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:17.748761  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.75363 (* 1 = 1.75363 loss)
I0422 14:40:17.748767  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:17.748770  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:40:17.748775  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:17.748778  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:17.748783  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.128728 (* 1 = 0.128728 loss)
I0422 14:40:17.748788  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00414667 (* 1 = 0.00414667 loss)
I0422 14:40:17.748795  3756 sgd_solver.cpp:106] Iteration 118, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:40:22.047446  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:40:22.047469  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:22.047474  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 22
('accuracy: ', 0.0)
I0422 14:40:22.064735  3756 solver.cpp:228] Iteration 119, loss = 1.90814
I0422 14:40:22.064754  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:22.064762  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.78752 (* 1 = 1.78752 loss)
I0422 14:40:22.064767  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:22.064771  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:40:22.064775  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:22.064779  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:22.064785  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.112654 (* 1 = 0.112654 loss)
I0422 14:40:22.064790  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00797096 (* 1 = 0.00797096 loss)
I0422 14:40:22.064795  3756 sgd_solver.cpp:106] Iteration 119, lr = 0.0001
speed: 4.305s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:40:26.352990  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:40:26.353013  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:26.353016  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 31
('accuracy: ', 0.0)
I0422 14:40:26.368561  3756 solver.cpp:228] Iteration 120, loss = 2.31627
I0422 14:40:26.368579  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:26.368587  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.17733 (* 1 = 2.17733 loss)
I0422 14:40:26.368592  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:26.368595  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:40:26.368599  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:26.368603  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:26.368607  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.135194 (* 1 = 0.135194 loss)
I0422 14:40:26.368613  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00375039 (* 1 = 0.00375039 loss)
I0422 14:40:26.368618  3756 sgd_solver.cpp:106] Iteration 120, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:40:30.656090  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:40:30.656114  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:30.656118  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 14:40:30.671612  3756 solver.cpp:228] Iteration 121, loss = 1.9556
I0422 14:40:30.671633  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:30.671640  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.7758 (* 1 = 1.7758 loss)
I0422 14:40:30.671645  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:30.671649  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:40:30.671653  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:30.671658  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:30.671663  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.174923 (* 1 = 0.174923 loss)
I0422 14:40:30.671667  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00488232 (* 1 = 0.00488232 loss)
I0422 14:40:30.671674  3756 sgd_solver.cpp:106] Iteration 121, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:40:34.957340  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:40:34.957361  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:34.957368  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 21
('accuracy: ', 0.0)
I0422 14:40:34.972988  3756 solver.cpp:228] Iteration 122, loss = 2.56208
I0422 14:40:34.973006  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:34.973013  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.466 (* 1 = 2.466 loss)
I0422 14:40:34.973021  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:34.973024  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:40:34.973031  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:34.973035  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:34.973042  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0920115 (* 1 = 0.0920115 loss)
I0422 14:40:34.973049  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00406566 (* 1 = 0.00406566 loss)
I0422 14:40:34.973057  3756 sgd_solver.cpp:106] Iteration 122, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:40:39.244217  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:40:39.244238  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:39.244242  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 31
('accuracy: ', 0.0)
I0422 14:40:39.260134  3756 solver.cpp:228] Iteration 123, loss = 2.21835
I0422 14:40:39.260154  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:39.260164  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.04907 (* 1 = 2.04907 loss)
I0422 14:40:39.260169  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:39.260172  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:40:39.260176  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:39.260185  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:39.260190  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.166209 (* 1 = 0.166209 loss)
I0422 14:40:39.260196  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00307205 (* 1 = 0.00307205 loss)
I0422 14:40:39.260202  3756 sgd_solver.cpp:106] Iteration 123, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:40:43.549955  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:40:43.549978  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:43.549983  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:40:43.565922  3756 solver.cpp:228] Iteration 124, loss = 2.20986
I0422 14:40:43.565939  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:43.565948  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.0465 (* 1 = 2.0465 loss)
I0422 14:40:43.565953  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:43.565956  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:40:43.565959  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:43.565963  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:43.565968  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.159275 (* 1 = 0.159275 loss)
I0422 14:40:43.565973  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0040921 (* 1 = 0.0040921 loss)
I0422 14:40:43.565979  3756 sgd_solver.cpp:106] Iteration 124, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 14:40:47.853440  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:40:47.853462  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:47.853467  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 23
('accuracy: ', 0.0)
I0422 14:40:47.871662  3756 solver.cpp:228] Iteration 125, loss = 2.78981
I0422 14:40:47.871686  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:47.871695  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.64354 (* 1 = 2.64354 loss)
I0422 14:40:47.871701  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:47.871706  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:40:47.871711  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:47.871714  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:47.871719  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.129527 (* 1 = 0.129527 loss)
I0422 14:40:47.871726  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0167421 (* 1 = 0.0167421 loss)
I0422 14:40:47.871732  3756 sgd_solver.cpp:106] Iteration 125, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:40:52.146642  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:40:52.146663  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:52.146667  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 27
('accuracy: ', 0.0)
I0422 14:40:52.162160  3756 solver.cpp:228] Iteration 126, loss = 1.44391
I0422 14:40:52.162178  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:52.162185  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.25507 (* 1 = 1.25507 loss)
I0422 14:40:52.162190  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:52.162194  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:40:52.162199  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:52.162202  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:52.162206  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.184832 (* 1 = 0.184832 loss)
I0422 14:40:52.162211  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00401435 (* 1 = 0.00401435 loss)
I0422 14:40:52.162216  3756 sgd_solver.cpp:106] Iteration 126, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:40:56.461679  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:40:56.461699  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:40:56.461704  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 14:40:56.477448  3756 solver.cpp:228] Iteration 127, loss = 2.32858
I0422 14:40:56.477474  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:40:56.477483  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.13848 (* 1 = 2.13848 loss)
I0422 14:40:56.477488  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:40:56.477491  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:40:56.477495  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:40:56.477499  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:40:56.477504  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.184915 (* 1 = 0.184915 loss)
I0422 14:40:56.477509  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0051889 (* 1 = 0.0051889 loss)
I0422 14:40:56.477514  3756 sgd_solver.cpp:106] Iteration 127, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:00.762408  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:00.762428  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:00.762434  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 32
('accuracy: ', 0.0)
I0422 14:41:00.778794  3756 solver.cpp:228] Iteration 128, loss = 2.02811
I0422 14:41:00.778818  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:00.778831  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.86265 (* 1 = 1.86265 loss)
I0422 14:41:00.778841  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:00.778848  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:00.778856  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:00.778862  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:00.778872  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.161039 (* 1 = 0.161039 loss)
I0422 14:41:00.778880  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00441957 (* 1 = 0.00441957 loss)
I0422 14:41:00.778890  3756 sgd_solver.cpp:106] Iteration 128, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:05.061522  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:05.061542  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:05.061547  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 14:41:05.076993  3756 solver.cpp:228] Iteration 129, loss = 1.7886
I0422 14:41:05.077011  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:05.077019  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.63443 (* 1 = 1.63443 loss)
I0422 14:41:05.077028  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:05.077031  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:05.077036  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:05.077039  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:05.077044  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.150428 (* 1 = 0.150428 loss)
I0422 14:41:05.077049  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00374128 (* 1 = 0.00374128 loss)
I0422 14:41:05.077057  3756 sgd_solver.cpp:106] Iteration 129, lr = 0.0001
speed: 4.304s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:09.381170  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:09.381191  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:09.381204  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:41:09.398232  3756 solver.cpp:228] Iteration 130, loss = 2.17126
I0422 14:41:09.398252  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:09.398260  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.00944 (* 1 = 2.00944 loss)
I0422 14:41:09.398265  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:09.398269  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:09.398274  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:09.398277  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:09.398283  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.157596 (* 1 = 0.157596 loss)
I0422 14:41:09.398288  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00421911 (* 1 = 0.00421911 loss)
I0422 14:41:09.398293  3756 sgd_solver.cpp:106] Iteration 130, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:13.698662  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:13.698694  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:13.698699  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:41:13.714419  3756 solver.cpp:228] Iteration 131, loss = 2.81804
I0422 14:41:13.714435  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:13.714443  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.62093 (* 1 = 2.62093 loss)
I0422 14:41:13.714448  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:13.714452  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:13.714457  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:13.714459  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:13.714463  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.192696 (* 1 = 0.192696 loss)
I0422 14:41:13.714468  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.004412 (* 1 = 0.004412 loss)
I0422 14:41:13.714473  3756 sgd_solver.cpp:106] Iteration 131, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:17.993566  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:17.993587  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:17.993592  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:41:18.009047  3756 solver.cpp:228] Iteration 132, loss = 2.27063
I0422 14:41:18.009064  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:18.009073  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.13002 (* 1 = 2.13002 loss)
I0422 14:41:18.009078  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:18.009081  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:18.009085  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:18.009088  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:18.009093  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.135394 (* 1 = 0.135394 loss)
I0422 14:41:18.009099  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00521227 (* 1 = 0.00521227 loss)
I0422 14:41:18.009104  3756 sgd_solver.cpp:106] Iteration 132, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:22.290593  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:22.290616  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:22.290621  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 27
('accuracy: ', 0.0)
I0422 14:41:22.306946  3756 solver.cpp:228] Iteration 133, loss = 2.8494
I0422 14:41:22.306967  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:22.306975  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.72503 (* 1 = 2.72503 loss)
I0422 14:41:22.306980  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:22.306984  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:22.306988  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:22.306993  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:22.306998  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.121153 (* 1 = 0.121153 loss)
I0422 14:41:22.307003  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00322137 (* 1 = 0.00322137 loss)
I0422 14:41:22.307009  3756 sgd_solver.cpp:106] Iteration 133, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:26.598755  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:26.598789  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:26.598794  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 27
('accuracy: ', 0.0)
I0422 14:41:26.614130  3756 solver.cpp:228] Iteration 134, loss = 2.00797
I0422 14:41:26.614146  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:26.614153  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.8829 (* 1 = 1.8829 loss)
I0422 14:41:26.614159  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:26.614162  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:26.614167  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:26.614171  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:26.614176  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.120884 (* 1 = 0.120884 loss)
I0422 14:41:26.614181  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00418978 (* 1 = 0.00418978 loss)
I0422 14:41:26.614187  3756 sgd_solver.cpp:106] Iteration 134, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:30.915571  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:30.915604  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:30.915609  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:41:30.931318  3756 solver.cpp:228] Iteration 135, loss = 1.9791
I0422 14:41:30.931336  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:30.931345  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.86605 (* 1 = 1.86605 loss)
I0422 14:41:30.931350  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:30.931354  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:30.931358  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:30.931362  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:30.931366  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.109684 (* 1 = 0.109684 loss)
I0422 14:41:30.931371  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00335873 (* 1 = 0.00335873 loss)
I0422 14:41:30.931383  3756 sgd_solver.cpp:106] Iteration 135, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:35.234665  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:35.234688  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:35.234691  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 30
('accuracy: ', 0.0)
I0422 14:41:35.250666  3756 solver.cpp:228] Iteration 136, loss = 2.65525
I0422 14:41:35.250684  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:35.250696  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.51943 (* 1 = 2.51943 loss)
I0422 14:41:35.250710  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:35.250720  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:35.250727  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:35.250735  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:35.250744  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.128211 (* 1 = 0.128211 loss)
I0422 14:41:35.250753  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00761493 (* 1 = 0.00761493 loss)
I0422 14:41:35.250790  3756 sgd_solver.cpp:106] Iteration 136, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:41:39.536308  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:41:39.536329  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:39.536336  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 6
num bg: 23
('accuracy: ', 0.0)
I0422 14:41:39.551875  3756 solver.cpp:228] Iteration 137, loss = 1.8868
I0422 14:41:39.551893  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:39.551905  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.82455 (* 1 = 1.82455 loss)
I0422 14:41:39.551920  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:39.551928  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:41:39.551936  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:39.551944  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:39.551954  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0519764 (* 1 = 0.0519764 loss)
I0422 14:41:39.551964  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0102724 (* 1 = 0.0102724 loss)
I0422 14:41:39.551975  3756 sgd_solver.cpp:106] Iteration 137, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:43.833441  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:43.833463  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:43.833469  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 14:41:43.848968  3756 solver.cpp:228] Iteration 138, loss = 2.93519
I0422 14:41:43.848986  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:43.848999  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.77278 (* 1 = 2.77278 loss)
I0422 14:41:43.849006  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:43.849014  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:43.849023  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:43.849032  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:43.849042  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.153428 (* 1 = 0.153428 loss)
I0422 14:41:43.849053  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00898031 (* 1 = 0.00898031 loss)
I0422 14:41:43.849063  3756 sgd_solver.cpp:106] Iteration 138, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:48.109742  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:48.109762  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:48.109778  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 30
('accuracy: ', 0.0)
I0422 14:41:48.125483  3756 solver.cpp:228] Iteration 139, loss = 1.95729
I0422 14:41:48.125511  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:48.125519  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.80244 (* 1 = 1.80244 loss)
I0422 14:41:48.125524  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:48.125528  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:48.125533  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:48.125536  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:48.125541  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.150599 (* 1 = 0.150599 loss)
I0422 14:41:48.125546  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00425064 (* 1 = 0.00425064 loss)
I0422 14:41:48.125551  3756 sgd_solver.cpp:106] Iteration 139, lr = 0.0001
speed: 4.304s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:52.423733  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:52.423756  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:52.423760  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:41:52.439312  3756 solver.cpp:228] Iteration 140, loss = 2.16859
I0422 14:41:52.439329  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:52.439337  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.96629 (* 1 = 1.96629 loss)
I0422 14:41:52.439342  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:52.439347  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:52.439350  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:52.439354  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:52.439358  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.198356 (* 1 = 0.198356 loss)
I0422 14:41:52.439363  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00395046 (* 1 = 0.00395046 loss)
I0422 14:41:52.439369  3756 sgd_solver.cpp:106] Iteration 140, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:41:56.742111  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:41:56.742132  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:41:56.742136  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 14:41:56.757995  3756 solver.cpp:228] Iteration 141, loss = 2.28386
I0422 14:41:56.758014  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:41:56.758023  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.10553 (* 1 = 2.10553 loss)
I0422 14:41:56.758028  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:41:56.758033  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:41:56.758036  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:41:56.758040  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:41:56.758045  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.175053 (* 1 = 0.175053 loss)
I0422 14:41:56.758050  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00328327 (* 1 = 0.00328327 loss)
I0422 14:41:56.758056  3756 sgd_solver.cpp:106] Iteration 141, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:42:01.015373  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:42:01.015395  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:01.015399  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 4
num bg: 9
('accuracy: ', 0.0)
I0422 14:42:01.026881  3756 solver.cpp:228] Iteration 142, loss = 2.69543
I0422 14:42:01.026899  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:01.026906  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.43878 (* 1 = 2.43878 loss)
I0422 14:42:01.026911  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:01.026916  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:42:01.026921  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:01.026923  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:01.026929  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.247461 (* 1 = 0.247461 loss)
I0422 14:42:01.026934  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00918106 (* 1 = 0.00918106 loss)
I0422 14:42:01.026939  3756 sgd_solver.cpp:106] Iteration 142, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:42:05.311106  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:42:05.311128  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:05.311144  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:42:05.326571  3756 solver.cpp:228] Iteration 143, loss = 2.23179
I0422 14:42:05.326588  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:05.326596  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.87493 (* 1 = 1.87493 loss)
I0422 14:42:05.326606  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:05.326611  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:42:05.326614  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:05.326617  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:05.326628  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.353032 (* 1 = 0.353032 loss)
I0422 14:42:05.326633  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00382468 (* 1 = 0.00382468 loss)
I0422 14:42:05.326642  3756 sgd_solver.cpp:106] Iteration 143, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:42:09.632236  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:42:09.632258  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:09.632262  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:42:09.647884  3756 solver.cpp:228] Iteration 144, loss = 2.14202
I0422 14:42:09.647904  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:09.647912  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.92515 (* 1 = 1.92515 loss)
I0422 14:42:09.647917  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:09.647922  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:42:09.647927  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:09.647929  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:09.647934  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.212908 (* 1 = 0.212908 loss)
I0422 14:42:09.647939  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00396399 (* 1 = 0.00396399 loss)
I0422 14:42:09.647944  3756 sgd_solver.cpp:106] Iteration 144, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:42:13.954849  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:42:13.954870  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:13.954875  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 17
('accuracy: ', 0.0)
I0422 14:42:13.970541  3756 solver.cpp:228] Iteration 145, loss = 2.42934
I0422 14:42:13.970557  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:13.970566  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.20503 (* 1 = 2.20503 loss)
I0422 14:42:13.970571  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:13.970574  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:42:13.970578  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:13.970582  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:13.970587  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.21463 (* 1 = 0.21463 loss)
I0422 14:42:13.970592  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00967739 (* 1 = 0.00967739 loss)
I0422 14:42:13.970597  3756 sgd_solver.cpp:106] Iteration 145, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:42:18.259639  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:42:18.259661  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:18.259666  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 14:42:18.275267  3756 solver.cpp:228] Iteration 146, loss = 1.59759
I0422 14:42:18.275285  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:18.275291  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.41956 (* 1 = 1.41956 loss)
I0422 14:42:18.275296  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:18.275300  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:42:18.275305  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:18.275307  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:18.275313  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.175315 (* 1 = 0.175315 loss)
I0422 14:42:18.275318  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00271467 (* 1 = 0.00271467 loss)
I0422 14:42:18.275323  3756 sgd_solver.cpp:106] Iteration 146, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:42:22.572867  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:42:22.572887  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:22.572892  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 24
('accuracy: ', 0.0)
I0422 14:42:22.588603  3756 solver.cpp:228] Iteration 147, loss = 3.08655
I0422 14:42:22.588623  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:22.588630  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.89909 (* 1 = 2.89909 loss)
I0422 14:42:22.588635  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:22.588639  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:42:22.588644  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:22.588647  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:22.588651  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.176031 (* 1 = 0.176031 loss)
I0422 14:42:22.588656  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0114311 (* 1 = 0.0114311 loss)
I0422 14:42:22.588662  3756 sgd_solver.cpp:106] Iteration 147, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:42:26.876117  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:42:26.876138  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:26.876143  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 28
('accuracy: ', 0.0)
I0422 14:42:26.891743  3756 solver.cpp:228] Iteration 148, loss = 1.87442
I0422 14:42:26.891760  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:26.891768  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.7015 (* 1 = 1.7015 loss)
I0422 14:42:26.891773  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:26.891777  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:42:26.891782  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:26.891785  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:26.891790  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.168766 (* 1 = 0.168766 loss)
I0422 14:42:26.891795  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00415137 (* 1 = 0.00415137 loss)
I0422 14:42:26.891800  3756 sgd_solver.cpp:106] Iteration 148, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:42:31.159600  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:42:31.159621  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:31.159626  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 19
('accuracy: ', 0.0)
I0422 14:42:31.175072  3756 solver.cpp:228] Iteration 149, loss = 2.62828
I0422 14:42:31.175089  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:31.175097  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.51865 (* 1 = 2.51865 loss)
I0422 14:42:31.175102  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:31.175107  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:42:31.175110  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:31.175113  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:31.175118  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0983522 (* 1 = 0.0983522 loss)
I0422 14:42:31.175123  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0112762 (* 1 = 0.0112762 loss)
I0422 14:42:31.175129  3756 sgd_solver.cpp:106] Iteration 149, lr = 0.0001
speed: 4.304s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:42:35.480712  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:42:35.480734  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:35.480739  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 14:42:35.496518  3756 solver.cpp:228] Iteration 150, loss = 2.39823
I0422 14:42:35.496536  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:35.496543  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.23085 (* 1 = 2.23085 loss)
I0422 14:42:35.496559  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:35.496563  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:42:35.496569  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:35.496572  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:35.496577  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.157788 (* 1 = 0.157788 loss)
I0422 14:42:35.496582  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00960126 (* 1 = 0.00960126 loss)
I0422 14:42:35.496587  3756 sgd_solver.cpp:106] Iteration 150, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:42:39.798527  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:42:39.798550  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:39.798554  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 23
('accuracy: ', 0.0)
I0422 14:42:39.814105  3756 solver.cpp:228] Iteration 151, loss = 2.26125
I0422 14:42:39.814133  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:39.814141  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.11814 (* 1 = 2.11814 loss)
I0422 14:42:39.814146  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:39.814151  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:42:39.814154  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:39.814158  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:39.814162  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.125402 (* 1 = 0.125402 loss)
I0422 14:42:39.814167  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0177063 (* 1 = 0.0177063 loss)
I0422 14:42:39.814173  3756 sgd_solver.cpp:106] Iteration 151, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:42:44.101414  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:42:44.101436  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:44.101441  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 14:42:44.116873  3756 solver.cpp:228] Iteration 152, loss = 2.00379
I0422 14:42:44.116896  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:44.116904  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.86989 (* 1 = 1.86989 loss)
I0422 14:42:44.116909  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:44.116914  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:42:44.116919  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:44.116921  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:44.116926  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.12844 (* 1 = 0.12844 loss)
I0422 14:42:44.116931  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00545617 (* 1 = 0.00545617 loss)
I0422 14:42:44.116937  3756 sgd_solver.cpp:106] Iteration 152, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:42:48.384274  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:42:48.384295  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:48.384299  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:42:48.399778  3756 solver.cpp:228] Iteration 153, loss = 2.22158
I0422 14:42:48.399796  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:48.399803  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.09475 (* 1 = 2.09475 loss)
I0422 14:42:48.399808  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:48.399812  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:42:48.399816  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:48.399821  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:48.399826  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.122951 (* 1 = 0.122951 loss)
I0422 14:42:48.399830  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00388262 (* 1 = 0.00388262 loss)
I0422 14:42:48.399835  3756 sgd_solver.cpp:106] Iteration 153, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:42:52.710167  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:42:52.710189  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:52.710194  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 21
('accuracy: ', 0.0)
I0422 14:42:52.725991  3756 solver.cpp:228] Iteration 154, loss = 2.45634
I0422 14:42:52.726019  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:52.726027  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.33875 (* 1 = 2.33875 loss)
I0422 14:42:52.726033  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:52.726037  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:42:52.726042  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:52.726044  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:52.726049  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.110328 (* 1 = 0.110328 loss)
I0422 14:42:52.726063  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0072557 (* 1 = 0.0072557 loss)
I0422 14:42:52.726068  3756 sgd_solver.cpp:106] Iteration 154, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:42:57.004806  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:42:57.004827  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:42:57.004832  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 22
('accuracy: ', 0.0)
I0422 14:42:57.020287  3756 solver.cpp:228] Iteration 155, loss = 2.06504
I0422 14:42:57.020304  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:42:57.020313  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.98561 (* 1 = 1.98561 loss)
I0422 14:42:57.020318  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:42:57.020321  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:42:57.020325  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:42:57.020329  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:42:57.020334  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0702528 (* 1 = 0.0702528 loss)
I0422 14:42:57.020339  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00917591 (* 1 = 0.00917591 loss)
I0422 14:42:57.020344  3756 sgd_solver.cpp:106] Iteration 155, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:01.293514  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:01.293536  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:01.293541  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 28
('accuracy: ', 0.0)
I0422 14:43:01.309532  3756 solver.cpp:228] Iteration 156, loss = 1.7492
I0422 14:43:01.309552  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:01.309561  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.59668 (* 1 = 1.59668 loss)
I0422 14:43:01.309566  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:01.309571  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:01.309574  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:01.309577  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:01.309582  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.149225 (* 1 = 0.149225 loss)
I0422 14:43:01.309587  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00329813 (* 1 = 0.00329813 loss)
I0422 14:43:01.309593  3756 sgd_solver.cpp:106] Iteration 156, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:05.594208  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:05.594230  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:05.594235  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:43:05.609838  3756 solver.cpp:228] Iteration 157, loss = 2.46385
I0422 14:43:05.609855  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:05.609863  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.30242 (* 1 = 2.30242 loss)
I0422 14:43:05.609869  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:05.609872  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:05.609876  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:05.609880  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:05.609885  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.157827 (* 1 = 0.157827 loss)
I0422 14:43:05.609895  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00360841 (* 1 = 0.00360841 loss)
I0422 14:43:05.609901  3756 sgd_solver.cpp:106] Iteration 157, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:43:09.895467  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:43:09.895488  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:09.895493  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 31
('accuracy: ', 0.0)
I0422 14:43:09.911082  3756 solver.cpp:228] Iteration 158, loss = 2.30985
I0422 14:43:09.911099  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:09.911110  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.20291 (* 1 = 2.20291 loss)
I0422 14:43:09.911118  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:09.911120  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:43:09.911125  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:09.911128  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:09.911134  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.100858 (* 1 = 0.100858 loss)
I0422 14:43:09.911139  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00607434 (* 1 = 0.00607434 loss)
I0422 14:43:09.911144  3756 sgd_solver.cpp:106] Iteration 158, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:14.203407  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:14.203428  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:14.203433  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 14:43:14.218772  3756 solver.cpp:228] Iteration 159, loss = 2.15483
I0422 14:43:14.218791  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:14.218798  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.03706 (* 1 = 2.03706 loss)
I0422 14:43:14.218803  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:14.218807  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:14.218812  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:14.218816  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:14.218819  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.113998 (* 1 = 0.113998 loss)
I0422 14:43:14.218824  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00377021 (* 1 = 0.00377021 loss)
I0422 14:43:14.218830  3756 sgd_solver.cpp:106] Iteration 159, lr = 0.0001
speed: 4.304s / iter
rpn: num_positive 3
rpn: num_negative 61
I0422 14:43:18.498417  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:43:18.498448  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:18.498453  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 14:43:18.513620  3756 solver.cpp:228] Iteration 160, loss = 2.49927
I0422 14:43:18.513648  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:18.513655  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.38606 (* 1 = 2.38606 loss)
I0422 14:43:18.513660  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:18.513664  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:43:18.513669  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:18.513672  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:18.513676  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.102122 (* 1 = 0.102122 loss)
I0422 14:43:18.513682  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0110809 (* 1 = 0.0110809 loss)
I0422 14:43:18.513687  3756 sgd_solver.cpp:106] Iteration 160, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:43:22.799177  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:43:22.799199  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:22.799204  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 3
num bg: 7
('accuracy: ', 0.0)
I0422 14:43:22.809536  3756 solver.cpp:228] Iteration 161, loss = 2.81869
I0422 14:43:22.809554  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:22.809562  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.77475 (* 1 = 2.77475 loss)
I0422 14:43:22.809567  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:22.809571  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:43:22.809576  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:22.809578  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:22.809583  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0315384 (* 1 = 0.0315384 loss)
I0422 14:43:22.809588  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0124009 (* 1 = 0.0124009 loss)
I0422 14:43:22.809594  3756 sgd_solver.cpp:106] Iteration 161, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:27.095074  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:27.095098  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:27.095101  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:43:27.110754  3756 solver.cpp:228] Iteration 162, loss = 1.91792
I0422 14:43:27.110783  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:27.110792  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.80315 (* 1 = 1.80315 loss)
I0422 14:43:27.110798  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:27.110802  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:27.110806  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:27.110810  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:27.110815  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.111016 (* 1 = 0.111016 loss)
I0422 14:43:27.110819  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00375883 (* 1 = 0.00375883 loss)
I0422 14:43:27.110826  3756 sgd_solver.cpp:106] Iteration 162, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:31.400017  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:31.400040  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:31.400054  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 14:43:31.415586  3756 solver.cpp:228] Iteration 163, loss = 2.38896
I0422 14:43:31.415613  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:31.415621  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.21096 (* 1 = 2.21096 loss)
I0422 14:43:31.415627  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:31.415630  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:31.415634  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:31.415637  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:31.415642  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.173094 (* 1 = 0.173094 loss)
I0422 14:43:31.415647  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00491172 (* 1 = 0.00491172 loss)
I0422 14:43:31.415652  3756 sgd_solver.cpp:106] Iteration 163, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:35.700382  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:35.700403  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:35.700407  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:43:35.715857  3756 solver.cpp:228] Iteration 164, loss = 2.39167
I0422 14:43:35.715875  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:35.715883  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.26864 (* 1 = 2.26864 loss)
I0422 14:43:35.715888  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:35.715891  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:35.715895  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:35.715898  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:35.715904  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.116263 (* 1 = 0.116263 loss)
I0422 14:43:35.715909  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0067735 (* 1 = 0.0067735 loss)
I0422 14:43:35.715914  3756 sgd_solver.cpp:106] Iteration 164, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:39.988415  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:39.988435  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:39.988440  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:43:40.003975  3756 solver.cpp:228] Iteration 165, loss = 2.12968
I0422 14:43:40.004003  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:40.004010  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.9304 (* 1 = 1.9304 loss)
I0422 14:43:40.004016  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:40.004020  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:40.004024  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:40.004027  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:40.004032  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.1853 (* 1 = 0.1853 loss)
I0422 14:43:40.004037  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0139786 (* 1 = 0.0139786 loss)
I0422 14:43:40.004042  3756 sgd_solver.cpp:106] Iteration 165, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:44.301229  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:44.301250  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:44.301254  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:43:44.317101  3756 solver.cpp:228] Iteration 166, loss = 1.75211
I0422 14:43:44.317119  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:44.317127  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.62654 (* 1 = 1.62654 loss)
I0422 14:43:44.317132  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:44.317137  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:44.317142  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:44.317144  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:44.317149  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.121104 (* 1 = 0.121104 loss)
I0422 14:43:44.317154  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0044615 (* 1 = 0.0044615 loss)
I0422 14:43:44.317160  3756 sgd_solver.cpp:106] Iteration 166, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:48.605020  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:48.605042  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:48.605046  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 14:43:48.620781  3756 solver.cpp:228] Iteration 167, loss = 1.81417
I0422 14:43:48.620800  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:48.620806  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.69946 (* 1 = 1.69946 loss)
I0422 14:43:48.620812  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:48.620816  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:48.620820  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:48.620824  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:48.620828  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.111543 (* 1 = 0.111543 loss)
I0422 14:43:48.620834  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00316772 (* 1 = 0.00316772 loss)
I0422 14:43:48.620839  3756 sgd_solver.cpp:106] Iteration 167, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:52.906797  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:52.906819  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:52.906824  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:43:52.922274  3756 solver.cpp:228] Iteration 168, loss = 2.34827
I0422 14:43:52.922296  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:52.922303  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.20687 (* 1 = 2.20687 loss)
I0422 14:43:52.922308  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:52.922312  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:52.922317  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:52.922320  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:52.922325  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.138562 (* 1 = 0.138562 loss)
I0422 14:43:52.922330  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00284086 (* 1 = 0.00284086 loss)
I0422 14:43:52.922336  3756 sgd_solver.cpp:106] Iteration 168, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:43:57.197386  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:43:57.197415  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:43:57.197420  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:43:57.212903  3756 solver.cpp:228] Iteration 169, loss = 2.12529
I0422 14:43:57.212932  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:43:57.212940  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.94731 (* 1 = 1.94731 loss)
I0422 14:43:57.212945  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:43:57.212949  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:43:57.212954  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:43:57.212957  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:43:57.212961  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.174803 (* 1 = 0.174803 loss)
I0422 14:43:57.212966  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00317243 (* 1 = 0.00317243 loss)
I0422 14:43:57.212972  3756 sgd_solver.cpp:106] Iteration 169, lr = 0.0001
speed: 4.304s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:44:01.503098  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:44:01.503119  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:01.503124  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:44:01.518501  3756 solver.cpp:228] Iteration 170, loss = 1.68968
I0422 14:44:01.518519  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:01.518527  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.56149 (* 1 = 1.56149 loss)
I0422 14:44:01.518532  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:01.518537  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:44:01.518540  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:01.518544  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:44:01.518549  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.124438 (* 1 = 0.124438 loss)
I0422 14:44:01.518554  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00375179 (* 1 = 0.00375179 loss)
I0422 14:44:01.518560  3756 sgd_solver.cpp:106] Iteration 170, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:44:05.807086  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:44:05.807108  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:05.807112  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:44:05.822644  3756 solver.cpp:228] Iteration 171, loss = 1.92993
I0422 14:44:05.822662  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:05.822670  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.76333 (* 1 = 1.76333 loss)
I0422 14:44:05.822676  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:05.822679  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:44:05.822684  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:05.822687  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:05.822692  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.162563 (* 1 = 0.162563 loss)
I0422 14:44:05.822702  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00402986 (* 1 = 0.00402986 loss)
I0422 14:44:05.822708  3756 sgd_solver.cpp:106] Iteration 171, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:44:10.106775  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:44:10.106797  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:10.106802  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:44:10.122243  3756 solver.cpp:228] Iteration 172, loss = 2.24815
I0422 14:44:10.122262  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:10.122269  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.07472 (* 1 = 2.07472 loss)
I0422 14:44:10.122274  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:10.122278  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:44:10.122282  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:10.122287  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:10.122290  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.169895 (* 1 = 0.169895 loss)
I0422 14:44:10.122295  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00353238 (* 1 = 0.00353238 loss)
I0422 14:44:10.122301  3756 sgd_solver.cpp:106] Iteration 172, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:44:14.407078  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:44:14.407110  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:14.407115  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 14:44:14.422581  3756 solver.cpp:228] Iteration 173, loss = 2.52786
I0422 14:44:14.422600  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:14.422608  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.29697 (* 1 = 2.29697 loss)
I0422 14:44:14.422613  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:14.422617  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:44:14.422621  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:14.422624  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:14.422629  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.22685 (* 1 = 0.22685 loss)
I0422 14:44:14.422634  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00403966 (* 1 = 0.00403966 loss)
I0422 14:44:14.422641  3756 sgd_solver.cpp:106] Iteration 173, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:44:18.687196  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:44:18.687218  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:18.687223  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 27
('accuracy: ', 0.0)
I0422 14:44:18.702574  3756 solver.cpp:228] Iteration 174, loss = 2.08723
I0422 14:44:18.702592  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:18.702600  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.89658 (* 1 = 1.89658 loss)
I0422 14:44:18.702606  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:18.702610  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:44:18.702615  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:18.702617  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:18.702622  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.184343 (* 1 = 0.184343 loss)
I0422 14:44:18.702627  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00630891 (* 1 = 0.00630891 loss)
I0422 14:44:18.702632  3756 sgd_solver.cpp:106] Iteration 174, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:44:22.970085  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:44:22.970108  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:22.970113  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:44:22.985597  3756 solver.cpp:228] Iteration 175, loss = 1.737
I0422 14:44:22.985616  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:22.985625  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.60212 (* 1 = 1.60212 loss)
I0422 14:44:22.985630  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:22.985633  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:44:22.985637  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:22.985646  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:22.985651  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.131468 (* 1 = 0.131468 loss)
I0422 14:44:22.985656  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00341258 (* 1 = 0.00341258 loss)
I0422 14:44:22.985661  3756 sgd_solver.cpp:106] Iteration 175, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:44:27.284996  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:44:27.285018  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:27.285023  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 28
('accuracy: ', 0.0)
I0422 14:44:27.300686  3756 solver.cpp:228] Iteration 176, loss = 1.47372
I0422 14:44:27.300704  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:27.300711  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.29548 (* 1 = 1.29548 loss)
I0422 14:44:27.300719  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:27.300724  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:44:27.300729  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:27.300732  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:27.300740  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.174371 (* 1 = 0.174371 loss)
I0422 14:44:27.300746  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00386436 (* 1 = 0.00386436 loss)
I0422 14:44:27.300753  3756 sgd_solver.cpp:106] Iteration 176, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:44:31.587762  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:44:31.587783  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:31.587788  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:44:31.603241  3756 solver.cpp:228] Iteration 177, loss = 2.36644
I0422 14:44:31.603258  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:31.603266  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.17559 (* 1 = 2.17559 loss)
I0422 14:44:31.603271  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:31.603276  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:44:31.603279  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:31.603283  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:31.603287  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.181357 (* 1 = 0.181357 loss)
I0422 14:44:31.603292  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00948565 (* 1 = 0.00948565 loss)
I0422 14:44:31.603297  3756 sgd_solver.cpp:106] Iteration 177, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:44:35.885260  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:44:35.885283  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:35.885288  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 34
('accuracy: ', 0.0)
I0422 14:44:35.901060  3756 solver.cpp:228] Iteration 178, loss = 1.61736
I0422 14:44:35.901078  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:35.901087  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.50128 (* 1 = 1.50128 loss)
I0422 14:44:35.901091  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:35.901095  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:44:35.901099  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:35.901103  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:35.901108  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.110662 (* 1 = 0.110662 loss)
I0422 14:44:35.901113  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0054154 (* 1 = 0.0054154 loss)
I0422 14:44:35.901118  3756 sgd_solver.cpp:106] Iteration 178, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:44:40.183650  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:44:40.183671  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:40.183676  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 14:44:40.199023  3756 solver.cpp:228] Iteration 179, loss = 2.28554
I0422 14:44:40.199041  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:40.199049  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.19454 (* 1 = 2.19454 loss)
I0422 14:44:40.199054  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:40.199059  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:44:40.199062  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:40.199065  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:40.199070  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0885756 (* 1 = 0.0885756 loss)
I0422 14:44:40.199075  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00241648 (* 1 = 0.00241648 loss)
I0422 14:44:40.199080  3756 sgd_solver.cpp:106] Iteration 179, lr = 0.0001
speed: 4.304s / iter
rpn: num_positive 1
rpn: num_negative 63
I0422 14:44:44.490061  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:44:44.490082  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:44.490087  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 1
num bg: 16
('accuracy: ', 0.0)
I0422 14:44:44.503957  3756 solver.cpp:228] Iteration 180, loss = 0.793966
I0422 14:44:44.503976  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:44.503984  3756 solver.cpp:244]     Train net output #1: loss_cls = 0.73442 (* 1 = 0.73442 loss)
I0422 14:44:44.503989  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:44.503993  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:44:44.503998  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:44.504001  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:44.504006  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0478686 (* 1 = 0.0478686 loss)
I0422 14:44:44.504011  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0116771 (* 1 = 0.0116771 loss)
I0422 14:44:44.504016  3756 sgd_solver.cpp:106] Iteration 180, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:44:48.779681  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:44:48.779702  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:48.779707  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 5
num bg: 21
('accuracy: ', 0.0)
I0422 14:44:48.794998  3756 solver.cpp:228] Iteration 181, loss = 1.72694
I0422 14:44:48.795019  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:48.795027  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.6373 (* 1 = 1.6373 loss)
I0422 14:44:48.795032  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:48.795037  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:44:48.795040  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:48.795044  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:48.795049  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0776027 (* 1 = 0.0776027 loss)
I0422 14:44:48.795053  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0120314 (* 1 = 0.0120314 loss)
I0422 14:44:48.795059  3756 sgd_solver.cpp:106] Iteration 181, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:44:53.082227  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:44:53.082248  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:53.082253  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 31
('accuracy: ', 0.0)
I0422 14:44:53.099529  3756 solver.cpp:228] Iteration 182, loss = 1.76131
I0422 14:44:53.099553  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:53.099561  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.65229 (* 1 = 1.65229 loss)
I0422 14:44:53.099566  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:53.099570  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:44:53.099575  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:53.099578  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:53.099582  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.105168 (* 1 = 0.105168 loss)
I0422 14:44:53.099588  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00385261 (* 1 = 0.00385261 loss)
I0422 14:44:53.099593  3756 sgd_solver.cpp:106] Iteration 182, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:44:57.390849  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:44:57.390871  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:44:57.390875  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 5
num bg: 20
('accuracy: ', 0.0)
I0422 14:44:57.406137  3756 solver.cpp:228] Iteration 183, loss = 1.66162
I0422 14:44:57.406157  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:44:57.406164  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.55211 (* 1 = 1.55211 loss)
I0422 14:44:57.406170  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:44:57.406173  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:44:57.406178  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:44:57.406183  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:44:57.406186  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0976881 (* 1 = 0.0976881 loss)
I0422 14:44:57.406191  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0118219 (* 1 = 0.0118219 loss)
I0422 14:44:57.406198  3756 sgd_solver.cpp:106] Iteration 183, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:45:01.695768  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:45:01.695789  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:01.695796  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 6
num bg: 16
('accuracy: ', 0.0)
I0422 14:45:01.711937  3756 solver.cpp:228] Iteration 184, loss = 2.10256
I0422 14:45:01.711959  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:01.711968  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.06405 (* 1 = 2.06405 loss)
I0422 14:45:01.711974  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:01.711978  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:45:01.711983  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:01.711987  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:45:01.711992  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0263074 (* 1 = 0.0263074 loss)
I0422 14:45:01.711997  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0122032 (* 1 = 0.0122032 loss)
I0422 14:45:01.712003  3756 sgd_solver.cpp:106] Iteration 184, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:45:05.980522  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:45:05.980542  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:05.980546  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:45:05.995993  3756 solver.cpp:228] Iteration 185, loss = 2.14397
I0422 14:45:05.996019  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:05.996027  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.04441 (* 1 = 2.04441 loss)
I0422 14:45:05.996032  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:05.996037  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:45:05.996040  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:05.996043  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:45:05.996048  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0970262 (* 1 = 0.0970262 loss)
I0422 14:45:05.996053  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00254004 (* 1 = 0.00254004 loss)
I0422 14:45:05.996059  3756 sgd_solver.cpp:106] Iteration 185, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:45:10.277837  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:45:10.277858  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:10.277863  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 7
num bg: 32
('accuracy: ', 0.0)
I0422 14:45:10.293407  3756 solver.cpp:228] Iteration 186, loss = 1.89103
I0422 14:45:10.293426  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:10.293435  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.79288 (* 1 = 1.79288 loss)
I0422 14:45:10.293440  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:10.293444  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:45:10.293449  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:10.293452  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:45:10.293458  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0954807 (* 1 = 0.0954807 loss)
I0422 14:45:10.293463  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00267019 (* 1 = 0.00267019 loss)
I0422 14:45:10.293468  3756 sgd_solver.cpp:106] Iteration 186, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:45:14.598204  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:45:14.598225  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:14.598240  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 14:45:14.615617  3756 solver.cpp:228] Iteration 187, loss = 1.79666
I0422 14:45:14.615650  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:14.615658  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.674 (* 1 = 1.674 loss)
I0422 14:45:14.615664  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:14.615667  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:45:14.615671  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:14.615675  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:45:14.615680  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.12015 (* 1 = 0.12015 loss)
I0422 14:45:14.615689  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00250755 (* 1 = 0.00250755 loss)
I0422 14:45:14.615698  3756 sgd_solver.cpp:106] Iteration 187, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:45:18.889101  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:45:18.889122  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:18.889127  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 4
num bg: 12
('accuracy: ', 0.0)
I0422 14:45:18.902747  3756 solver.cpp:228] Iteration 188, loss = 2.4092
I0422 14:45:18.902784  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:18.902797  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.34336 (* 1 = 2.34336 loss)
I0422 14:45:18.902807  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:18.902813  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:45:18.902822  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:18.902832  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:45:18.902844  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0600865 (* 1 = 0.0600865 loss)
I0422 14:45:18.902854  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0057601 (* 1 = 0.0057601 loss)
I0422 14:45:18.902865  3756 sgd_solver.cpp:106] Iteration 188, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:45:23.172837  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:45:23.172858  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:23.172865  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 22
('accuracy: ', 0.0)
I0422 14:45:23.189030  3756 solver.cpp:228] Iteration 189, loss = 1.81637
I0422 14:45:23.189049  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:23.189060  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.75179 (* 1 = 1.75179 loss)
I0422 14:45:23.189071  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:23.189079  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:45:23.189088  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:23.189095  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:45:23.189105  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0616442 (* 1 = 0.0616442 loss)
I0422 14:45:23.189115  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00293472 (* 1 = 0.00293472 loss)
I0422 14:45:23.189126  3756 sgd_solver.cpp:106] Iteration 189, lr = 0.0001
speed: 4.304s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:45:27.478201  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:45:27.478224  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:27.478230  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 14:45:27.493736  3756 solver.cpp:228] Iteration 190, loss = 2.54552
I0422 14:45:27.493754  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:27.493767  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.42452 (* 1 = 2.42452 loss)
I0422 14:45:27.493778  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:27.493788  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:45:27.493798  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:27.493804  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:45:27.493813  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.11713 (* 1 = 0.11713 loss)
I0422 14:45:27.493824  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00386551 (* 1 = 0.00386551 loss)
I0422 14:45:27.493834  3756 sgd_solver.cpp:106] Iteration 190, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:45:31.760818  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:45:31.760838  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:31.760843  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 14:45:31.776440  3756 solver.cpp:228] Iteration 191, loss = 2.00565
I0422 14:45:31.776470  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:31.776479  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.85413 (* 1 = 1.85413 loss)
I0422 14:45:31.776484  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:31.776489  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:45:31.776494  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:31.776497  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:45:31.776501  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.14776 (* 1 = 0.14776 loss)
I0422 14:45:31.776507  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00375048 (* 1 = 0.00375048 loss)
I0422 14:45:31.776512  3756 sgd_solver.cpp:106] Iteration 191, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:45:36.093475  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:45:36.093497  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:36.093502  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 33
('accuracy: ', 0.0)
I0422 14:45:36.109722  3756 solver.cpp:228] Iteration 192, loss = 1.61408
I0422 14:45:36.109742  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:36.109750  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.48292 (* 1 = 1.48292 loss)
I0422 14:45:36.109755  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:36.109760  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:45:36.109763  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:36.109768  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:45:36.109773  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.126596 (* 1 = 0.126596 loss)
I0422 14:45:36.109778  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00457318 (* 1 = 0.00457318 loss)
I0422 14:45:36.109784  3756 sgd_solver.cpp:106] Iteration 192, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:45:40.394193  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:45:40.394214  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:40.394219  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 4
num bg: 7
('accuracy: ', 0.0)
I0422 14:45:40.404788  3756 solver.cpp:228] Iteration 193, loss = 2.7785
I0422 14:45:40.404805  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:40.404814  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.70713 (* 1 = 2.70713 loss)
I0422 14:45:40.404819  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:40.404824  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:45:40.404827  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:40.404830  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:45:40.404835  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0637832 (* 1 = 0.0637832 loss)
I0422 14:45:40.404840  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00757914 (* 1 = 0.00757914 loss)
I0422 14:45:40.404845  3756 sgd_solver.cpp:106] Iteration 193, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:45:44.678375  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:45:44.678396  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:44.678401  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 14:45:44.694198  3756 solver.cpp:228] Iteration 194, loss = 2.16636
I0422 14:45:44.694216  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:44.694224  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.04857 (* 1 = 2.04857 loss)
I0422 14:45:44.694231  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:44.694233  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:45:44.694237  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:44.694242  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:45:44.694247  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.113197 (* 1 = 0.113197 loss)
I0422 14:45:44.694252  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00460123 (* 1 = 0.00460123 loss)
I0422 14:45:44.694257  3756 sgd_solver.cpp:106] Iteration 194, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:45:48.975325  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:45:48.975356  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:48.975373  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 32
('accuracy: ', 0.0)
I0422 14:45:48.991003  3756 solver.cpp:228] Iteration 195, loss = 2.05867
I0422 14:45:48.991020  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:48.991029  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.93869 (* 1 = 1.93869 loss)
I0422 14:45:48.991034  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:48.991037  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:45:48.991041  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:48.991044  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:45:48.991050  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.115726 (* 1 = 0.115726 loss)
I0422 14:45:48.991055  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00425337 (* 1 = 0.00425337 loss)
I0422 14:45:48.991060  3756 sgd_solver.cpp:106] Iteration 195, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:45:53.291762  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:45:53.291793  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:53.291798  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 14:45:53.307301  3756 solver.cpp:228] Iteration 196, loss = 1.97592
I0422 14:45:53.307318  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:53.307327  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.85584 (* 1 = 1.85584 loss)
I0422 14:45:53.307332  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:53.307335  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:45:53.307339  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:53.307343  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:45:53.307348  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.115793 (* 1 = 0.115793 loss)
I0422 14:45:53.307353  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00427878 (* 1 = 0.00427878 loss)
I0422 14:45:53.307358  3756 sgd_solver.cpp:106] Iteration 196, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:45:57.588425  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:45:57.588446  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:45:57.588451  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
num fg: 8
num bg: 24
('accuracy: ', 0.0)
I0422 14:45:57.604034  3756 solver.cpp:228] Iteration 197, loss = 2.05458
I0422 14:45:57.604054  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:45:57.604063  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.0038 (* 1 = 2.0038 loss)
I0422 14:45:57.604068  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:45:57.604071  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:45:57.604076  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:45:57.604079  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 14:45:57.604085  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0486214 (* 1 = 0.0486214 loss)
I0422 14:45:57.604090  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00214971 (* 1 = 0.00214971 loss)
I0422 14:45:57.604095  3756 sgd_solver.cpp:106] Iteration 197, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:01.894325  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:01.894346  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:01.894351  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:46:01.909811  3756 solver.cpp:228] Iteration 198, loss = 1.95695
I0422 14:46:01.909838  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:01.909845  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.8047 (* 1 = 1.8047 loss)
I0422 14:46:01.909852  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:01.909855  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:01.909859  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:01.909862  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:01.909868  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.149215 (* 1 = 0.149215 loss)
I0422 14:46:01.909873  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00303268 (* 1 = 0.00303268 loss)
I0422 14:46:01.909878  3756 sgd_solver.cpp:106] Iteration 198, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:06.206643  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:06.206665  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:06.206671  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 33
('accuracy: ', 0.0)
I0422 14:46:06.222913  3756 solver.cpp:228] Iteration 199, loss = 2.12402
I0422 14:46:06.222934  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:06.222941  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.01872 (* 1 = 2.01872 loss)
I0422 14:46:06.222947  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:06.222950  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:06.222955  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:06.222959  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:06.222964  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.102258 (* 1 = 0.102258 loss)
I0422 14:46:06.222970  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00303737 (* 1 = 0.00303737 loss)
I0422 14:46:06.222980  3756 sgd_solver.cpp:106] Iteration 199, lr = 0.0001
speed: 4.304s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:10.519573  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:10.519595  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:10.519603  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:46:10.535270  3756 solver.cpp:228] Iteration 200, loss = 1.98971
I0422 14:46:10.535287  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:10.535295  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.86122 (* 1 = 1.86122 loss)
I0422 14:46:10.535300  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:10.535305  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:10.535308  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:10.535312  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:10.535316  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.124675 (* 1 = 0.124675 loss)
I0422 14:46:10.535321  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00381123 (* 1 = 0.00381123 loss)
I0422 14:46:10.535327  3756 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:14.802520  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:14.802541  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:14.802544  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:46:14.817956  3756 solver.cpp:228] Iteration 201, loss = 1.96201
I0422 14:46:14.817975  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:14.817983  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.85367 (* 1 = 1.85367 loss)
I0422 14:46:14.817988  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:14.817992  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:14.817997  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:14.818001  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:14.818012  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.104315 (* 1 = 0.104315 loss)
I0422 14:46:14.818017  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00402416 (* 1 = 0.00402416 loss)
I0422 14:46:14.818025  3756 sgd_solver.cpp:106] Iteration 201, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:19.103056  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:19.103078  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:19.103083  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 31
('accuracy: ', 0.0)
I0422 14:46:19.118738  3756 solver.cpp:228] Iteration 202, loss = 1.80827
I0422 14:46:19.118757  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:19.118780  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.6817 (* 1 = 1.6817 loss)
I0422 14:46:19.118786  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:19.118790  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:19.118794  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:19.118798  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:19.118803  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.118406 (* 1 = 0.118406 loss)
I0422 14:46:19.118808  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00816345 (* 1 = 0.00816345 loss)
I0422 14:46:19.118813  3756 sgd_solver.cpp:106] Iteration 202, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:23.426059  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:23.426081  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:23.426085  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 14:46:23.441946  3756 solver.cpp:228] Iteration 203, loss = 2.35699
I0422 14:46:23.441964  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:23.441972  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.21496 (* 1 = 2.21496 loss)
I0422 14:46:23.441977  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:23.441980  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:23.441984  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:23.441987  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:23.441992  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.136629 (* 1 = 0.136629 loss)
I0422 14:46:23.441996  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00540622 (* 1 = 0.00540622 loss)
I0422 14:46:23.442003  3756 sgd_solver.cpp:106] Iteration 203, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:27.710731  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:27.710753  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:27.710757  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 14:46:27.726171  3756 solver.cpp:228] Iteration 204, loss = 2.44327
I0422 14:46:27.726191  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:27.726198  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.3383 (* 1 = 2.3383 loss)
I0422 14:46:27.726204  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:27.726208  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:27.726212  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:27.726217  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:27.726222  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.102252 (* 1 = 0.102252 loss)
I0422 14:46:27.726227  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00272307 (* 1 = 0.00272307 loss)
I0422 14:46:27.726231  3756 sgd_solver.cpp:106] Iteration 204, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:46:32.009829  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:46:32.009850  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:32.009855  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 22
('accuracy: ', 0.0)
I0422 14:46:32.025549  3756 solver.cpp:228] Iteration 205, loss = 2.15529
I0422 14:46:32.025568  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:32.025575  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.10189 (* 1 = 2.10189 loss)
I0422 14:46:32.025580  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:32.025584  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:46:32.025588  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:32.025593  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:32.025596  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0478279 (* 1 = 0.0478279 loss)
I0422 14:46:32.025601  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00557892 (* 1 = 0.00557892 loss)
I0422 14:46:32.025607  3756 sgd_solver.cpp:106] Iteration 205, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:36.340037  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:36.340059  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:36.340065  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:46:36.355856  3756 solver.cpp:228] Iteration 206, loss = 2.05083
I0422 14:46:36.355876  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:36.355885  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.89531 (* 1 = 1.89531 loss)
I0422 14:46:36.355890  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:36.355895  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:36.355898  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:36.355901  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:36.355907  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.150708 (* 1 = 0.150708 loss)
I0422 14:46:36.355912  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00481492 (* 1 = 0.00481492 loss)
I0422 14:46:36.355918  3756 sgd_solver.cpp:106] Iteration 206, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:40.654909  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:40.654930  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:40.654935  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:46:40.670456  3756 solver.cpp:228] Iteration 207, loss = 2.0698
I0422 14:46:40.670475  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:40.670483  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.92315 (* 1 = 1.92315 loss)
I0422 14:46:40.670488  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:40.670492  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:40.670496  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:40.670500  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:40.670505  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.143197 (* 1 = 0.143197 loss)
I0422 14:46:40.670509  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00345026 (* 1 = 0.00345026 loss)
I0422 14:46:40.670516  3756 sgd_solver.cpp:106] Iteration 207, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:44.954347  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:46:44.954370  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:44.954373  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 14:46:44.969995  3756 solver.cpp:228] Iteration 208, loss = 1.80362
I0422 14:46:44.970012  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:44.970021  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.66438 (* 1 = 1.66438 loss)
I0422 14:46:44.970026  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:44.970028  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:46:44.970032  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:44.970036  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:46:44.970042  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.13623 (* 1 = 0.13623 loss)
I0422 14:46:44.970046  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00301443 (* 1 = 0.00301443 loss)
I0422 14:46:44.970052  3756 sgd_solver.cpp:106] Iteration 208, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:49.239318  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:49.239341  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:49.239346  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 14:46:49.254600  3756 solver.cpp:228] Iteration 209, loss = 2.15849
I0422 14:46:49.254617  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:49.254626  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.94618 (* 1 = 1.94618 loss)
I0422 14:46:49.254631  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:49.254634  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:49.254638  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:49.254642  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:49.254647  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.208179 (* 1 = 0.208179 loss)
I0422 14:46:49.254652  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0041328 (* 1 = 0.0041328 loss)
I0422 14:46:49.254657  3756 sgd_solver.cpp:106] Iteration 209, lr = 0.0001
speed: 4.304s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:53.540709  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:46:53.540729  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:53.540735  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:46:53.556555  3756 solver.cpp:228] Iteration 210, loss = 2.0493
I0422 14:46:53.556576  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:53.556583  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.91502 (* 1 = 1.91502 loss)
I0422 14:46:53.556588  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:53.556592  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:46:53.556596  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:53.556601  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:46:53.556604  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.131061 (* 1 = 0.131061 loss)
I0422 14:46:53.556609  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00321519 (* 1 = 0.00321519 loss)
I0422 14:46:53.556615  3756 sgd_solver.cpp:106] Iteration 210, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:46:57.850354  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:46:57.850385  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:46:57.850390  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:46:57.866080  3756 solver.cpp:228] Iteration 211, loss = 2.23538
I0422 14:46:57.866097  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:46:57.866106  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.0995 (* 1 = 2.0995 loss)
I0422 14:46:57.866111  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:46:57.866114  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:46:57.866118  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:46:57.866122  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:46:57.866127  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.131731 (* 1 = 0.131731 loss)
I0422 14:46:57.866132  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00414976 (* 1 = 0.00414976 loss)
I0422 14:46:57.866137  3756 sgd_solver.cpp:106] Iteration 211, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:47:02.146615  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:47:02.146636  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:02.146641  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:47:02.162019  3756 solver.cpp:228] Iteration 212, loss = 2.50424
I0422 14:47:02.162035  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:02.162042  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.38135 (* 1 = 2.38135 loss)
I0422 14:47:02.162047  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:02.162051  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:47:02.162055  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:02.162058  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:47:02.162063  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.115625 (* 1 = 0.115625 loss)
I0422 14:47:02.162068  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00726155 (* 1 = 0.00726155 loss)
I0422 14:47:02.162073  3756 sgd_solver.cpp:106] Iteration 212, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:47:06.439978  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:47:06.439999  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:06.440004  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 14:47:06.455462  3756 solver.cpp:228] Iteration 213, loss = 1.87894
I0422 14:47:06.455480  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:06.455488  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.71222 (* 1 = 1.71222 loss)
I0422 14:47:06.455494  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:06.455498  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:47:06.455502  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:06.455505  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:47:06.455510  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.163678 (* 1 = 0.163678 loss)
I0422 14:47:06.455515  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00303358 (* 1 = 0.00303358 loss)
I0422 14:47:06.455521  3756 sgd_solver.cpp:106] Iteration 213, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:47:10.751862  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:47:10.751881  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:10.751895  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 7
num bg: 28
('accuracy: ', 0.0)
I0422 14:47:10.771227  3756 solver.cpp:228] Iteration 214, loss = 1.67424
I0422 14:47:10.771255  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:10.771265  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.50183 (* 1 = 1.50183 loss)
I0422 14:47:10.771271  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:10.771277  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:47:10.771282  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:10.771287  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:47:10.771293  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.168608 (* 1 = 0.168608 loss)
I0422 14:47:10.771301  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00380282 (* 1 = 0.00380282 loss)
I0422 14:47:10.771307  3756 sgd_solver.cpp:106] Iteration 214, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:47:15.042800  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:47:15.042822  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:15.042827  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 22
('accuracy: ', 0.0)
I0422 14:47:15.058295  3756 solver.cpp:228] Iteration 215, loss = 2.84382
I0422 14:47:15.058315  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:15.058323  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.7431 (* 1 = 2.7431 loss)
I0422 14:47:15.058328  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:15.058333  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:47:15.058337  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:15.058341  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:47:15.058346  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0931995 (* 1 = 0.0931995 loss)
I0422 14:47:15.058352  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00751716 (* 1 = 0.00751716 loss)
I0422 14:47:15.058357  3756 sgd_solver.cpp:106] Iteration 215, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:47:19.366751  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:47:19.366801  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:19.366807  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 14:47:19.382702  3756 solver.cpp:228] Iteration 216, loss = 1.89143
I0422 14:47:19.382722  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:19.382730  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.74396 (* 1 = 1.74396 loss)
I0422 14:47:19.382735  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:19.382738  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:47:19.382741  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:19.382745  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:47:19.382750  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.135119 (* 1 = 0.135119 loss)
I0422 14:47:19.382755  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0123523 (* 1 = 0.0123523 loss)
I0422 14:47:19.382773  3756 sgd_solver.cpp:106] Iteration 216, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:47:23.664506  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:47:23.664530  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:23.664535  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 14:47:23.679929  3756 solver.cpp:228] Iteration 217, loss = 2.41963
I0422 14:47:23.679947  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:23.679955  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.31026 (* 1 = 2.31026 loss)
I0422 14:47:23.679960  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:23.679965  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:47:23.679970  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:23.679973  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:47:23.679978  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0960786 (* 1 = 0.0960786 loss)
I0422 14:47:23.679983  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0132917 (* 1 = 0.0132917 loss)
I0422 14:47:23.679989  3756 sgd_solver.cpp:106] Iteration 217, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:47:27.964956  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:47:27.964978  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:27.964982  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:47:27.980651  3756 solver.cpp:228] Iteration 218, loss = 1.85545
I0422 14:47:27.980670  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:27.980677  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.70438 (* 1 = 1.70438 loss)
I0422 14:47:27.980682  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:27.980686  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:47:27.980690  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:27.980695  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:47:27.980698  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.14044 (* 1 = 0.14044 loss)
I0422 14:47:27.980705  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0106262 (* 1 = 0.0106262 loss)
I0422 14:47:27.980710  3756 sgd_solver.cpp:106] Iteration 218, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:47:32.256572  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:47:32.256593  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:32.256609  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:47:32.272038  3756 solver.cpp:228] Iteration 219, loss = 2.28372
I0422 14:47:32.272058  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:32.272065  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.19376 (* 1 = 2.19376 loss)
I0422 14:47:32.272070  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:32.272076  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:47:32.272081  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:32.272084  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:47:32.272091  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0862485 (* 1 = 0.0862485 loss)
I0422 14:47:32.272097  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00371473 (* 1 = 0.00371473 loss)
I0422 14:47:32.272104  3756 sgd_solver.cpp:106] Iteration 219, lr = 0.0001
speed: 4.303s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:47:36.565093  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:47:36.565116  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:36.565121  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 14:47:36.580690  3756 solver.cpp:228] Iteration 220, loss = 2.28392
I0422 14:47:36.580710  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:36.580718  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.18115 (* 1 = 2.18115 loss)
I0422 14:47:36.580724  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:36.580727  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:47:36.580731  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:36.580734  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:47:36.580739  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0980944 (* 1 = 0.0980944 loss)
I0422 14:47:36.580744  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00467286 (* 1 = 0.00467286 loss)
I0422 14:47:36.580750  3756 sgd_solver.cpp:106] Iteration 220, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:47:40.885376  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:47:40.885397  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:40.885401  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 2
num bg: 15
('accuracy: ', 0.0)
I0422 14:47:40.899426  3756 solver.cpp:228] Iteration 221, loss = 0.970053
I0422 14:47:40.899443  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:40.899451  3756 solver.cpp:244]     Train net output #1: loss_cls = 0.897805 (* 1 = 0.897805 loss)
I0422 14:47:40.899459  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:40.899463  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:47:40.899469  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:40.899473  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:47:40.899477  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0675311 (* 1 = 0.0675311 loss)
I0422 14:47:40.899483  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00471665 (* 1 = 0.00471665 loss)
I0422 14:47:40.899489  3756 sgd_solver.cpp:106] Iteration 221, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:47:45.183218  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:47:45.183239  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:45.183244  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 14:47:45.198647  3756 solver.cpp:228] Iteration 222, loss = 1.99041
I0422 14:47:45.198667  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:45.198674  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.84288 (* 1 = 1.84288 loss)
I0422 14:47:45.198679  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:45.198683  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:47:45.198688  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:45.198690  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:47:45.198695  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.142832 (* 1 = 0.142832 loss)
I0422 14:47:45.198702  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00469882 (* 1 = 0.00469882 loss)
I0422 14:47:45.198707  3756 sgd_solver.cpp:106] Iteration 222, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:47:49.482403  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:47:49.482424  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:49.482429  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 6
num bg: 32
('accuracy: ', 0.0)
I0422 14:47:49.497905  3756 solver.cpp:228] Iteration 223, loss = 1.62684
I0422 14:47:49.497922  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:49.497931  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.51878 (* 1 = 1.51878 loss)
I0422 14:47:49.497936  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:49.497939  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:47:49.497943  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:49.497947  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:47:49.497952  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.104623 (* 1 = 0.104623 loss)
I0422 14:47:49.497957  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00344237 (* 1 = 0.00344237 loss)
I0422 14:47:49.497962  3756 sgd_solver.cpp:106] Iteration 223, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:47:53.777113  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:47:53.777135  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:53.777140  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:47:53.792575  3756 solver.cpp:228] Iteration 224, loss = 1.63137
I0422 14:47:53.792604  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:53.792613  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.4802 (* 1 = 1.4802 loss)
I0422 14:47:53.792618  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:53.792621  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:47:53.792625  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:53.792629  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:47:53.792634  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.147401 (* 1 = 0.147401 loss)
I0422 14:47:53.792639  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00376789 (* 1 = 0.00376789 loss)
I0422 14:47:53.792644  3756 sgd_solver.cpp:106] Iteration 224, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:47:58.070000  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:47:58.070022  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:47:58.070027  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:47:58.085443  3756 solver.cpp:228] Iteration 225, loss = 1.89597
I0422 14:47:58.085460  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:47:58.085469  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.78745 (* 1 = 1.78745 loss)
I0422 14:47:58.085474  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:47:58.085477  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:47:58.085481  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:47:58.085485  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:47:58.085490  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.104249 (* 1 = 0.104249 loss)
I0422 14:47:58.085495  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00427543 (* 1 = 0.00427543 loss)
I0422 14:47:58.085500  3756 sgd_solver.cpp:106] Iteration 225, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:48:02.375715  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:48:02.375735  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:02.375739  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 28
('accuracy: ', 0.0)
I0422 14:48:02.391248  3756 solver.cpp:228] Iteration 226, loss = 2.02295
I0422 14:48:02.391269  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:02.391278  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.90539 (* 1 = 1.90539 loss)
I0422 14:48:02.391283  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:02.391286  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:48:02.391290  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:02.391294  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:48:02.391299  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.113462 (* 1 = 0.113462 loss)
I0422 14:48:02.391304  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00410485 (* 1 = 0.00410485 loss)
I0422 14:48:02.391316  3756 sgd_solver.cpp:106] Iteration 226, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:48:06.688374  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:48:06.688395  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:06.688401  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 8
num bg: 16
('accuracy: ', 0.0)
I0422 14:48:06.707105  3756 solver.cpp:228] Iteration 227, loss = 2.44413
I0422 14:48:06.707125  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:06.707134  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.34128 (* 1 = 2.34128 loss)
I0422 14:48:06.707139  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:06.707142  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:48:06.707146  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:06.707149  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 14:48:06.707154  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0895507 (* 1 = 0.0895507 loss)
I0422 14:48:06.707159  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0133017 (* 1 = 0.0133017 loss)
I0422 14:48:06.707165  3756 sgd_solver.cpp:106] Iteration 227, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:48:10.987663  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:48:10.987694  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:10.987699  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 14:48:11.005200  3756 solver.cpp:228] Iteration 228, loss = 1.83584
I0422 14:48:11.005223  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:11.005230  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.71946 (* 1 = 1.71946 loss)
I0422 14:48:11.005235  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:11.005240  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:48:11.005244  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:11.005249  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:48:11.005260  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.112203 (* 1 = 0.112203 loss)
I0422 14:48:11.005265  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00418392 (* 1 = 0.00418392 loss)
I0422 14:48:11.005272  3756 sgd_solver.cpp:106] Iteration 228, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:48:15.287961  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:48:15.287982  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:15.287986  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 4
num bg: 7
('accuracy: ', 0.0)
I0422 14:48:15.298529  3756 solver.cpp:228] Iteration 229, loss = 2.90739
I0422 14:48:15.298547  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:15.298555  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.86309 (* 1 = 2.86309 loss)
I0422 14:48:15.298562  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:15.298564  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:48:15.298568  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:15.298573  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:48:15.298576  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.041602 (* 1 = 0.041602 loss)
I0422 14:48:15.298581  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00270229 (* 1 = 0.00270229 loss)
I0422 14:48:15.298588  3756 sgd_solver.cpp:106] Iteration 229, lr = 0.0001
speed: 4.303s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:48:19.576686  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:48:19.576707  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:19.576711  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 14:48:19.592187  3756 solver.cpp:228] Iteration 230, loss = 1.65058
I0422 14:48:19.592206  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:19.592213  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.55638 (* 1 = 1.55638 loss)
I0422 14:48:19.592218  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:19.592222  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:48:19.592226  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:19.592231  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:48:19.592236  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0903889 (* 1 = 0.0903889 loss)
I0422 14:48:19.592241  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00381211 (* 1 = 0.00381211 loss)
I0422 14:48:19.592245  3756 sgd_solver.cpp:106] Iteration 230, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:48:23.870239  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:48:23.870261  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:23.870265  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 26
('accuracy: ', 0.0)
I0422 14:48:23.885659  3756 solver.cpp:228] Iteration 231, loss = 1.83409
I0422 14:48:23.885677  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:23.885685  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.72932 (* 1 = 1.72932 loss)
I0422 14:48:23.885690  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:23.885694  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:48:23.885699  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:23.885702  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:48:23.885707  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0884631 (* 1 = 0.0884631 loss)
I0422 14:48:23.885712  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0162977 (* 1 = 0.0162977 loss)
I0422 14:48:23.885718  3756 sgd_solver.cpp:106] Iteration 231, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:48:28.171144  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:48:28.171165  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:28.171170  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:48:28.186738  3756 solver.cpp:228] Iteration 232, loss = 2.01605
I0422 14:48:28.186755  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:28.186777  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.92399 (* 1 = 1.92399 loss)
I0422 14:48:28.186784  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:28.186789  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:48:28.186794  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:28.186797  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:48:28.186802  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0877068 (* 1 = 0.0877068 loss)
I0422 14:48:28.186807  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00436129 (* 1 = 0.00436129 loss)
I0422 14:48:28.186812  3756 sgd_solver.cpp:106] Iteration 232, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:48:32.481320  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:48:32.481343  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:32.481346  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 14
('accuracy: ', 0.0)
I0422 14:48:32.496632  3756 solver.cpp:228] Iteration 233, loss = 2.93342
I0422 14:48:32.496651  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:32.496659  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.89209 (* 1 = 2.89209 loss)
I0422 14:48:32.496665  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:32.496668  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:48:32.496672  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:32.496676  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:48:32.496680  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0304434 (* 1 = 0.0304434 loss)
I0422 14:48:32.496685  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0108942 (* 1 = 0.0108942 loss)
I0422 14:48:32.496691  3756 sgd_solver.cpp:106] Iteration 233, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:48:36.775018  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:48:36.775044  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:36.775049  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 14:48:36.790542  3756 solver.cpp:228] Iteration 234, loss = 1.91111
I0422 14:48:36.790560  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:36.790568  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.82258 (* 1 = 1.82258 loss)
I0422 14:48:36.790573  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:36.790577  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:48:36.790580  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:36.790585  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:48:36.790588  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0854032 (* 1 = 0.0854032 loss)
I0422 14:48:36.790593  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0031314 (* 1 = 0.0031314 loss)
I0422 14:48:36.790599  3756 sgd_solver.cpp:106] Iteration 234, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:48:41.076778  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:48:41.076800  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:41.076805  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 14:48:41.092298  3756 solver.cpp:228] Iteration 235, loss = 1.88935
I0422 14:48:41.092325  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:41.092334  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.78933 (* 1 = 1.78933 loss)
I0422 14:48:41.092339  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:41.092342  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:48:41.092346  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:41.092350  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:48:41.092355  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0958248 (* 1 = 0.0958248 loss)
I0422 14:48:41.092360  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00419596 (* 1 = 0.00419596 loss)
I0422 14:48:41.092365  3756 sgd_solver.cpp:106] Iteration 235, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:48:45.370487  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:48:45.370509  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:45.370514  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 14:48:45.386035  3756 solver.cpp:228] Iteration 236, loss = 2.22456
I0422 14:48:45.386054  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:45.386061  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.13748 (* 1 = 2.13748 loss)
I0422 14:48:45.386066  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:45.386070  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:48:45.386075  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:45.386078  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:48:45.386083  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0829888 (* 1 = 0.0829888 loss)
I0422 14:48:45.386088  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00409131 (* 1 = 0.00409131 loss)
I0422 14:48:45.386095  3756 sgd_solver.cpp:106] Iteration 236, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:48:49.662492  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:48:49.662514  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:49.662520  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 14:48:49.678591  3756 solver.cpp:228] Iteration 237, loss = 2.36406
I0422 14:48:49.678611  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:49.678619  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.21487 (* 1 = 2.21487 loss)
I0422 14:48:49.678624  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:49.678629  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:48:49.678633  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:49.678637  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:48:49.678642  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.136696 (* 1 = 0.136696 loss)
I0422 14:48:49.678647  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0124923 (* 1 = 0.0124923 loss)
I0422 14:48:49.678653  3756 sgd_solver.cpp:106] Iteration 237, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:48:53.965489  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:48:53.965512  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:53.965517  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 14:48:53.980983  3756 solver.cpp:228] Iteration 238, loss = 2.04953
I0422 14:48:53.981003  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:53.981011  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.95964 (* 1 = 1.95964 loss)
I0422 14:48:53.981016  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:53.981020  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:48:53.981024  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:53.981029  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:48:53.981032  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0855539 (* 1 = 0.0855539 loss)
I0422 14:48:53.981037  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00433298 (* 1 = 0.00433298 loss)
I0422 14:48:53.981043  3756 sgd_solver.cpp:106] Iteration 238, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:48:58.237696  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:48:58.237716  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:48:58.237721  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:48:58.253329  3756 solver.cpp:228] Iteration 239, loss = 1.91922
I0422 14:48:58.253357  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:48:58.253365  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.82013 (* 1 = 1.82013 loss)
I0422 14:48:58.253371  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:48:58.253376  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:48:58.253379  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:48:58.253383  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:48:58.253388  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0950863 (* 1 = 0.0950863 loss)
I0422 14:48:58.253393  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00400613 (* 1 = 0.00400613 loss)
I0422 14:48:58.253399  3756 sgd_solver.cpp:106] Iteration 239, lr = 0.0001
speed: 4.303s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:49:02.536566  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:49:02.536586  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:02.536590  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:49:02.552000  3756 solver.cpp:228] Iteration 240, loss = 2.07569
I0422 14:49:02.552017  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:02.552026  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.93261 (* 1 = 1.93261 loss)
I0422 14:49:02.552031  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:02.552036  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:49:02.552039  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:02.552043  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:49:02.552047  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.139617 (* 1 = 0.139617 loss)
I0422 14:49:02.552052  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00346419 (* 1 = 0.00346419 loss)
I0422 14:49:02.552058  3756 sgd_solver.cpp:106] Iteration 240, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:49:06.875284  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:49:06.875305  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:06.875310  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:49:06.891254  3756 solver.cpp:228] Iteration 241, loss = 1.6581
I0422 14:49:06.891274  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:06.891283  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.4917 (* 1 = 1.4917 loss)
I0422 14:49:06.891288  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:06.891291  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:49:06.891296  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:06.891300  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:49:06.891304  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.162256 (* 1 = 0.162256 loss)
I0422 14:49:06.891309  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00414855 (* 1 = 0.00414855 loss)
I0422 14:49:06.891315  3756 sgd_solver.cpp:106] Iteration 241, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:49:11.183209  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:49:11.183231  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:11.183236  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.25
TRAIN
num fg: 8
num bg: 16
('accuracy: ', 0.0)
I0422 14:49:11.199079  3756 solver.cpp:228] Iteration 242, loss = 2.63614
I0422 14:49:11.199100  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:11.199108  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.48292 (* 1 = 2.48292 loss)
I0422 14:49:11.199115  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:11.199118  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:49:11.199122  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:11.199126  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.25
I0422 14:49:11.199131  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.134978 (* 1 = 0.134978 loss)
I0422 14:49:11.199136  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.018243 (* 1 = 0.018243 loss)
I0422 14:49:11.199141  3756 sgd_solver.cpp:106] Iteration 242, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 14:49:15.464509  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:49:15.464529  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:15.464534  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.2
TRAIN
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 14:49:15.479533  3756 solver.cpp:228] Iteration 243, loss = 2.22602
I0422 14:49:15.479552  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:15.479558  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.061 (* 1 = 2.061 loss)
I0422 14:49:15.479563  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:15.479568  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:49:15.479571  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:15.479575  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.2
I0422 14:49:15.479580  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.152187 (* 1 = 0.152187 loss)
I0422 14:49:15.479585  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0128279 (* 1 = 0.0128279 loss)
I0422 14:49:15.479591  3756 sgd_solver.cpp:106] Iteration 243, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:49:19.756237  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:49:19.756258  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:19.756263  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 10
num bg: 26
('accuracy: ', 0.0)
I0422 14:49:19.771749  3756 solver.cpp:228] Iteration 244, loss = 2.47329
I0422 14:49:19.771780  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:19.771787  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.32392 (* 1 = 2.32392 loss)
I0422 14:49:19.771792  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:19.771796  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:49:19.771811  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:19.771814  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:49:19.771823  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.14587 (* 1 = 0.14587 loss)
I0422 14:49:19.771838  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00350397 (* 1 = 0.00350397 loss)
I0422 14:49:19.771844  3756 sgd_solver.cpp:106] Iteration 244, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:49:24.049767  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:49:24.049787  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:24.049791  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 4
num bg: 22
('accuracy: ', 0.0)
I0422 14:49:24.065151  3756 solver.cpp:228] Iteration 245, loss = 1.33037
I0422 14:49:24.065171  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:24.065178  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.20496 (* 1 = 1.20496 loss)
I0422 14:49:24.065183  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:24.065187  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:49:24.065192  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:24.065196  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:49:24.065201  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.116899 (* 1 = 0.116899 loss)
I0422 14:49:24.065210  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00850621 (* 1 = 0.00850621 loss)
I0422 14:49:24.065215  3756 sgd_solver.cpp:106] Iteration 245, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:49:28.356568  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:49:28.356590  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:28.356595  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 14:49:28.372200  3756 solver.cpp:228] Iteration 246, loss = 2.07755
I0422 14:49:28.372220  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:28.372227  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.95791 (* 1 = 1.95791 loss)
I0422 14:49:28.372232  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:28.372236  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:49:28.372241  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:28.372244  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:49:28.372249  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.115714 (* 1 = 0.115714 loss)
I0422 14:49:28.372254  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00391962 (* 1 = 0.00391962 loss)
I0422 14:49:28.372261  3756 sgd_solver.cpp:106] Iteration 246, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 14:49:32.647886  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:49:32.647908  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:32.647912  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:49:32.663370  3756 solver.cpp:228] Iteration 247, loss = 2.14696
I0422 14:49:32.663388  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:32.663394  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.01108 (* 1 = 2.01108 loss)
I0422 14:49:32.663399  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:32.663403  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:49:32.663408  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:32.663410  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:49:32.663414  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.125442 (* 1 = 0.125442 loss)
I0422 14:49:32.663419  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0104306 (* 1 = 0.0104306 loss)
I0422 14:49:32.663424  3756 sgd_solver.cpp:106] Iteration 247, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:49:36.934203  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:49:36.934224  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:36.934229  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 5
num bg: 21
('accuracy: ', 0.0)
I0422 14:49:36.952278  3756 solver.cpp:228] Iteration 248, loss = 1.43553
I0422 14:49:36.952314  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:36.952328  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.39489 (* 1 = 1.39489 loss)
I0422 14:49:36.952338  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:36.952345  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:49:36.952353  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:36.952360  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:49:36.952369  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0348437 (* 1 = 0.0348437 loss)
I0422 14:49:36.952381  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00579145 (* 1 = 0.00579145 loss)
I0422 14:49:36.952391  3756 sgd_solver.cpp:106] Iteration 248, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:49:41.242336  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:49:41.242357  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:41.242362  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 14:49:41.257993  3756 solver.cpp:228] Iteration 249, loss = 2.16921
I0422 14:49:41.258011  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:41.258019  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.07623 (* 1 = 2.07623 loss)
I0422 14:49:41.258024  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:41.258028  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:49:41.258033  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:41.258036  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:49:41.258041  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0900452 (* 1 = 0.0900452 loss)
I0422 14:49:41.258046  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00293543 (* 1 = 0.00293543 loss)
I0422 14:49:41.258052  3756 sgd_solver.cpp:106] Iteration 249, lr = 0.0001
speed: 4.303s / iter
rpn: num_positive 2
rpn: num_negative 62
I0422 14:49:45.542810  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:49:45.542832  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:45.542837  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 20
('accuracy: ', 0.0)
I0422 14:49:45.560261  3756 solver.cpp:228] Iteration 250, loss = 2.89395
I0422 14:49:45.560283  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:45.560292  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.84654 (* 1 = 2.84654 loss)
I0422 14:49:45.560298  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:45.560302  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:49:45.560307  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:45.560312  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:49:45.560317  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0424728 (* 1 = 0.0424728 loss)
I0422 14:49:45.560322  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0049384 (* 1 = 0.0049384 loss)
I0422 14:49:45.560328  3756 sgd_solver.cpp:106] Iteration 250, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:49:49.835332  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:49:49.835355  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:49.835360  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 10
num bg: 30
('accuracy: ', 0.0)
I0422 14:49:49.851094  3756 solver.cpp:228] Iteration 251, loss = 18.0924
I0422 14:49:49.851114  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:49.851121  3756 solver.cpp:244]     Train net output #1: loss_cls = 18.0074 (* 1 = 18.0074 loss)
I0422 14:49:49.851127  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:49.851131  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:49:49.851135  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:49.851138  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:49:49.851143  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0813312 (* 1 = 0.0813312 loss)
I0422 14:49:49.851148  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00364233 (* 1 = 0.00364233 loss)
I0422 14:49:49.851155  3756 sgd_solver.cpp:106] Iteration 251, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:49:54.147457  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:49:54.147478  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:54.147483  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:49:54.163285  3756 solver.cpp:228] Iteration 252, loss = 2.25696
I0422 14:49:54.163305  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:54.163313  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.11945 (* 1 = 2.11945 loss)
I0422 14:49:54.163318  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:54.163322  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:49:54.163327  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:54.163331  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:49:54.163336  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.133828 (* 1 = 0.133828 loss)
I0422 14:49:54.163341  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00367935 (* 1 = 0.00367935 loss)
I0422 14:49:54.163347  3756 sgd_solver.cpp:106] Iteration 252, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 14:49:58.442457  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:49:58.442479  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:49:58.442484  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 24
('accuracy: ', 0.0)
I0422 14:49:58.458333  3756 solver.cpp:228] Iteration 253, loss = 2.20045
I0422 14:49:58.458351  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:49:58.458359  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.00463 (* 1 = 2.00463 loss)
I0422 14:49:58.458364  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:49:58.458369  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:49:58.458372  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:49:58.458376  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:49:58.458380  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.183439 (* 1 = 0.183439 loss)
I0422 14:49:58.458385  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0123814 (* 1 = 0.0123814 loss)
I0422 14:49:58.458390  3756 sgd_solver.cpp:106] Iteration 253, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:02.756305  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:50:02.756335  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:02.756345  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 8
num bg: 23
('accuracy: ', 0.0)
I0422 14:50:02.772609  3756 solver.cpp:228] Iteration 254, loss = 2.6365
I0422 14:50:02.772627  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:02.772635  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.25694 (* 1 = 2.25694 loss)
I0422 14:50:02.772640  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:02.772644  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:50:02.772649  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:02.772652  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 14:50:02.772657  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.375553 (* 1 = 0.375553 loss)
I0422 14:50:02.772662  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0040115 (* 1 = 0.0040115 loss)
I0422 14:50:02.772668  3756 sgd_solver.cpp:106] Iteration 254, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:07.029270  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:50:07.029294  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:07.029297  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 14:50:07.044637  3756 solver.cpp:228] Iteration 255, loss = 2.61473
I0422 14:50:07.044654  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:07.044662  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.19436 (* 1 = 2.19436 loss)
I0422 14:50:07.044667  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:07.044672  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:50:07.044677  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:07.044680  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 14:50:07.044685  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.415291 (* 1 = 0.415291 loss)
I0422 14:50:07.044690  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0050748 (* 1 = 0.0050748 loss)
I0422 14:50:07.044697  3756 sgd_solver.cpp:106] Iteration 255, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:11.327653  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:50:11.327675  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:11.327680  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 8
num bg: 24
('accuracy: ', 0.0)
I0422 14:50:11.343312  3756 solver.cpp:228] Iteration 256, loss = 12.8474
I0422 14:50:11.343331  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:11.343339  3756 solver.cpp:244]     Train net output #1: loss_cls = 12.4038 (* 1 = 12.4038 loss)
I0422 14:50:11.343345  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:11.343349  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:50:11.343353  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:11.343358  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:50:11.343361  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.437986 (* 1 = 0.437986 loss)
I0422 14:50:11.343366  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00568067 (* 1 = 0.00568067 loss)
I0422 14:50:11.343372  3756 sgd_solver.cpp:106] Iteration 256, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:15.645665  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:50:15.645687  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:15.645691  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 8
num bg: 24
('accuracy: ', 0.0)
I0422 14:50:15.661577  3756 solver.cpp:228] Iteration 257, loss = 2.71808
I0422 14:50:15.661597  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:15.661604  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.28066 (* 1 = 2.28066 loss)
I0422 14:50:15.661609  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:15.661613  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:50:15.661617  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:15.661620  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:50:15.661625  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.431253 (* 1 = 0.431253 loss)
I0422 14:50:15.661630  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00617131 (* 1 = 0.00617131 loss)
I0422 14:50:15.661636  3756 sgd_solver.cpp:106] Iteration 257, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:19.959641  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:50:19.959666  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:19.959674  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 8
num bg: 23
('accuracy: ', 0.0)
I0422 14:50:19.975515  3756 solver.cpp:228] Iteration 258, loss = 2.5843
I0422 14:50:19.975533  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:19.975540  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.14178 (* 1 = 2.14178 loss)
I0422 14:50:19.975546  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:19.975550  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:50:19.975554  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:19.975558  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:50:19.975564  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.436068 (* 1 = 0.436068 loss)
I0422 14:50:19.975569  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00645459 (* 1 = 0.00645459 loss)
I0422 14:50:19.975574  3756 sgd_solver.cpp:106] Iteration 258, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:24.241513  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:50:24.241535  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:24.241540  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 8
num bg: 22
('accuracy: ', 0.0)
I0422 14:50:24.257038  3756 solver.cpp:228] Iteration 259, loss = 3.10447
I0422 14:50:24.257055  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:24.257063  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.66758 (* 1 = 2.66758 loss)
I0422 14:50:24.257068  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:24.257072  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:50:24.257076  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:24.257079  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:50:24.257084  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.431077 (* 1 = 0.431077 loss)
I0422 14:50:24.257091  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00581367 (* 1 = 0.00581367 loss)
I0422 14:50:24.257095  3756 sgd_solver.cpp:106] Iteration 259, lr = 0.0001
speed: 4.303s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:28.539808  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:50:28.539831  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:28.539835  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 14:50:28.555232  3756 solver.cpp:228] Iteration 260, loss = 3.20769
I0422 14:50:28.555249  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:28.555258  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.75406 (* 1 = 2.75406 loss)
I0422 14:50:28.555263  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:28.555268  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:50:28.555271  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:28.555275  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 14:50:28.555285  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.447805 (* 1 = 0.447805 loss)
I0422 14:50:28.555294  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00582452 (* 1 = 0.00582452 loss)
I0422 14:50:28.555299  3756 sgd_solver.cpp:106] Iteration 260, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:32.848001  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:50:32.848022  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:32.848027  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 22
('accuracy: ', 0.0)
I0422 14:50:32.866336  3756 solver.cpp:228] Iteration 261, loss = 2.78348
I0422 14:50:32.866364  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:32.866375  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.35359 (* 1 = 2.35359 loss)
I0422 14:50:32.866382  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:32.866386  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:50:32.866392  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:32.866397  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:50:32.866403  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.421725 (* 1 = 0.421725 loss)
I0422 14:50:32.866410  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00816446 (* 1 = 0.00816446 loss)
I0422 14:50:32.866415  3756 sgd_solver.cpp:106] Iteration 261, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:37.150997  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:50:37.151020  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:37.151024  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 22
('accuracy: ', 0.0)
I0422 14:50:37.166652  3756 solver.cpp:228] Iteration 262, loss = 2.68579
I0422 14:50:37.166672  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:37.166680  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.27056 (* 1 = 2.27056 loss)
I0422 14:50:37.166685  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:37.166690  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:50:37.166694  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:37.166699  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:50:37.166704  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.407123 (* 1 = 0.407123 loss)
I0422 14:50:37.166709  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0080999 (* 1 = 0.0080999 loss)
I0422 14:50:37.166715  3756 sgd_solver.cpp:106] Iteration 262, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:50:41.434670  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:50:41.434692  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:41.434696  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 16
('accuracy: ', 0.0)
I0422 14:50:41.449940  3756 solver.cpp:228] Iteration 263, loss = 2.83179
I0422 14:50:41.449957  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:41.449965  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.44546 (* 1 = 2.44546 loss)
I0422 14:50:41.449971  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:41.449975  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:50:41.449980  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:41.449982  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:50:41.449986  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.377097 (* 1 = 0.377097 loss)
I0422 14:50:41.449992  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00922857 (* 1 = 0.00922857 loss)
I0422 14:50:41.449997  3756 sgd_solver.cpp:106] Iteration 263, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:45.705870  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:50:45.705891  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:45.705907  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 14:50:45.721287  3756 solver.cpp:228] Iteration 264, loss = 2.48684
I0422 14:50:45.721304  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:45.721312  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.08743 (* 1 = 2.08743 loss)
I0422 14:50:45.721318  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:45.721321  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:50:45.721326  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:45.721329  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:50:45.721334  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.393912 (* 1 = 0.393912 loss)
I0422 14:50:45.721339  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00550096 (* 1 = 0.00550096 loss)
I0422 14:50:45.721345  3756 sgd_solver.cpp:106] Iteration 264, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:50:50.026513  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:50:50.026535  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:50.026540  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
num fg: 7
num bg: 25
('accuracy: ', 0.0)
I0422 14:50:50.042377  3756 solver.cpp:228] Iteration 265, loss = 2.21822
I0422 14:50:50.042394  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:50.042402  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.85069 (* 1 = 1.85069 loss)
I0422 14:50:50.042407  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:50.042412  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:50:50.042415  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:50.042418  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 14:50:50.042423  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.364302 (* 1 = 0.364302 loss)
I0422 14:50:50.042428  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00322748 (* 1 = 0.00322748 loss)
I0422 14:50:50.042433  3756 sgd_solver.cpp:106] Iteration 265, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:50:54.306202  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:50:54.306226  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:54.306229  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 14:50:54.321658  3756 solver.cpp:228] Iteration 266, loss = 2.20603
I0422 14:50:54.321676  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:54.321683  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.83051 (* 1 = 1.83051 loss)
I0422 14:50:54.321688  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:54.321692  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:50:54.321696  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:54.321701  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:50:54.321704  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.371376 (* 1 = 0.371376 loss)
I0422 14:50:54.321709  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00414016 (* 1 = 0.00414016 loss)
I0422 14:50:54.321722  3756 sgd_solver.cpp:106] Iteration 266, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:50:58.585608  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:50:58.585630  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:50:58.585634  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 19
('accuracy: ', 0.0)
I0422 14:50:58.601020  3756 solver.cpp:228] Iteration 267, loss = 2.63061
I0422 14:50:58.601037  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:50:58.601045  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.28265 (* 1 = 2.28265 loss)
I0422 14:50:58.601050  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:50:58.601054  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:50:58.601058  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:50:58.601061  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:50:58.601068  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.344641 (* 1 = 0.344641 loss)
I0422 14:50:58.601073  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00331512 (* 1 = 0.00331512 loss)
I0422 14:50:58.601078  3756 sgd_solver.cpp:106] Iteration 267, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:02.850489  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:02.850512  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:02.850517  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 14:51:02.866170  3756 solver.cpp:228] Iteration 268, loss = 2.61654
I0422 14:51:02.866192  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:02.866200  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.28434 (* 1 = 2.28434 loss)
I0422 14:51:02.866206  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:02.866210  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:02.866214  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:02.866219  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:02.866222  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.328622 (* 1 = 0.328622 loss)
I0422 14:51:02.866227  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00357809 (* 1 = 0.00357809 loss)
I0422 14:51:02.866233  3756 sgd_solver.cpp:106] Iteration 268, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:07.136026  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:07.136049  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:07.136054  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 14:51:07.151486  3756 solver.cpp:228] Iteration 269, loss = 2.53062
I0422 14:51:07.151515  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:07.151522  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.18393 (* 1 = 2.18393 loss)
I0422 14:51:07.151528  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:07.151532  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:07.151536  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:07.151540  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:07.151546  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.342906 (* 1 = 0.342906 loss)
I0422 14:51:07.151551  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00378329 (* 1 = 0.00378329 loss)
I0422 14:51:07.151556  3756 sgd_solver.cpp:106] Iteration 269, lr = 0.0001
speed: 4.302s / iter
rpn: num_positive 4
rpn: num_negative 60
I0422 14:51:11.463167  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:51:11.463191  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:11.463194  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 14:51:11.479013  3756 solver.cpp:228] Iteration 270, loss = 2.70552
I0422 14:51:11.479030  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:11.479039  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.43303 (* 1 = 2.43303 loss)
I0422 14:51:11.479044  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:11.479048  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:51:11.479053  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:11.479056  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:11.479061  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.260312 (* 1 = 0.260312 loss)
I0422 14:51:11.479066  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0121832 (* 1 = 0.0121832 loss)
I0422 14:51:11.479073  3756 sgd_solver.cpp:106] Iteration 270, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:15.781422  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:15.781445  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:15.781450  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 28
('accuracy: ', 0.0)
I0422 14:51:15.797322  3756 solver.cpp:228] Iteration 271, loss = 2.67925
I0422 14:51:15.797339  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:15.797348  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.38031 (* 1 = 2.38031 loss)
I0422 14:51:15.797353  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:15.797358  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:15.797361  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:15.797364  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:15.797369  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.293799 (* 1 = 0.293799 loss)
I0422 14:51:15.797374  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00513733 (* 1 = 0.00513733 loss)
I0422 14:51:15.797379  3756 sgd_solver.cpp:106] Iteration 271, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:20.069542  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:20.069576  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:20.069581  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 14:51:20.085554  3756 solver.cpp:228] Iteration 272, loss = 2.26084
I0422 14:51:20.085572  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:20.085579  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.04813 (* 1 = 2.04813 loss)
I0422 14:51:20.085584  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:20.085588  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:20.085592  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:20.085595  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:20.085599  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.208596 (* 1 = 0.208596 loss)
I0422 14:51:20.085604  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00411403 (* 1 = 0.00411403 loss)
I0422 14:51:20.085609  3756 sgd_solver.cpp:106] Iteration 272, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:24.371047  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:24.371068  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:24.371073  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 31
('accuracy: ', 0.0)
I0422 14:51:24.387032  3756 solver.cpp:228] Iteration 273, loss = 2.11354
I0422 14:51:24.387050  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:24.387058  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.86947 (* 1 = 1.86947 loss)
I0422 14:51:24.387063  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:24.387068  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:24.387071  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:24.387075  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:24.387079  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.239041 (* 1 = 0.239041 loss)
I0422 14:51:24.387084  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00502757 (* 1 = 0.00502757 loss)
I0422 14:51:24.387090  3756 sgd_solver.cpp:106] Iteration 273, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:28.662466  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:28.662492  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:28.662497  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:51:28.677971  3756 solver.cpp:228] Iteration 274, loss = 2.0041
I0422 14:51:28.677989  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:28.677996  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.70714 (* 1 = 1.70714 loss)
I0422 14:51:28.678001  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:28.678005  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:28.678010  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:28.678014  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:28.678019  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.292312 (* 1 = 0.292312 loss)
I0422 14:51:28.678023  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00465497 (* 1 = 0.00465497 loss)
I0422 14:51:28.678030  3756 sgd_solver.cpp:106] Iteration 274, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:32.963634  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:32.963657  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:32.963662  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:51:32.979110  3756 solver.cpp:228] Iteration 275, loss = 2.238
I0422 14:51:32.979127  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:32.979135  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.95037 (* 1 = 1.95037 loss)
I0422 14:51:32.979140  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:32.979145  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:32.979148  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:32.979151  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:32.979156  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.284285 (* 1 = 0.284285 loss)
I0422 14:51:32.979161  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00334532 (* 1 = 0.00334532 loss)
I0422 14:51:32.979167  3756 sgd_solver.cpp:106] Iteration 275, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:37.252436  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:37.252456  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:37.252461  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 30
('accuracy: ', 0.0)
I0422 14:51:37.268182  3756 solver.cpp:228] Iteration 276, loss = 2.19508
I0422 14:51:37.268203  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:37.268210  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.97555 (* 1 = 1.97555 loss)
I0422 14:51:37.268216  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:37.268219  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:37.268224  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:37.268227  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:37.268232  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.213058 (* 1 = 0.213058 loss)
I0422 14:51:37.268237  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00647548 (* 1 = 0.00647548 loss)
I0422 14:51:37.268244  3756 sgd_solver.cpp:106] Iteration 276, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:51:41.547384  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:51:41.547405  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:41.547410  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 23
('accuracy: ', 0.0)
I0422 14:51:41.562935  3756 solver.cpp:228] Iteration 277, loss = 2.0235
I0422 14:51:41.562960  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:41.562968  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.85908 (* 1 = 1.85908 loss)
I0422 14:51:41.562974  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:41.562978  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:51:41.562983  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:41.562985  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:41.562990  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.160162 (* 1 = 0.160162 loss)
I0422 14:51:41.562996  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00424911 (* 1 = 0.00424911 loss)
I0422 14:51:41.563001  3756 sgd_solver.cpp:106] Iteration 277, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:45.847679  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:45.847702  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:45.847707  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 14:51:45.863297  3756 solver.cpp:228] Iteration 278, loss = 1.77642
I0422 14:51:45.863315  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:45.863322  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.50612 (* 1 = 1.50612 loss)
I0422 14:51:45.863328  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:45.863332  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:45.863337  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:45.863339  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:45.863343  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.265621 (* 1 = 0.265621 loss)
I0422 14:51:45.863349  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00467971 (* 1 = 0.00467971 loss)
I0422 14:51:45.863354  3756 sgd_solver.cpp:106] Iteration 278, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:50.158738  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:50.158787  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:50.158797  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 14:51:50.174401  3756 solver.cpp:228] Iteration 279, loss = 2.33302
I0422 14:51:50.174418  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:50.174427  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.12746 (* 1 = 2.12746 loss)
I0422 14:51:50.174432  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:50.174435  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:50.174444  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:50.174448  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:50.174453  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.197144 (* 1 = 0.197144 loss)
I0422 14:51:50.174458  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00841294 (* 1 = 0.00841294 loss)
I0422 14:51:50.174464  3756 sgd_solver.cpp:106] Iteration 279, lr = 0.0001
speed: 4.302s / iter
rpn: num_positive 2
rpn: num_negative 62
I0422 14:51:54.466295  3756 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 14:51:54.466316  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:54.466320  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 12
num bg: 20
('accuracy: ', 0.0)
I0422 14:51:54.482089  3756 solver.cpp:228] Iteration 280, loss = 3.23794
I0422 14:51:54.482106  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:54.482115  3756 solver.cpp:244]     Train net output #1: loss_cls = 3.0715 (* 1 = 3.0715 loss)
I0422 14:51:54.482120  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:54.482123  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 14:51:54.482128  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:54.482131  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:54.482136  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.16236 (* 1 = 0.16236 loss)
I0422 14:51:54.482141  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00407529 (* 1 = 0.00407529 loss)
I0422 14:51:54.482147  3756 sgd_solver.cpp:106] Iteration 280, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:51:58.744922  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:51:58.744945  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:51:58.744949  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 14:51:58.760488  3756 solver.cpp:228] Iteration 281, loss = 2.14406
I0422 14:51:58.760506  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:51:58.760514  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.86079 (* 1 = 1.86079 loss)
I0422 14:51:58.760519  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:51:58.760524  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:51:58.760527  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:51:58.760531  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:51:58.760535  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.279978 (* 1 = 0.279978 loss)
I0422 14:51:58.760540  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00328701 (* 1 = 0.00328701 loss)
I0422 14:51:58.760545  3756 sgd_solver.cpp:106] Iteration 281, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:52:03.034399  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:52:03.034420  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:03.034425  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 14:52:03.049962  3756 solver.cpp:228] Iteration 282, loss = 1.86259
I0422 14:52:03.049980  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:03.049988  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.5885 (* 1 = 1.5885 loss)
I0422 14:52:03.049994  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:03.049998  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:52:03.050001  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:03.050005  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:03.050009  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.270619 (* 1 = 0.270619 loss)
I0422 14:52:03.050015  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00346606 (* 1 = 0.00346606 loss)
I0422 14:52:03.050020  3756 sgd_solver.cpp:106] Iteration 282, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:52:07.333658  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:52:07.333680  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:07.333684  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 26
('accuracy: ', 0.0)
I0422 14:52:07.349161  3756 solver.cpp:228] Iteration 283, loss = 2.30376
I0422 14:52:07.349179  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:07.349187  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.04452 (* 1 = 2.04452 loss)
I0422 14:52:07.349192  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:07.349196  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:52:07.349200  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:07.349205  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:07.349210  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.255004 (* 1 = 0.255004 loss)
I0422 14:52:07.349215  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0042412 (* 1 = 0.0042412 loss)
I0422 14:52:07.349220  3756 sgd_solver.cpp:106] Iteration 283, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:52:11.634838  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:52:11.634860  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:11.634865  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:52:11.650352  3756 solver.cpp:228] Iteration 284, loss = 2.08906
I0422 14:52:11.650369  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:11.650377  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.84599 (* 1 = 1.84599 loss)
I0422 14:52:11.650382  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:11.650387  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:52:11.650390  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:11.650394  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:11.650398  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.239962 (* 1 = 0.239962 loss)
I0422 14:52:11.650404  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00310033 (* 1 = 0.00310033 loss)
I0422 14:52:11.650409  3756 sgd_solver.cpp:106] Iteration 284, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:52:15.922446  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:52:15.922467  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:15.922473  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:52:15.937973  3756 solver.cpp:228] Iteration 285, loss = 1.50843
I0422 14:52:15.937991  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:15.938002  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.24236 (* 1 = 1.24236 loss)
I0422 14:52:15.938009  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:15.938014  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:52:15.938019  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:15.938022  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:15.938030  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.262789 (* 1 = 0.262789 loss)
I0422 14:52:15.938036  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00328056 (* 1 = 0.00328056 loss)
I0422 14:52:15.938041  3756 sgd_solver.cpp:106] Iteration 285, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:52:20.218797  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:52:20.218819  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:20.218824  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 11
num bg: 27
('accuracy: ', 0.0)
I0422 14:52:20.234352  3756 solver.cpp:228] Iteration 286, loss = 2.80084
I0422 14:52:20.234371  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:20.234380  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.55563 (* 1 = 2.55563 loss)
I0422 14:52:20.234385  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:20.234388  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:52:20.234392  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:20.234396  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:20.234407  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.242026 (* 1 = 0.242026 loss)
I0422 14:52:20.234413  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0031868 (* 1 = 0.0031868 loss)
I0422 14:52:20.234421  3756 sgd_solver.cpp:106] Iteration 286, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:52:24.517655  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:52:24.517678  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:24.517683  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 16
('accuracy: ', 0.0)
I0422 14:52:24.533296  3756 solver.cpp:228] Iteration 287, loss = 3.00279
I0422 14:52:24.533316  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:24.533324  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.79247 (* 1 = 2.79247 loss)
I0422 14:52:24.533329  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:24.533334  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:52:24.533339  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:24.533341  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:24.533346  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.202851 (* 1 = 0.202851 loss)
I0422 14:52:24.533351  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00746935 (* 1 = 0.00746935 loss)
I0422 14:52:24.533357  3756 sgd_solver.cpp:106] Iteration 287, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:52:28.806099  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:52:28.806120  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:28.806125  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 14:52:28.822114  3756 solver.cpp:228] Iteration 288, loss = 1.75002
I0422 14:52:28.822136  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:28.822144  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.49321 (* 1 = 1.49321 loss)
I0422 14:52:28.822149  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:28.822154  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:52:28.822158  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:28.822162  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:28.822167  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.253547 (* 1 = 0.253547 loss)
I0422 14:52:28.822177  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00326532 (* 1 = 0.00326532 loss)
I0422 14:52:28.822183  3756 sgd_solver.cpp:106] Iteration 288, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:52:33.097350  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:52:33.097371  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:33.097376  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 14:52:33.113215  3756 solver.cpp:228] Iteration 289, loss = 2.17893
I0422 14:52:33.113234  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:33.113241  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.93076 (* 1 = 1.93076 loss)
I0422 14:52:33.113246  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:33.113251  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:52:33.113255  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:33.113260  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:33.113263  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.245772 (* 1 = 0.245772 loss)
I0422 14:52:33.113268  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00239603 (* 1 = 0.00239603 loss)
I0422 14:52:33.113274  3756 sgd_solver.cpp:106] Iteration 289, lr = 0.0001
speed: 4.302s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:52:37.392923  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:52:37.392946  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:37.392962  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:52:37.408434  3756 solver.cpp:228] Iteration 290, loss = 2.14959
I0422 14:52:37.408453  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:37.408460  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.90202 (* 1 = 1.90202 loss)
I0422 14:52:37.408465  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:37.408469  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:52:37.408473  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:37.408478  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:37.408481  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.24466 (* 1 = 0.24466 loss)
I0422 14:52:37.408486  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00291049 (* 1 = 0.00291049 loss)
I0422 14:52:37.408499  3756 sgd_solver.cpp:106] Iteration 290, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 14:52:41.689211  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:52:41.689232  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:41.689237  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 9
num bg: 31
('accuracy: ', 0.0)
I0422 14:52:41.704977  3756 solver.cpp:228] Iteration 291, loss = 1.87047
I0422 14:52:41.704993  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:41.705001  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.59541 (* 1 = 1.59541 loss)
I0422 14:52:41.705008  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:41.705011  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:52:41.705015  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:41.705018  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:41.705024  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.265721 (* 1 = 0.265721 loss)
I0422 14:52:41.705029  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00933652 (* 1 = 0.00933652 loss)
I0422 14:52:41.705034  3756 sgd_solver.cpp:106] Iteration 291, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 14:52:45.981654  3756 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 14:52:45.981688  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:45.981693  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 31
('accuracy: ', 0.0)
I0422 14:52:45.997189  3756 solver.cpp:228] Iteration 292, loss = 1.9968
I0422 14:52:45.997205  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:45.997213  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.80087 (* 1 = 1.80087 loss)
I0422 14:52:45.997218  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:45.997222  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 14:52:45.997226  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:45.997229  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:45.997233  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.19433 (* 1 = 0.19433 loss)
I0422 14:52:45.997238  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0015992 (* 1 = 0.0015992 loss)
I0422 14:52:45.997244  3756 sgd_solver.cpp:106] Iteration 292, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:52:50.298717  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:52:50.298738  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:50.298743  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:52:50.314563  3756 solver.cpp:228] Iteration 293, loss = 1.78447
I0422 14:52:50.314581  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:50.314590  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.56886 (* 1 = 1.56886 loss)
I0422 14:52:50.314595  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:50.314599  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:52:50.314604  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:50.314607  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:50.314620  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.212862 (* 1 = 0.212862 loss)
I0422 14:52:50.314625  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00274136 (* 1 = 0.00274136 loss)
I0422 14:52:50.314633  3756 sgd_solver.cpp:106] Iteration 293, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:52:54.587292  3756 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 14:52:54.587313  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:54.587318  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 7
num bg: 16
('accuracy: ', 0.0)
I0422 14:52:54.603575  3756 solver.cpp:228] Iteration 294, loss = 2.33868
I0422 14:52:54.603597  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:54.603605  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.22889 (* 1 = 2.22889 loss)
I0422 14:52:54.603611  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:54.603615  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 14:52:54.603619  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:54.603623  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:54.603636  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0980298 (* 1 = 0.0980298 loss)
I0422 14:52:54.603641  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0117601 (* 1 = 0.0117601 loss)
I0422 14:52:54.603653  3756 sgd_solver.cpp:106] Iteration 294, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 14:52:58.883002  3756 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 14:52:58.883023  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:52:58.883026  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 6
num bg: 18
('accuracy: ', 0.0)
I0422 14:52:58.900243  3756 solver.cpp:228] Iteration 295, loss = 1.9952
I0422 14:52:58.900265  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:52:58.900274  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.80874 (* 1 = 1.80874 loss)
I0422 14:52:58.900280  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:52:58.900285  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 14:52:58.900290  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:52:58.900293  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:52:58.900298  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.175885 (* 1 = 0.175885 loss)
I0422 14:52:58.900303  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0105782 (* 1 = 0.0105782 loss)
I0422 14:52:58.900310  3756 sgd_solver.cpp:106] Iteration 295, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:53:03.205875  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:53:03.205896  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:53:03.205901  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 10
num bg: 26
('accuracy: ', 0.0)
I0422 14:53:03.221653  3756 solver.cpp:228] Iteration 296, loss = 2.42473
I0422 14:53:03.221674  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:53:03.221681  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.18022 (* 1 = 2.18022 loss)
I0422 14:53:03.221686  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:53:03.221690  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:53:03.221695  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:53:03.221698  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:53:03.221702  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.241961 (* 1 = 0.241961 loss)
I0422 14:53:03.221707  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00254911 (* 1 = 0.00254911 loss)
I0422 14:53:03.221712  3756 sgd_solver.cpp:106] Iteration 296, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:53:07.510668  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:53:07.510689  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:53:07.510694  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:53:07.526068  3756 solver.cpp:228] Iteration 297, loss = 2.07886
I0422 14:53:07.526088  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:53:07.526098  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.87501 (* 1 = 1.87501 loss)
I0422 14:53:07.526103  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:53:07.526106  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:53:07.526110  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:53:07.526114  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:53:07.526118  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.201702 (* 1 = 0.201702 loss)
I0422 14:53:07.526124  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00214405 (* 1 = 0.00214405 loss)
I0422 14:53:07.526129  3756 sgd_solver.cpp:106] Iteration 297, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:53:11.795703  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:53:11.795727  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:53:11.795730  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:53:11.811105  3756 solver.cpp:228] Iteration 298, loss = 2.08612
I0422 14:53:11.811125  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:53:11.811132  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.88873 (* 1 = 1.88873 loss)
I0422 14:53:11.811137  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:53:11.811141  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:53:11.811146  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:53:11.811149  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:53:11.811154  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.194799 (* 1 = 0.194799 loss)
I0422 14:53:11.811159  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00258653 (* 1 = 0.00258653 loss)
I0422 14:53:11.811164  3756 sgd_solver.cpp:106] Iteration 298, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:53:16.093130  3756 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 14:53:16.093150  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:53:16.093155  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 14:53:16.108893  3756 solver.cpp:228] Iteration 299, loss = 2.37391
I0422 14:53:16.108919  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:53:16.108933  3756 solver.cpp:244]     Train net output #1: loss_cls = 2.11469 (* 1 = 2.11469 loss)
I0422 14:53:16.108942  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:53:16.108950  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 14:53:16.108958  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:53:16.108964  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:53:16.108973  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.235254 (* 1 = 0.235254 loss)
I0422 14:53:16.108996  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0239685 (* 1 = 0.0239685 loss)
I0422 14:53:16.109007  3756 sgd_solver.cpp:106] Iteration 299, lr = 0.0001
speed: 4.302s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 14:53:20.404615  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:53:20.404637  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:53:20.404641  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 14:53:20.420275  3756 solver.cpp:228] Iteration 300, loss = 2.02548
I0422 14:53:20.420305  3756 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:53:20.420312  3756 solver.cpp:244]     Train net output #1: loss_cls = 1.82729 (* 1 = 1.82729 loss)
I0422 14:53:20.420317  3756 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:53:20.420321  3756 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 14:53:20.420325  3756 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 14:53:20.420330  3756 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 14:53:20.420333  3756 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.195813 (* 1 = 0.195813 loss)
I0422 14:53:20.420338  3756 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00237369 (* 1 = 0.00237369 loss)
I0422 14:53:20.420344  3756 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:53:24.695381  3756 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 14:53:24.695405  3756 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 14:53:24.695410  3756 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
Traceback (most recent call last):
  File "./experiments/activitynet/train_net.py", line 97, in <module>
    max_iters=args.max_iters)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/tdcnn/train.py", line 125, in train_net
    model_paths = sw.train_model(max_iters)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/tdcnn/train.py", line 102, in train_model
    self.solver.step(1)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/rpn/proposal_target_layer.py", line 84, in forward
    rois_per_image, self._num_classes)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/rpn/proposal_target_layer.py", line 225, in _sample_rois
    _get_twin_regression_labels(twin_target_data, num_classes)
  File "/data/gpu/prannay/aman/R-C3D-1/experiments/activitynet/../../lib/rpn/proposal_target_layer.py", line 157, in _get_twin_regression_labels
    twin_targets[ind, start:end] = twin_target_data[ind, 1:]
ValueError: could not broadcast input array from shape (201) into shape (2)

real	21m46.568s
user	6m43.712s
sys	15m2.646s
Called with args:
Namespace(cfg_file='./experiments/activitynet/td_cnn_end2end.yml', gpu_id=0, max_iters=350000, pretrained_model='./pretrain/activitynet_iter_30000_3fps.caffemodel', randomize=False, set_cfgs=None, solver='./experiments/activitynet/solver.prototxt')
Using config:
{'DEDUP_BOXES': 0.125,
 'EPS': 1e-14,
 'FPS': 25,
 'GPU_ID': 0,
 'INPUT': 'video',
 'NUM_CLASSES': 201,
 'PIXEL_MEANS': array([[[ 90,  98, 102]]]),
 'PIXEL_MEANS_FLOW': array([128]),
 'RNG_SEED': 3,
 'TEST': {'CROP_SIZE': 112,
          'FRAME_SIZE': [128, 171],
          'HAS_RPN': True,
          'LENGTH': [768],
          'MAX_SIZE': 1000,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.9,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SVM': False,
          'TWIN_REG': True},
 'TRAIN': {'BATCH_SIZE': 128,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.1,
           'CINPUT': False,
           'CROP_SIZE': 112,
           'FG_FRACTION': 0.5,
           'FG_THRESH': 0.5,
           'FRAME_SIZE': [128, 171],
           'HAS_RPN': True,
           'LENGTH': [768],
           'OHEM_LOSS_ONLY_CLASSIFICATION': False,
           'OHEM_LOSS_ONLY_LOCALIZATION': False,
           'OHEM_NMS_THRESH': 0.7,
           'OHEM_USE_NMS': True,
           'PROPOSAL_METHOD': 'gt',
           'RANDOM': False,
           'RPN_BATCHSIZE': 64,
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.8,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'RPN_TWIN_INSIDE_WEIGHTS': [1.0, 1.0],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 1000,
           'TWIN_INSIDE_WEIGHTS': [1.0, 1.0],
           'TWIN_NORMALIZE_MEANS': [0.0, 0.0],
           'TWIN_NORMALIZE_STDS': [0.1, 0.2],
           'TWIN_NORMALIZE_TARGETS': False,
           'TWIN_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'TWIN_REG': True,
           'TWIN_THRESH': 0.5,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False,
           'VIDEO_BATCH': 1},
 'USE_GPU_NMS': True}
45074 roidb entries
Output will be saved to `./experiments/best_activitynet/snapshot/`
Computing bounding-box regression targets...
precimputed
twin target means:
twin target stdevs:
NOT normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0422 14:59:24.284477  7918 solver.cpp:48] Initializing solver from parameters: 
train_net: "./experiments/activitynet/train.prototxt"
base_lr: 0.0001
display: 1
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 350000
snapshot: 0
snapshot_prefix: "./experiments/activitynet/snapshot/activitynet"
average_loss: 100
iter_size: 1
I0422 14:59:24.284508  7918 solver.cpp:81] Creating training net from train_net file: ./experiments/activitynet/train.prototxt
I0422 14:59:24.285555  7918 net.cpp:58] Initializing net from parameters: 
name: "activitynet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 200"
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1a"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1a"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    kernel_size: 2
    kernel_size: 2
    stride: 1
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv2a"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2a"
  type: "ReLU"
  bottom: "conv2a"
  top: "conv2a"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2a"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv3a"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3a"
  type: "ReLU"
  bottom: "conv3a"
  top: "conv3a"
}
layer {
  name: "conv3b"
  type: "Convolution"
  bottom: "conv3a"
  top: "conv3b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3b"
  type: "ReLU"
  bottom: "conv3b"
  top: "conv3b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv4a"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4a"
  type: "ReLU"
  bottom: "conv4a"
  top: "conv4a"
}
layer {
  name: "conv4b"
  type: "Convolution"
  bottom: "conv4a"
  top: "conv4b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4b"
  type: "ReLU"
  bottom: "conv4b"
  top: "conv4b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    kernel_size: 2
    kernel_size: 2
    stride: 2
    stride: 2
    stride: 2
  }
}
layer {
  name: "conv5a"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5a"
  type: "ReLU"
  bottom: "conv5a"
  top: "conv5a"
}
layer {
  name: "conv5b"
  type: "Convolution"
  bottom: "conv5a"
  top: "conv5b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5b"
  type: "ReLU"
  bottom: "conv5b"
  top: "conv5b"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5b"
  top: "rpn/output"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_conv/3x3_2"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn/output_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    pad: 1
    pad: 1
    kernel_size: 3
    kernel_size: 3
    kernel_size: 3
    stride: 1
    stride: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3_2"
  type: "ReLU"
  bottom: "rpn/output_2"
  top: "rpn/output_2"
}
layer {
  name: "rpn/output_pool"
  type: "Pooling"
  bottom: "rpn/output_2"
  top: "rpn/output_pool"
  pooling_param {
    pool: MAX
    kernel_size: 1
    kernel_size: 2
    kernel_size: 2
  }
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output_pool"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 74
    kernel_size: 1
    kernel_size: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_twin_pred"
  type: "Convolution"
  bottom: "rpn/output_pool"
  top: "rpn_twin_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 74
    kernel_size: 1
    kernel_size: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_twin_targets"
  top: "rpn_twin_inside_weights"
  top: "rpn_twin_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 8 \n\'scales\': !!python/tuple [1,1.25, 1.5,1.75, 2,2.5, 3,3.5, 4,4.5, 5,5.5, 6,7, 8,9,10,11,12,14,16,18,20,22,24,28,32,36,40,44,52,60,68,76,84,92,100]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_twin"
  type: "SmoothL1Loss"
  bottom: "rpn_twin_pred"
  bottom: "rpn_twin_targets"
  bottom: "rpn_twin_inside_weights"
  bottom: "rpn_twin_outside_weights"
  top: "rpn_loss_twin"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_accuarcy"
  type: "Accuracy"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_accuarcy"
  top: "rpn_accuarcy_class"
  propagate_down: false
  propagate_down: false
  accuracy_param {
    ignore_label: -1
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 74
      dim: -1
      dim: 0
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_twin_pred"
  top: "rpn_rois"
  include {
    phase: TRAIN
  }
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 8 \n\'scales\': !!python/tuple [1,1.25, 1.5,1.75, 2,2.5, 3,3.5, 4,4.5, 5,5.5, 6,7, 8,9,10,11,12,14,16,18,20,22,24,28,32,36,40,44,52,60,68,76,84,92,100]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  top: "rois"
  top: "labels"
  top: "twin_targets"
  top: "twin_inside_weights"
  top: "twin_outside_weights"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 200"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5b"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 4
    pooled_w: 4
    spatial_scale: 0.0625
    pooled_l: 1
    temporal_scale: 0.125
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc6"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 200
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "twin_pred"
  type: "InnerProduct"
  bottom: "fc6"
  top: "twin_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 400
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SigmoidCrossEntropyLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_twin"
  type: "SmoothL1Loss"
  bottom: "twin_pred"
  bottom: "twin_targets"
  bottom: "twin_inside_weights"
  bottom: "twin_outside_weights"
  top: "loss_twin"
  loss_weight: 1
}
layer {
  name: "accuracy"
  type: "Python"
  bottom: "cls_score"
  bottom: "labels"
  top: "accuracy"
  python_param {
    module: "utils.accuracy_layer"
    layer: "AccuracyLayer"
    param_str: "{\"top_k\": 2}"
  }
}
I0422 14:59:24.285769  7918 layer_factory.hpp:77] Creating layer data
I0422 14:59:24.309615  7918 net.cpp:100] Creating Layer data
I0422 14:59:24.309638  7918 net.cpp:408] data -> data
I0422 14:59:24.309649  7918 net.cpp:408] data -> gt_boxes
setting up
has rpn
RoiDataLayer: name_to_top: {'gt_windows': 1, 'data': 0}
I0422 14:59:24.322412  7918 net.cpp:150] Setting up data
I0422 14:59:24.322432  7918 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 14:59:24.322438  7918 net.cpp:157] Top shape: 1 101 (101)
I0422 14:59:24.322443  7918 net.cpp:165] Memory required for data: 115605908
I0422 14:59:24.322448  7918 layer_factory.hpp:77] Creating layer data_data_0_split
I0422 14:59:24.322461  7918 net.cpp:100] Creating Layer data_data_0_split
I0422 14:59:24.322468  7918 net.cpp:434] data_data_0_split <- data
I0422 14:59:24.322474  7918 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0422 14:59:24.322484  7918 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0422 14:59:24.322515  7918 net.cpp:150] Setting up data_data_0_split
I0422 14:59:24.322521  7918 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 14:59:24.322525  7918 net.cpp:157] Top shape: 1 3 768 112 112 (28901376)
I0422 14:59:24.322528  7918 net.cpp:165] Memory required for data: 346816916
I0422 14:59:24.322531  7918 layer_factory.hpp:77] Creating layer gt_boxes_data_1_split
I0422 14:59:24.322537  7918 net.cpp:100] Creating Layer gt_boxes_data_1_split
I0422 14:59:24.322540  7918 net.cpp:434] gt_boxes_data_1_split <- gt_boxes
I0422 14:59:24.322546  7918 net.cpp:408] gt_boxes_data_1_split -> gt_boxes_data_1_split_0
I0422 14:59:24.322551  7918 net.cpp:408] gt_boxes_data_1_split -> gt_boxes_data_1_split_1
I0422 14:59:24.322576  7918 net.cpp:150] Setting up gt_boxes_data_1_split
I0422 14:59:24.322582  7918 net.cpp:157] Top shape: 1 101 (101)
I0422 14:59:24.322585  7918 net.cpp:157] Top shape: 1 101 (101)
I0422 14:59:24.322588  7918 net.cpp:165] Memory required for data: 346817724
I0422 14:59:24.322592  7918 layer_factory.hpp:77] Creating layer conv1a
I0422 14:59:24.322607  7918 net.cpp:100] Creating Layer conv1a
I0422 14:59:24.322612  7918 net.cpp:434] conv1a <- data_data_0_split_0
I0422 14:59:24.322618  7918 net.cpp:408] conv1a -> conv1a
I0422 14:59:24.502665  7918 net.cpp:150] Setting up conv1a
I0422 14:59:24.502696  7918 net.cpp:157] Top shape: 1 64 768 112 112 (616562688)
I0422 14:59:24.502701  7918 net.cpp:165] Memory required for data: 2813068476
I0422 14:59:24.502719  7918 layer_factory.hpp:77] Creating layer relu1a
I0422 14:59:24.502732  7918 net.cpp:100] Creating Layer relu1a
I0422 14:59:24.502737  7918 net.cpp:434] relu1a <- conv1a
I0422 14:59:24.502743  7918 net.cpp:395] relu1a -> conv1a (in-place)
I0422 14:59:24.503183  7918 net.cpp:150] Setting up relu1a
I0422 14:59:24.503196  7918 net.cpp:157] Top shape: 1 64 768 112 112 (616562688)
I0422 14:59:24.503201  7918 net.cpp:165] Memory required for data: 5279319228
I0422 14:59:24.503204  7918 layer_factory.hpp:77] Creating layer pool1
I0422 14:59:24.503213  7918 net.cpp:100] Creating Layer pool1
I0422 14:59:24.503217  7918 net.cpp:434] pool1 <- conv1a
I0422 14:59:24.503224  7918 net.cpp:408] pool1 -> pool1
I0422 14:59:24.503394  7918 net.cpp:150] Setting up pool1
I0422 14:59:24.503406  7918 net.cpp:157] Top shape: 1 64 768 56 56 (154140672)
I0422 14:59:24.503409  7918 net.cpp:165] Memory required for data: 5895881916
I0422 14:59:24.503413  7918 layer_factory.hpp:77] Creating layer conv2a
I0422 14:59:24.503423  7918 net.cpp:100] Creating Layer conv2a
I0422 14:59:24.503429  7918 net.cpp:434] conv2a <- pool1
I0422 14:59:24.503435  7918 net.cpp:408] conv2a -> conv2a
I0422 14:59:24.514014  7918 net.cpp:150] Setting up conv2a
I0422 14:59:24.514040  7918 net.cpp:157] Top shape: 1 128 768 56 56 (308281344)
I0422 14:59:24.514045  7918 net.cpp:165] Memory required for data: 7129007292
I0422 14:59:24.514055  7918 layer_factory.hpp:77] Creating layer relu2a
I0422 14:59:24.514062  7918 net.cpp:100] Creating Layer relu2a
I0422 14:59:24.514066  7918 net.cpp:434] relu2a <- conv2a
I0422 14:59:24.514071  7918 net.cpp:395] relu2a -> conv2a (in-place)
I0422 14:59:24.514353  7918 net.cpp:150] Setting up relu2a
I0422 14:59:24.514365  7918 net.cpp:157] Top shape: 1 128 768 56 56 (308281344)
I0422 14:59:24.514369  7918 net.cpp:165] Memory required for data: 8362132668
I0422 14:59:24.514372  7918 layer_factory.hpp:77] Creating layer pool2
I0422 14:59:24.514381  7918 net.cpp:100] Creating Layer pool2
I0422 14:59:24.514384  7918 net.cpp:434] pool2 <- conv2a
I0422 14:59:24.514390  7918 net.cpp:408] pool2 -> pool2
I0422 14:59:24.514544  7918 net.cpp:150] Setting up pool2
I0422 14:59:24.514554  7918 net.cpp:157] Top shape: 1 128 384 28 28 (38535168)
I0422 14:59:24.514557  7918 net.cpp:165] Memory required for data: 8516273340
I0422 14:59:24.514561  7918 layer_factory.hpp:77] Creating layer conv3a
I0422 14:59:24.514570  7918 net.cpp:100] Creating Layer conv3a
I0422 14:59:24.514575  7918 net.cpp:434] conv3a <- pool2
I0422 14:59:24.514580  7918 net.cpp:408] conv3a -> conv3a
I0422 14:59:24.539093  7918 net.cpp:150] Setting up conv3a
I0422 14:59:24.539106  7918 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 14:59:24.539110  7918 net.cpp:165] Memory required for data: 8824554684
I0422 14:59:24.539119  7918 layer_factory.hpp:77] Creating layer relu3a
I0422 14:59:24.539126  7918 net.cpp:100] Creating Layer relu3a
I0422 14:59:24.539129  7918 net.cpp:434] relu3a <- conv3a
I0422 14:59:24.539137  7918 net.cpp:395] relu3a -> conv3a (in-place)
I0422 14:59:24.539419  7918 net.cpp:150] Setting up relu3a
I0422 14:59:24.539433  7918 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 14:59:24.539436  7918 net.cpp:165] Memory required for data: 9132836028
I0422 14:59:24.539440  7918 layer_factory.hpp:77] Creating layer conv3b
I0422 14:59:24.539449  7918 net.cpp:100] Creating Layer conv3b
I0422 14:59:24.539453  7918 net.cpp:434] conv3b <- conv3a
I0422 14:59:24.539463  7918 net.cpp:408] conv3b -> conv3b
I0422 14:59:24.587148  7918 net.cpp:150] Setting up conv3b
I0422 14:59:24.587169  7918 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 14:59:24.587173  7918 net.cpp:165] Memory required for data: 9441117372
I0422 14:59:24.587182  7918 layer_factory.hpp:77] Creating layer relu3b
I0422 14:59:24.587191  7918 net.cpp:100] Creating Layer relu3b
I0422 14:59:24.587196  7918 net.cpp:434] relu3b <- conv3b
I0422 14:59:24.587203  7918 net.cpp:395] relu3b -> conv3b (in-place)
I0422 14:59:24.587489  7918 net.cpp:150] Setting up relu3b
I0422 14:59:24.587502  7918 net.cpp:157] Top shape: 1 256 384 28 28 (77070336)
I0422 14:59:24.587505  7918 net.cpp:165] Memory required for data: 9749398716
I0422 14:59:24.587508  7918 layer_factory.hpp:77] Creating layer pool3
I0422 14:59:24.587517  7918 net.cpp:100] Creating Layer pool3
I0422 14:59:24.587522  7918 net.cpp:434] pool3 <- conv3b
I0422 14:59:24.587527  7918 net.cpp:408] pool3 -> pool3
I0422 14:59:24.587703  7918 net.cpp:150] Setting up pool3
I0422 14:59:24.587713  7918 net.cpp:157] Top shape: 1 256 192 14 14 (9633792)
I0422 14:59:24.587716  7918 net.cpp:165] Memory required for data: 9787933884
I0422 14:59:24.587720  7918 layer_factory.hpp:77] Creating layer conv4a
I0422 14:59:24.587739  7918 net.cpp:100] Creating Layer conv4a
I0422 14:59:24.587745  7918 net.cpp:434] conv4a <- pool3
I0422 14:59:24.587750  7918 net.cpp:408] conv4a -> conv4a
I0422 14:59:24.681679  7918 net.cpp:150] Setting up conv4a
I0422 14:59:24.681700  7918 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 14:59:24.681704  7918 net.cpp:165] Memory required for data: 9865004220
I0422 14:59:24.681720  7918 layer_factory.hpp:77] Creating layer relu4a
I0422 14:59:24.681730  7918 net.cpp:100] Creating Layer relu4a
I0422 14:59:24.681735  7918 net.cpp:434] relu4a <- conv4a
I0422 14:59:24.681741  7918 net.cpp:395] relu4a -> conv4a (in-place)
I0422 14:59:24.682039  7918 net.cpp:150] Setting up relu4a
I0422 14:59:24.682050  7918 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 14:59:24.682054  7918 net.cpp:165] Memory required for data: 9942074556
I0422 14:59:24.682059  7918 layer_factory.hpp:77] Creating layer conv4b
I0422 14:59:24.682071  7918 net.cpp:100] Creating Layer conv4b
I0422 14:59:24.682085  7918 net.cpp:434] conv4b <- conv4a
I0422 14:59:24.682090  7918 net.cpp:408] conv4b -> conv4b
I0422 14:59:24.868533  7918 net.cpp:150] Setting up conv4b
I0422 14:59:24.868556  7918 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 14:59:24.868559  7918 net.cpp:165] Memory required for data: 10019144892
I0422 14:59:24.868569  7918 layer_factory.hpp:77] Creating layer relu4b
I0422 14:59:24.868578  7918 net.cpp:100] Creating Layer relu4b
I0422 14:59:24.868583  7918 net.cpp:434] relu4b <- conv4b
I0422 14:59:24.868592  7918 net.cpp:395] relu4b -> conv4b (in-place)
I0422 14:59:24.868743  7918 net.cpp:150] Setting up relu4b
I0422 14:59:24.868753  7918 net.cpp:157] Top shape: 1 512 192 14 14 (19267584)
I0422 14:59:24.868757  7918 net.cpp:165] Memory required for data: 10096215228
I0422 14:59:24.868774  7918 layer_factory.hpp:77] Creating layer pool4
I0422 14:59:24.868783  7918 net.cpp:100] Creating Layer pool4
I0422 14:59:24.868793  7918 net.cpp:434] pool4 <- conv4b
I0422 14:59:24.868798  7918 net.cpp:408] pool4 -> pool4
I0422 14:59:24.869118  7918 net.cpp:150] Setting up pool4
I0422 14:59:24.869130  7918 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:59:24.869134  7918 net.cpp:165] Memory required for data: 10105849020
I0422 14:59:24.869138  7918 layer_factory.hpp:77] Creating layer conv5a
I0422 14:59:24.869150  7918 net.cpp:100] Creating Layer conv5a
I0422 14:59:24.869153  7918 net.cpp:434] conv5a <- pool4
I0422 14:59:24.869161  7918 net.cpp:408] conv5a -> conv5a
I0422 14:59:25.054849  7918 net.cpp:150] Setting up conv5a
I0422 14:59:25.054875  7918 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:59:25.054879  7918 net.cpp:165] Memory required for data: 10115482812
I0422 14:59:25.054888  7918 layer_factory.hpp:77] Creating layer relu5a
I0422 14:59:25.054898  7918 net.cpp:100] Creating Layer relu5a
I0422 14:59:25.054903  7918 net.cpp:434] relu5a <- conv5a
I0422 14:59:25.054908  7918 net.cpp:395] relu5a -> conv5a (in-place)
I0422 14:59:25.055328  7918 net.cpp:150] Setting up relu5a
I0422 14:59:25.055343  7918 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:59:25.055347  7918 net.cpp:165] Memory required for data: 10125116604
I0422 14:59:25.055351  7918 layer_factory.hpp:77] Creating layer conv5b
I0422 14:59:25.055362  7918 net.cpp:100] Creating Layer conv5b
I0422 14:59:25.055366  7918 net.cpp:434] conv5b <- conv5a
I0422 14:59:25.055372  7918 net.cpp:408] conv5b -> conv5b
I0422 14:59:25.242494  7918 net.cpp:150] Setting up conv5b
I0422 14:59:25.242517  7918 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:59:25.242522  7918 net.cpp:165] Memory required for data: 10134750396
I0422 14:59:25.242530  7918 layer_factory.hpp:77] Creating layer relu5b
I0422 14:59:25.242539  7918 net.cpp:100] Creating Layer relu5b
I0422 14:59:25.242547  7918 net.cpp:434] relu5b <- conv5b
I0422 14:59:25.242553  7918 net.cpp:395] relu5b -> conv5b (in-place)
I0422 14:59:25.242700  7918 net.cpp:150] Setting up relu5b
I0422 14:59:25.242710  7918 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:59:25.242714  7918 net.cpp:165] Memory required for data: 10144384188
I0422 14:59:25.242717  7918 layer_factory.hpp:77] Creating layer conv5b_relu5b_0_split
I0422 14:59:25.242724  7918 net.cpp:100] Creating Layer conv5b_relu5b_0_split
I0422 14:59:25.242727  7918 net.cpp:434] conv5b_relu5b_0_split <- conv5b
I0422 14:59:25.242733  7918 net.cpp:408] conv5b_relu5b_0_split -> conv5b_relu5b_0_split_0
I0422 14:59:25.242739  7918 net.cpp:408] conv5b_relu5b_0_split -> conv5b_relu5b_0_split_1
I0422 14:59:25.242794  7918 net.cpp:150] Setting up conv5b_relu5b_0_split
I0422 14:59:25.242801  7918 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:59:25.242806  7918 net.cpp:157] Top shape: 1 512 96 7 7 (2408448)
I0422 14:59:25.242810  7918 net.cpp:165] Memory required for data: 10163651772
I0422 14:59:25.242812  7918 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0422 14:59:25.242823  7918 net.cpp:100] Creating Layer rpn_conv/3x3
I0422 14:59:25.242830  7918 net.cpp:434] rpn_conv/3x3 <- conv5b_relu5b_0_split_0
I0422 14:59:25.242837  7918 net.cpp:408] rpn_conv/3x3 -> rpn/output
I0422 14:59:25.430646  7918 net.cpp:150] Setting up rpn_conv/3x3
I0422 14:59:25.430670  7918 net.cpp:157] Top shape: 1 512 96 4 4 (786432)
I0422 14:59:25.430673  7918 net.cpp:165] Memory required for data: 10166797500
I0422 14:59:25.430687  7918 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0422 14:59:25.430696  7918 net.cpp:100] Creating Layer rpn_relu/3x3
I0422 14:59:25.430701  7918 net.cpp:434] rpn_relu/3x3 <- rpn/output
I0422 14:59:25.430709  7918 net.cpp:395] rpn_relu/3x3 -> rpn/output (in-place)
I0422 14:59:25.431022  7918 net.cpp:150] Setting up rpn_relu/3x3
I0422 14:59:25.431035  7918 net.cpp:157] Top shape: 1 512 96 4 4 (786432)
I0422 14:59:25.431038  7918 net.cpp:165] Memory required for data: 10169943228
I0422 14:59:25.431042  7918 layer_factory.hpp:77] Creating layer rpn_conv/3x3_2
I0422 14:59:25.431053  7918 net.cpp:100] Creating Layer rpn_conv/3x3_2
I0422 14:59:25.431062  7918 net.cpp:434] rpn_conv/3x3_2 <- rpn/output
I0422 14:59:25.431069  7918 net.cpp:408] rpn_conv/3x3_2 -> rpn/output_2
I0422 14:59:25.617197  7918 net.cpp:150] Setting up rpn_conv/3x3_2
I0422 14:59:25.617230  7918 net.cpp:157] Top shape: 1 512 96 2 2 (196608)
I0422 14:59:25.617234  7918 net.cpp:165] Memory required for data: 10170729660
I0422 14:59:25.617244  7918 layer_factory.hpp:77] Creating layer rpn_relu/3x3_2
I0422 14:59:25.617256  7918 net.cpp:100] Creating Layer rpn_relu/3x3_2
I0422 14:59:25.617261  7918 net.cpp:434] rpn_relu/3x3_2 <- rpn/output_2
I0422 14:59:25.617266  7918 net.cpp:395] rpn_relu/3x3_2 -> rpn/output_2 (in-place)
I0422 14:59:25.617568  7918 net.cpp:150] Setting up rpn_relu/3x3_2
I0422 14:59:25.617579  7918 net.cpp:157] Top shape: 1 512 96 2 2 (196608)
I0422 14:59:25.617583  7918 net.cpp:165] Memory required for data: 10171516092
I0422 14:59:25.617588  7918 layer_factory.hpp:77] Creating layer rpn/output_pool
I0422 14:59:25.617594  7918 net.cpp:100] Creating Layer rpn/output_pool
I0422 14:59:25.617597  7918 net.cpp:434] rpn/output_pool <- rpn/output_2
I0422 14:59:25.617604  7918 net.cpp:408] rpn/output_pool -> rpn/output_pool
I0422 14:59:25.617784  7918 net.cpp:150] Setting up rpn/output_pool
I0422 14:59:25.617794  7918 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 14:59:25.617797  7918 net.cpp:165] Memory required for data: 10171712700
I0422 14:59:25.617805  7918 layer_factory.hpp:77] Creating layer rpn/output_pool_rpn/output_pool_0_split
I0422 14:59:25.617810  7918 net.cpp:100] Creating Layer rpn/output_pool_rpn/output_pool_0_split
I0422 14:59:25.617815  7918 net.cpp:434] rpn/output_pool_rpn/output_pool_0_split <- rpn/output_pool
I0422 14:59:25.617822  7918 net.cpp:408] rpn/output_pool_rpn/output_pool_0_split -> rpn/output_pool_rpn/output_pool_0_split_0
I0422 14:59:25.617828  7918 net.cpp:408] rpn/output_pool_rpn/output_pool_0_split -> rpn/output_pool_rpn/output_pool_0_split_1
I0422 14:59:25.617861  7918 net.cpp:150] Setting up rpn/output_pool_rpn/output_pool_0_split
I0422 14:59:25.617867  7918 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 14:59:25.617871  7918 net.cpp:157] Top shape: 1 512 96 1 1 (49152)
I0422 14:59:25.617875  7918 net.cpp:165] Memory required for data: 10172105916
I0422 14:59:25.617878  7918 layer_factory.hpp:77] Creating layer rpn_cls_score
I0422 14:59:25.617892  7918 net.cpp:100] Creating Layer rpn_cls_score
I0422 14:59:25.617897  7918 net.cpp:434] rpn_cls_score <- rpn/output_pool_rpn/output_pool_0_split_0
I0422 14:59:25.617902  7918 net.cpp:408] rpn_cls_score -> rpn_cls_score
I0422 14:59:25.620580  7918 net.cpp:150] Setting up rpn_cls_score
I0422 14:59:25.620594  7918 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:59:25.620596  7918 net.cpp:165] Memory required for data: 10172134332
I0422 14:59:25.620604  7918 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0422 14:59:25.620610  7918 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0422 14:59:25.620615  7918 net.cpp:434] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0422 14:59:25.620620  7918 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0422 14:59:25.620626  7918 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0422 14:59:25.620666  7918 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0422 14:59:25.620673  7918 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:59:25.620677  7918 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:59:25.620681  7918 net.cpp:165] Memory required for data: 10172191164
I0422 14:59:25.620683  7918 layer_factory.hpp:77] Creating layer rpn_twin_pred
I0422 14:59:25.620699  7918 net.cpp:100] Creating Layer rpn_twin_pred
I0422 14:59:25.620704  7918 net.cpp:434] rpn_twin_pred <- rpn/output_pool_rpn/output_pool_0_split_1
I0422 14:59:25.620709  7918 net.cpp:408] rpn_twin_pred -> rpn_twin_pred
I0422 14:59:25.623776  7918 net.cpp:150] Setting up rpn_twin_pred
I0422 14:59:25.623790  7918 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:59:25.623793  7918 net.cpp:165] Memory required for data: 10172219580
I0422 14:59:25.623800  7918 layer_factory.hpp:77] Creating layer rpn_twin_pred_rpn_twin_pred_0_split
I0422 14:59:25.623807  7918 net.cpp:100] Creating Layer rpn_twin_pred_rpn_twin_pred_0_split
I0422 14:59:25.623811  7918 net.cpp:434] rpn_twin_pred_rpn_twin_pred_0_split <- rpn_twin_pred
I0422 14:59:25.623816  7918 net.cpp:408] rpn_twin_pred_rpn_twin_pred_0_split -> rpn_twin_pred_rpn_twin_pred_0_split_0
I0422 14:59:25.623822  7918 net.cpp:408] rpn_twin_pred_rpn_twin_pred_0_split -> rpn_twin_pred_rpn_twin_pred_0_split_1
I0422 14:59:25.623859  7918 net.cpp:150] Setting up rpn_twin_pred_rpn_twin_pred_0_split
I0422 14:59:25.623867  7918 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:59:25.623870  7918 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:59:25.623875  7918 net.cpp:165] Memory required for data: 10172276412
I0422 14:59:25.623878  7918 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0422 14:59:25.623888  7918 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0422 14:59:25.623893  7918 net.cpp:434] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0422 14:59:25.623899  7918 net.cpp:408] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0422 14:59:25.623926  7918 net.cpp:150] Setting up rpn_cls_score_reshape
I0422 14:59:25.623934  7918 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 14:59:25.623936  7918 net.cpp:165] Memory required for data: 10172304828
I0422 14:59:25.623939  7918 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 14:59:25.623946  7918 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 14:59:25.623950  7918 net.cpp:434] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0422 14:59:25.623956  7918 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0422 14:59:25.623965  7918 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0422 14:59:25.623972  7918 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_2
I0422 14:59:25.624011  7918 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0422 14:59:25.624019  7918 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 14:59:25.624023  7918 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 14:59:25.624027  7918 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 14:59:25.624032  7918 net.cpp:165] Memory required for data: 10172390076
I0422 14:59:25.624035  7918 layer_factory.hpp:77] Creating layer rpn-data
I0422 14:59:25.624442  7918 net.cpp:100] Creating Layer rpn-data
I0422 14:59:25.624455  7918 net.cpp:434] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0422 14:59:25.624461  7918 net.cpp:434] rpn-data <- gt_boxes_data_1_split_0
I0422 14:59:25.624465  7918 net.cpp:434] rpn-data <- data_data_0_split_1
I0422 14:59:25.624471  7918 net.cpp:408] rpn-data -> rpn_labels
I0422 14:59:25.624480  7918 net.cpp:408] rpn-data -> rpn_twin_targets
I0422 14:59:25.624485  7918 net.cpp:408] rpn-data -> rpn_twin_inside_weights
I0422 14:59:25.624491  7918 net.cpp:408] rpn-data -> rpn_twin_outside_weights
I0422 14:59:25.626921  7918 net.cpp:150] Setting up rpn-data
I0422 14:59:25.626935  7918 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 14:59:25.626940  7918 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:59:25.626945  7918 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:59:25.626950  7918 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:59:25.626953  7918 net.cpp:165] Memory required for data: 10172489532
I0422 14:59:25.626958  7918 layer_factory.hpp:77] Creating layer rpn_labels_rpn-data_0_split
I0422 14:59:25.626963  7918 net.cpp:100] Creating Layer rpn_labels_rpn-data_0_split
I0422 14:59:25.626968  7918 net.cpp:434] rpn_labels_rpn-data_0_split <- rpn_labels
I0422 14:59:25.626974  7918 net.cpp:408] rpn_labels_rpn-data_0_split -> rpn_labels_rpn-data_0_split_0
I0422 14:59:25.626982  7918 net.cpp:408] rpn_labels_rpn-data_0_split -> rpn_labels_rpn-data_0_split_1
I0422 14:59:25.627013  7918 net.cpp:150] Setting up rpn_labels_rpn-data_0_split
I0422 14:59:25.627020  7918 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 14:59:25.627024  7918 net.cpp:157] Top shape: 1 1 3552 1 1 (3552)
I0422 14:59:25.627027  7918 net.cpp:165] Memory required for data: 10172517948
I0422 14:59:25.627032  7918 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0422 14:59:25.627040  7918 net.cpp:100] Creating Layer rpn_loss_cls
I0422 14:59:25.627045  7918 net.cpp:434] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0422 14:59:25.627050  7918 net.cpp:434] rpn_loss_cls <- rpn_labels_rpn-data_0_split_0
I0422 14:59:25.627056  7918 net.cpp:408] rpn_loss_cls -> rpn_cls_loss
I0422 14:59:25.627068  7918 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0422 14:59:25.628551  7918 net.cpp:150] Setting up rpn_loss_cls
I0422 14:59:25.628564  7918 net.cpp:157] Top shape: (1)
I0422 14:59:25.628569  7918 net.cpp:160]     with loss weight 1
I0422 14:59:25.628582  7918 net.cpp:165] Memory required for data: 10172517952
I0422 14:59:25.628587  7918 layer_factory.hpp:77] Creating layer rpn_loss_twin
I0422 14:59:25.628597  7918 net.cpp:100] Creating Layer rpn_loss_twin
I0422 14:59:25.628602  7918 net.cpp:434] rpn_loss_twin <- rpn_twin_pred_rpn_twin_pred_0_split_0
I0422 14:59:25.628607  7918 net.cpp:434] rpn_loss_twin <- rpn_twin_targets
I0422 14:59:25.628612  7918 net.cpp:434] rpn_loss_twin <- rpn_twin_inside_weights
I0422 14:59:25.628615  7918 net.cpp:434] rpn_loss_twin <- rpn_twin_outside_weights
I0422 14:59:25.628621  7918 net.cpp:408] rpn_loss_twin -> rpn_loss_twin
I0422 14:59:25.628696  7918 net.cpp:150] Setting up rpn_loss_twin
I0422 14:59:25.628706  7918 net.cpp:157] Top shape: (1)
I0422 14:59:25.628711  7918 net.cpp:160]     with loss weight 1
I0422 14:59:25.628715  7918 net.cpp:165] Memory required for data: 10172517956
I0422 14:59:25.628720  7918 layer_factory.hpp:77] Creating layer rpn_accuarcy
I0422 14:59:25.628728  7918 net.cpp:100] Creating Layer rpn_accuarcy
I0422 14:59:25.628733  7918 net.cpp:434] rpn_accuarcy <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0422 14:59:25.628737  7918 net.cpp:434] rpn_accuarcy <- rpn_labels_rpn-data_0_split_1
I0422 14:59:25.628743  7918 net.cpp:408] rpn_accuarcy -> rpn_accuarcy
I0422 14:59:25.628749  7918 net.cpp:408] rpn_accuarcy -> rpn_accuarcy_class
I0422 14:59:25.628787  7918 net.cpp:150] Setting up rpn_accuarcy
I0422 14:59:25.628793  7918 net.cpp:157] Top shape: (1)
I0422 14:59:25.628798  7918 net.cpp:157] Top shape: 2 (2)
I0422 14:59:25.628801  7918 net.cpp:165] Memory required for data: 10172517968
I0422 14:59:25.628805  7918 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0422 14:59:25.628810  7918 net.cpp:100] Creating Layer rpn_cls_prob
I0422 14:59:25.628815  7918 net.cpp:434] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_2
I0422 14:59:25.628819  7918 net.cpp:408] rpn_cls_prob -> rpn_cls_prob
I0422 14:59:25.629009  7918 net.cpp:150] Setting up rpn_cls_prob
I0422 14:59:25.629019  7918 net.cpp:157] Top shape: 1 2 3552 1 1 (7104)
I0422 14:59:25.629022  7918 net.cpp:165] Memory required for data: 10172546384
I0422 14:59:25.629027  7918 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0422 14:59:25.629034  7918 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0422 14:59:25.629039  7918 net.cpp:434] rpn_cls_prob_reshape <- rpn_cls_prob
I0422 14:59:25.629047  7918 net.cpp:408] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0422 14:59:25.629073  7918 net.cpp:150] Setting up rpn_cls_prob_reshape
I0422 14:59:25.629081  7918 net.cpp:157] Top shape: 1 74 96 1 1 (7104)
I0422 14:59:25.629083  7918 net.cpp:165] Memory required for data: 10172574800
I0422 14:59:25.629086  7918 layer_factory.hpp:77] Creating layer proposal
I0422 14:59:25.629631  7918 net.cpp:100] Creating Layer proposal
I0422 14:59:25.629643  7918 net.cpp:434] proposal <- rpn_cls_prob_reshape
I0422 14:59:25.629649  7918 net.cpp:434] proposal <- rpn_twin_pred_rpn_twin_pred_0_split_1
I0422 14:59:25.629655  7918 net.cpp:408] proposal -> rpn_rois
I0422 14:59:25.632001  7918 net.cpp:150] Setting up proposal
I0422 14:59:25.632017  7918 net.cpp:157] Top shape: 1 3 (3)
I0422 14:59:25.632024  7918 net.cpp:165] Memory required for data: 10172574812
I0422 14:59:25.632028  7918 layer_factory.hpp:77] Creating layer roi-data
I0422 14:59:25.633877  7918 net.cpp:100] Creating Layer roi-data
I0422 14:59:25.633890  7918 net.cpp:434] roi-data <- rpn_rois
I0422 14:59:25.633898  7918 net.cpp:434] roi-data <- gt_boxes_data_1_split_1
I0422 14:59:25.633904  7918 net.cpp:408] roi-data -> rois
I0422 14:59:25.633913  7918 net.cpp:408] roi-data -> labels
I0422 14:59:25.633922  7918 net.cpp:408] roi-data -> twin_targets
I0422 14:59:25.633929  7918 net.cpp:408] roi-data -> twin_inside_weights
I0422 14:59:25.633936  7918 net.cpp:408] roi-data -> twin_outside_weights
('sampling method:', 'Random')
I0422 14:59:25.634351  7918 net.cpp:150] Setting up roi-data
I0422 14:59:25.634366  7918 net.cpp:157] Top shape: 1 3 (3)
I0422 14:59:25.634371  7918 net.cpp:157] Top shape: 1 200 (200)
I0422 14:59:25.634376  7918 net.cpp:157] Top shape: 1 400 (400)
I0422 14:59:25.634380  7918 net.cpp:157] Top shape: 1 400 (400)
I0422 14:59:25.634384  7918 net.cpp:157] Top shape: 1 400 (400)
I0422 14:59:25.634388  7918 net.cpp:165] Memory required for data: 10172580424
I0422 14:59:25.634393  7918 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0422 14:59:25.634400  7918 net.cpp:100] Creating Layer labels_roi-data_1_split
I0422 14:59:25.634404  7918 net.cpp:434] labels_roi-data_1_split <- labels
I0422 14:59:25.634411  7918 net.cpp:408] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0422 14:59:25.634419  7918 net.cpp:408] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0422 14:59:25.634455  7918 net.cpp:150] Setting up labels_roi-data_1_split
I0422 14:59:25.634464  7918 net.cpp:157] Top shape: 1 200 (200)
I0422 14:59:25.634469  7918 net.cpp:157] Top shape: 1 200 (200)
I0422 14:59:25.634472  7918 net.cpp:165] Memory required for data: 10172582024
I0422 14:59:25.634476  7918 layer_factory.hpp:77] Creating layer roi_pool5
I0422 14:59:25.634486  7918 net.cpp:100] Creating Layer roi_pool5
I0422 14:59:25.634493  7918 net.cpp:434] roi_pool5 <- conv5b_relu5b_0_split_1
I0422 14:59:25.634500  7918 net.cpp:434] roi_pool5 <- rois
I0422 14:59:25.634505  7918 net.cpp:408] roi_pool5 -> pool5
I0422 14:59:25.634513  7918 roi_pooling_layer.cpp:34] Temporal scale: 0.125
I0422 14:59:25.634523  7918 roi_pooling_layer.cpp:35] Spatial scale: 0.0625
I0422 14:59:25.634559  7918 net.cpp:150] Setting up roi_pool5
I0422 14:59:25.634567  7918 net.cpp:157] Top shape: 1 512 1 4 4 (8192)
I0422 14:59:25.634572  7918 net.cpp:165] Memory required for data: 10172614792
I0422 14:59:25.634575  7918 layer_factory.hpp:77] Creating layer fc6
I0422 14:59:25.634585  7918 net.cpp:100] Creating Layer fc6
I0422 14:59:25.634589  7918 net.cpp:434] fc6 <- pool5
I0422 14:59:25.634595  7918 net.cpp:408] fc6 -> fc6
I0422 14:59:26.510922  7918 net.cpp:150] Setting up fc6
I0422 14:59:26.510946  7918 net.cpp:157] Top shape: 1 4096 (4096)
I0422 14:59:26.510949  7918 net.cpp:165] Memory required for data: 10172631176
I0422 14:59:26.510960  7918 layer_factory.hpp:77] Creating layer relu6
I0422 14:59:26.510970  7918 net.cpp:100] Creating Layer relu6
I0422 14:59:26.510974  7918 net.cpp:434] relu6 <- fc6
I0422 14:59:26.510980  7918 net.cpp:395] relu6 -> fc6 (in-place)
I0422 14:59:26.511428  7918 net.cpp:150] Setting up relu6
I0422 14:59:26.511441  7918 net.cpp:157] Top shape: 1 4096 (4096)
I0422 14:59:26.511445  7918 net.cpp:165] Memory required for data: 10172647560
I0422 14:59:26.511448  7918 layer_factory.hpp:77] Creating layer drop6
I0422 14:59:26.511462  7918 net.cpp:100] Creating Layer drop6
I0422 14:59:26.511466  7918 net.cpp:434] drop6 <- fc6
I0422 14:59:26.511471  7918 net.cpp:395] drop6 -> fc6 (in-place)
I0422 14:59:26.511497  7918 net.cpp:150] Setting up drop6
I0422 14:59:26.511508  7918 net.cpp:157] Top shape: 1 4096 (4096)
I0422 14:59:26.511512  7918 net.cpp:165] Memory required for data: 10172663944
I0422 14:59:26.511514  7918 layer_factory.hpp:77] Creating layer fc6_drop6_0_split
I0422 14:59:26.511520  7918 net.cpp:100] Creating Layer fc6_drop6_0_split
I0422 14:59:26.511523  7918 net.cpp:434] fc6_drop6_0_split <- fc6
I0422 14:59:26.511528  7918 net.cpp:408] fc6_drop6_0_split -> fc6_drop6_0_split_0
I0422 14:59:26.511534  7918 net.cpp:408] fc6_drop6_0_split -> fc6_drop6_0_split_1
I0422 14:59:26.511565  7918 net.cpp:150] Setting up fc6_drop6_0_split
I0422 14:59:26.511571  7918 net.cpp:157] Top shape: 1 4096 (4096)
I0422 14:59:26.511576  7918 net.cpp:157] Top shape: 1 4096 (4096)
I0422 14:59:26.511579  7918 net.cpp:165] Memory required for data: 10172696712
I0422 14:59:26.511582  7918 layer_factory.hpp:77] Creating layer cls_score
I0422 14:59:26.511590  7918 net.cpp:100] Creating Layer cls_score
I0422 14:59:26.511593  7918 net.cpp:434] cls_score <- fc6_drop6_0_split_0
I0422 14:59:26.511600  7918 net.cpp:408] cls_score -> cls_score
I0422 14:59:26.532923  7918 net.cpp:150] Setting up cls_score
I0422 14:59:26.532935  7918 net.cpp:157] Top shape: 1 200 (200)
I0422 14:59:26.532939  7918 net.cpp:165] Memory required for data: 10172697512
I0422 14:59:26.532946  7918 layer_factory.hpp:77] Creating layer cls_score_cls_score_0_split
I0422 14:59:26.532953  7918 net.cpp:100] Creating Layer cls_score_cls_score_0_split
I0422 14:59:26.532956  7918 net.cpp:434] cls_score_cls_score_0_split <- cls_score
I0422 14:59:26.532961  7918 net.cpp:408] cls_score_cls_score_0_split -> cls_score_cls_score_0_split_0
I0422 14:59:26.532968  7918 net.cpp:408] cls_score_cls_score_0_split -> cls_score_cls_score_0_split_1
I0422 14:59:26.532999  7918 net.cpp:150] Setting up cls_score_cls_score_0_split
I0422 14:59:26.533006  7918 net.cpp:157] Top shape: 1 200 (200)
I0422 14:59:26.533010  7918 net.cpp:157] Top shape: 1 200 (200)
I0422 14:59:26.533013  7918 net.cpp:165] Memory required for data: 10172699112
I0422 14:59:26.533017  7918 layer_factory.hpp:77] Creating layer twin_pred
I0422 14:59:26.533023  7918 net.cpp:100] Creating Layer twin_pred
I0422 14:59:26.533027  7918 net.cpp:434] twin_pred <- fc6_drop6_0_split_1
I0422 14:59:26.533036  7918 net.cpp:408] twin_pred -> twin_pred
I0422 14:59:26.575811  7918 net.cpp:150] Setting up twin_pred
I0422 14:59:26.575839  7918 net.cpp:157] Top shape: 1 400 (400)
I0422 14:59:26.575844  7918 net.cpp:165] Memory required for data: 10172700712
I0422 14:59:26.575851  7918 layer_factory.hpp:77] Creating layer loss_cls
I0422 14:59:26.575863  7918 net.cpp:100] Creating Layer loss_cls
I0422 14:59:26.575868  7918 net.cpp:434] loss_cls <- cls_score_cls_score_0_split_0
I0422 14:59:26.575875  7918 net.cpp:434] loss_cls <- labels_roi-data_1_split_0
I0422 14:59:26.575879  7918 net.cpp:408] loss_cls -> loss_cls
I0422 14:59:26.575932  7918 net.cpp:150] Setting up loss_cls
I0422 14:59:26.575938  7918 net.cpp:157] Top shape: (1)
I0422 14:59:26.575942  7918 net.cpp:160]     with loss weight 1
I0422 14:59:26.575950  7918 net.cpp:165] Memory required for data: 10172700716
I0422 14:59:26.575953  7918 layer_factory.hpp:77] Creating layer loss_twin
I0422 14:59:26.575959  7918 net.cpp:100] Creating Layer loss_twin
I0422 14:59:26.575963  7918 net.cpp:434] loss_twin <- twin_pred
I0422 14:59:26.575968  7918 net.cpp:434] loss_twin <- twin_targets
I0422 14:59:26.575971  7918 net.cpp:434] loss_twin <- twin_inside_weights
I0422 14:59:26.575975  7918 net.cpp:434] loss_twin <- twin_outside_weights
I0422 14:59:26.575980  7918 net.cpp:408] loss_twin -> loss_twin
I0422 14:59:26.576055  7918 net.cpp:150] Setting up loss_twin
I0422 14:59:26.576063  7918 net.cpp:157] Top shape: (1)
I0422 14:59:26.576066  7918 net.cpp:160]     with loss weight 1
I0422 14:59:26.576071  7918 net.cpp:165] Memory required for data: 10172700720
I0422 14:59:26.576074  7918 layer_factory.hpp:77] Creating layer accuracy
I0422 14:59:26.576264  7918 net.cpp:100] Creating Layer accuracy
I0422 14:59:26.576275  7918 net.cpp:434] accuracy <- cls_score_cls_score_0_split_1
I0422 14:59:26.576280  7918 net.cpp:434] accuracy <- labels_roi-data_1_split_1
I0422 14:59:26.576285  7918 net.cpp:408] accuracy -> accuracy
I0422 14:59:26.576361  7918 net.cpp:150] Setting up accuracy
I0422 14:59:26.576372  7918 net.cpp:157] Top shape: 1 (1)
I0422 14:59:26.576375  7918 net.cpp:165] Memory required for data: 10172700724
I0422 14:59:26.576380  7918 net.cpp:228] accuracy does not need backward computation.
I0422 14:59:26.576383  7918 net.cpp:226] loss_twin needs backward computation.
I0422 14:59:26.576387  7918 net.cpp:226] loss_cls needs backward computation.
I0422 14:59:26.576390  7918 net.cpp:226] twin_pred needs backward computation.
I0422 14:59:26.576395  7918 net.cpp:226] cls_score_cls_score_0_split needs backward computation.
I0422 14:59:26.576397  7918 net.cpp:226] cls_score needs backward computation.
I0422 14:59:26.576401  7918 net.cpp:226] fc6_drop6_0_split needs backward computation.
I0422 14:59:26.576405  7918 net.cpp:226] drop6 needs backward computation.
I0422 14:59:26.576407  7918 net.cpp:226] relu6 needs backward computation.
I0422 14:59:26.576411  7918 net.cpp:226] fc6 needs backward computation.
I0422 14:59:26.576414  7918 net.cpp:226] roi_pool5 needs backward computation.
I0422 14:59:26.576418  7918 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0422 14:59:26.576422  7918 net.cpp:226] roi-data needs backward computation.
I0422 14:59:26.576426  7918 net.cpp:226] proposal needs backward computation.
I0422 14:59:26.576431  7918 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0422 14:59:26.576434  7918 net.cpp:226] rpn_cls_prob needs backward computation.
I0422 14:59:26.576437  7918 net.cpp:228] rpn_accuarcy does not need backward computation.
I0422 14:59:26.576442  7918 net.cpp:226] rpn_loss_twin needs backward computation.
I0422 14:59:26.576445  7918 net.cpp:226] rpn_loss_cls needs backward computation.
I0422 14:59:26.576450  7918 net.cpp:228] rpn_labels_rpn-data_0_split does not need backward computation.
I0422 14:59:26.576454  7918 net.cpp:226] rpn-data needs backward computation.
I0422 14:59:26.576459  7918 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0422 14:59:26.576463  7918 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0422 14:59:26.576467  7918 net.cpp:226] rpn_twin_pred_rpn_twin_pred_0_split needs backward computation.
I0422 14:59:26.576472  7918 net.cpp:226] rpn_twin_pred needs backward computation.
I0422 14:59:26.576474  7918 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0422 14:59:26.576478  7918 net.cpp:226] rpn_cls_score needs backward computation.
I0422 14:59:26.576481  7918 net.cpp:226] rpn/output_pool_rpn/output_pool_0_split needs backward computation.
I0422 14:59:26.576485  7918 net.cpp:226] rpn/output_pool needs backward computation.
I0422 14:59:26.576489  7918 net.cpp:226] rpn_relu/3x3_2 needs backward computation.
I0422 14:59:26.576493  7918 net.cpp:226] rpn_conv/3x3_2 needs backward computation.
I0422 14:59:26.576496  7918 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0422 14:59:26.576499  7918 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0422 14:59:26.576503  7918 net.cpp:226] conv5b_relu5b_0_split needs backward computation.
I0422 14:59:26.576508  7918 net.cpp:226] relu5b needs backward computation.
I0422 14:59:26.576510  7918 net.cpp:226] conv5b needs backward computation.
I0422 14:59:26.576514  7918 net.cpp:226] relu5a needs backward computation.
I0422 14:59:26.576517  7918 net.cpp:226] conv5a needs backward computation.
I0422 14:59:26.576521  7918 net.cpp:226] pool4 needs backward computation.
I0422 14:59:26.576524  7918 net.cpp:226] relu4b needs backward computation.
I0422 14:59:26.576529  7918 net.cpp:226] conv4b needs backward computation.
I0422 14:59:26.576531  7918 net.cpp:226] relu4a needs backward computation.
I0422 14:59:26.576534  7918 net.cpp:226] conv4a needs backward computation.
I0422 14:59:26.576539  7918 net.cpp:226] pool3 needs backward computation.
I0422 14:59:26.576541  7918 net.cpp:226] relu3b needs backward computation.
I0422 14:59:26.576545  7918 net.cpp:226] conv3b needs backward computation.
I0422 14:59:26.576547  7918 net.cpp:226] relu3a needs backward computation.
I0422 14:59:26.576551  7918 net.cpp:226] conv3a needs backward computation.
I0422 14:59:26.576555  7918 net.cpp:228] pool2 does not need backward computation.
I0422 14:59:26.576558  7918 net.cpp:228] relu2a does not need backward computation.
I0422 14:59:26.576561  7918 net.cpp:228] conv2a does not need backward computation.
I0422 14:59:26.576565  7918 net.cpp:228] pool1 does not need backward computation.
I0422 14:59:26.576570  7918 net.cpp:228] relu1a does not need backward computation.
I0422 14:59:26.576572  7918 net.cpp:228] conv1a does not need backward computation.
I0422 14:59:26.576576  7918 net.cpp:228] gt_boxes_data_1_split does not need backward computation.
I0422 14:59:26.576581  7918 net.cpp:228] data_data_0_split does not need backward computation.
I0422 14:59:26.576584  7918 net.cpp:228] data does not need backward computation.
I0422 14:59:26.576587  7918 net.cpp:270] This network produces output accuracy
I0422 14:59:26.576591  7918 net.cpp:270] This network produces output loss_cls
I0422 14:59:26.576594  7918 net.cpp:270] This network produces output loss_twin
I0422 14:59:26.576597  7918 net.cpp:270] This network produces output rpn_accuarcy
I0422 14:59:26.576601  7918 net.cpp:270] This network produces output rpn_accuarcy_class
I0422 14:59:26.576604  7918 net.cpp:270] This network produces output rpn_cls_loss
I0422 14:59:26.576607  7918 net.cpp:270] This network produces output rpn_loss_twin
I0422 14:59:26.576639  7918 net.cpp:283] Network initialization done.
I0422 14:59:26.576768  7918 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from ./pretrain/activitynet_iter_30000_3fps.caffemodel
I0422 14:59:27.422363  7918 net.cpp:761] Ignoring source layer pool5
I0422 14:59:27.442679  7918 net.cpp:761] Ignoring source layer fc7
I0422 14:59:27.442700  7918 net.cpp:761] Ignoring source layer relu7
I0422 14:59:27.442715  7918 net.cpp:761] Ignoring source layer drop7
I0422 14:59:27.442718  7918 net.cpp:761] Ignoring source layer fc8-200
I0422 14:59:27.442720  7918 net.cpp:761] Ignoring source layer loss
Solving...
rpn: num_positive 6
rpn: num_negative 58
I0422 14:59:29.509690  7918 accuracy_layer.cpp:96] Accuracy: 0.390625
I0422 14:59:29.509711  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.344828
I0422 14:59:29.509716  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
[]
get twin regression called
num fg: 10
num bg: 25
('accuracy: ', 0.0)
I0422 14:59:29.563081  7918 solver.cpp:228] Iteration 0, loss = 168.252
I0422 14:59:29.563103  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:59:29.563113  7918 solver.cpp:244]     Train net output #1: loss_cls = 167.511 (* 1 = 167.511 loss)
I0422 14:59:29.563119  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:59:29.563124  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.390625
I0422 14:59:29.563128  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.344828
I0422 14:59:29.563140  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 14:59:29.563146  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.711967 (* 1 = 0.711967 loss)
I0422 14:59:29.563151  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0290697 (* 1 = 0.0290697 loss)
I0422 14:59:29.563160  7918 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 14:59:33.787344  7918 accuracy_layer.cpp:96] Accuracy: 0.515625
I0422 14:59:33.787369  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.5
I0422 14:59:33.787379  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.75
TRAIN
[]
get twin regression called
num fg: 8
num bg: 12
('accuracy: ', 0.0)
I0422 14:59:33.802233  7918 solver.cpp:228] Iteration 1, loss = 139.961
I0422 14:59:33.802251  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:59:33.802268  7918 solver.cpp:244]     Train net output #1: loss_cls = 139.252 (* 1 = 139.252 loss)
I0422 14:59:33.802273  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:59:33.802278  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.515625
I0422 14:59:33.802281  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.5
I0422 14:59:33.802284  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.75
I0422 14:59:33.802289  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.694252 (* 1 = 0.694252 loss)
I0422 14:59:33.802294  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0142117 (* 1 = 0.0142117 loss)
I0422 14:59:33.802299  7918 sgd_solver.cpp:106] Iteration 1, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:59:38.031791  7918 accuracy_layer.cpp:96] Accuracy: 0.421875
I0422 14:59:38.031812  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.37931
I0422 14:59:38.031819  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
[]
get twin regression called
num fg: 9
num bg: 24
('accuracy: ', 0.0)
I0422 14:59:38.047634  7918 solver.cpp:228] Iteration 2, loss = 121.195
I0422 14:59:38.047654  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:59:38.047662  7918 solver.cpp:244]     Train net output #1: loss_cls = 120.468 (* 1 = 120.468 loss)
I0422 14:59:38.047668  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:59:38.047672  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.421875
I0422 14:59:38.047677  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.37931
I0422 14:59:38.047679  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 14:59:38.047684  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.706309 (* 1 = 0.706309 loss)
I0422 14:59:38.047689  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0207997 (* 1 = 0.0207997 loss)
I0422 14:59:38.047694  7918 sgd_solver.cpp:106] Iteration 2, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 14:59:42.277251  7918 accuracy_layer.cpp:96] Accuracy: 0.4375
I0422 14:59:42.277271  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.419355
I0422 14:59:42.277287  7918 accuracy_layer.cpp:101] Class 1 accuracy : 1
TRAIN
[]
get twin regression called
num fg: 9
num bg: 16
('accuracy: ', 0.0)
I0422 14:59:42.292563  7918 solver.cpp:228] Iteration 3, loss = 99.0933
I0422 14:59:42.292582  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:59:42.292590  7918 solver.cpp:244]     Train net output #1: loss_cls = 98.3854 (* 1 = 98.3854 loss)
I0422 14:59:42.292595  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:59:42.292599  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.4375
I0422 14:59:42.292604  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.419355
I0422 14:59:42.292610  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 1
I0422 14:59:42.292618  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.704422 (* 1 = 0.704422 loss)
I0422 14:59:42.292623  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0034403 (* 1 = 0.0034403 loss)
I0422 14:59:42.292628  7918 sgd_solver.cpp:106] Iteration 3, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:59:46.522863  7918 accuracy_layer.cpp:96] Accuracy: 0.5
I0422 14:59:46.522886  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.5
I0422 14:59:46.522891  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:59:46.541653  7918 solver.cpp:228] Iteration 4, loss = 57.0111
I0422 14:59:46.541672  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:59:46.541683  7918 solver.cpp:244]     Train net output #1: loss_cls = 56.2702 (* 1 = 56.2702 loss)
I0422 14:59:46.541689  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:59:46.541693  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.5
I0422 14:59:46.541697  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.5
I0422 14:59:46.541700  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 14:59:46.541705  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.701073 (* 1 = 0.701073 loss)
I0422 14:59:46.541710  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.03982 (* 1 = 0.03982 loss)
I0422 14:59:46.541716  7918 sgd_solver.cpp:106] Iteration 4, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 14:59:50.780488  7918 accuracy_layer.cpp:96] Accuracy: 0.5625
I0422 14:59:50.780510  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.568965
I0422 14:59:50.780514  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 14:59:50.796013  7918 solver.cpp:228] Iteration 5, loss = 17.5852
I0422 14:59:50.796032  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:59:50.796041  7918 solver.cpp:244]     Train net output #1: loss_cls = 16.697 (* 1 = 16.697 loss)
I0422 14:59:50.796046  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:59:50.796049  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.5625
I0422 14:59:50.796053  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.568965
I0422 14:59:50.796057  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 14:59:50.796062  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.819137 (* 1 = 0.819137 loss)
I0422 14:59:50.796067  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0690544 (* 1 = 0.0690544 loss)
I0422 14:59:50.796072  7918 sgd_solver.cpp:106] Iteration 5, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:59:55.038290  7918 accuracy_layer.cpp:96] Accuracy: 0.53125
I0422 14:59:55.038311  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.52381
I0422 14:59:55.038314  7918 accuracy_layer.cpp:101] Class 1 accuracy : 1
TRAIN
[]
get twin regression called
num fg: 6
num bg: 18
('accuracy: ', 0.0)
I0422 14:59:55.053462  7918 solver.cpp:228] Iteration 6, loss = 5.42373
I0422 14:59:55.053478  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:59:55.053485  7918 solver.cpp:244]     Train net output #1: loss_cls = 4.28723 (* 1 = 4.28723 loss)
I0422 14:59:55.053491  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:59:55.053495  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.53125
I0422 14:59:55.053498  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.52381
I0422 14:59:55.053503  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 1
I0422 14:59:55.053508  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 1.0995 (* 1 = 1.0995 loss)
I0422 14:59:55.053513  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0369938 (* 1 = 0.0369938 loss)
I0422 14:59:55.053519  7918 sgd_solver.cpp:106] Iteration 6, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 14:59:59.302737  7918 accuracy_layer.cpp:96] Accuracy: 0.640625
I0422 14:59:59.302776  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.634921
I0422 14:59:59.302786  7918 accuracy_layer.cpp:101] Class 1 accuracy : 1
TRAIN
[]
get twin regression called
num fg: 3
num bg: 16
('accuracy: ', 0.0)
I0422 14:59:59.317411  7918 solver.cpp:228] Iteration 7, loss = 8.48811
I0422 14:59:59.317430  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 14:59:59.317437  7918 solver.cpp:244]     Train net output #1: loss_cls = 7.49931 (* 1 = 7.49931 loss)
I0422 14:59:59.317442  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 14:59:59.317446  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.640625
I0422 14:59:59.317450  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.634921
I0422 14:59:59.317453  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 1
I0422 14:59:59.317457  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.927861 (* 1 = 0.927861 loss)
I0422 14:59:59.317462  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0609337 (* 1 = 0.0609337 loss)
I0422 14:59:59.317468  7918 sgd_solver.cpp:106] Iteration 7, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:03.572465  7918 accuracy_layer.cpp:96] Accuracy: 0.71875
I0422 15:00:03.572487  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.758621
I0422 15:00:03.572491  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
[]
get twin regression called
num fg: 6
num bg: 19
('accuracy: ', 0.0)
I0422 15:00:03.587883  7918 solver.cpp:228] Iteration 8, loss = 17.7025
I0422 15:00:03.587901  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:03.587909  7918 solver.cpp:244]     Train net output #1: loss_cls = 15.3441 (* 1 = 15.3441 loss)
I0422 15:00:03.587914  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:03.587918  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.71875
I0422 15:00:03.587923  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.758621
I0422 15:00:03.587926  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 15:00:03.587930  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 1.66707 (* 1 = 1.66707 loss)
I0422 15:00:03.587935  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.69131 (* 1 = 0.69131 loss)
I0422 15:00:03.587941  7918 sgd_solver.cpp:106] Iteration 8, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:07.840790  7918 accuracy_layer.cpp:96] Accuracy: 0.734375
I0422 15:00:07.840812  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.793103
I0422 15:00:07.840816  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 9
num bg: 23
('accuracy: ', 0.0)
I0422 15:00:07.857784  7918 solver.cpp:228] Iteration 9, loss = 44.2518
I0422 15:00:07.857805  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:07.857815  7918 solver.cpp:244]     Train net output #1: loss_cls = 42.6116 (* 1 = 42.6116 loss)
I0422 15:00:07.857820  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:07.857825  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.734375
I0422 15:00:07.857830  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.793103
I0422 15:00:07.857834  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:00:07.857839  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 1.24957 (* 1 = 1.24957 loss)
I0422 15:00:07.857844  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.390599 (* 1 = 0.390599 loss)
I0422 15:00:07.857851  7918 sgd_solver.cpp:106] Iteration 9, lr = 0.0001
speed: 4.039s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:12.103627  7918 accuracy_layer.cpp:96] Accuracy: 0.78125
I0422 15:00:12.103649  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.827586
I0422 15:00:12.103654  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
[]
get twin regression called
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 15:00:12.118988  7918 solver.cpp:228] Iteration 10, loss = 12.9966
I0422 15:00:12.119004  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:12.119012  7918 solver.cpp:244]     Train net output #1: loss_cls = 12.3809 (* 1 = 12.3809 loss)
I0422 15:00:12.119019  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:12.119024  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.78125
I0422 15:00:12.119029  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.827586
I0422 15:00:12.119032  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 15:00:12.119040  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.528092 (* 1 = 0.528092 loss)
I0422 15:00:12.119045  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0876347 (* 1 = 0.0876347 loss)
I0422 15:00:12.119051  7918 sgd_solver.cpp:106] Iteration 10, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:00:16.555651  7918 accuracy_layer.cpp:96] Accuracy: 0.78125
I0422 15:00:16.555672  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.806452
I0422 15:00:16.555677  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 15
num bg: 32
('accuracy: ', 0.0)
I0422 15:00:16.579069  7918 solver.cpp:228] Iteration 11, loss = 18.6921
I0422 15:00:16.579094  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:16.579107  7918 solver.cpp:244]     Train net output #1: loss_cls = 17.9909 (* 1 = 17.9909 loss)
I0422 15:00:16.579114  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:16.579119  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.78125
I0422 15:00:16.579124  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.806452
I0422 15:00:16.579130  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:00:16.579144  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.599454 (* 1 = 0.599454 loss)
I0422 15:00:16.579151  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.101718 (* 1 = 0.101718 loss)
I0422 15:00:16.579161  7918 sgd_solver.cpp:106] Iteration 11, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:21.064827  7918 accuracy_layer.cpp:96] Accuracy: 0.75
I0422 15:00:21.064851  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.741379
I0422 15:00:21.064854  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
[]
get twin regression called
num fg: 11
num bg: 30
('accuracy: ', 0.0)
I0422 15:00:21.081127  7918 solver.cpp:228] Iteration 12, loss = 4.84592
I0422 15:00:21.081145  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:21.081152  7918 solver.cpp:244]     Train net output #1: loss_cls = 4.33354 (* 1 = 4.33354 loss)
I0422 15:00:21.081157  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:21.081161  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.75
I0422 15:00:21.081166  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.741379
I0422 15:00:21.081169  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 15:00:21.081174  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.463682 (* 1 = 0.463682 loss)
I0422 15:00:21.081179  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0486925 (* 1 = 0.0486925 loss)
I0422 15:00:21.081184  7918 sgd_solver.cpp:106] Iteration 12, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:25.509140  7918 accuracy_layer.cpp:96] Accuracy: 0.890625
I0422 15:00:25.509169  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.896552
I0422 15:00:25.509174  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
[]
get twin regression called
num fg: 10
num bg: 26
('accuracy: ', 0.0)
I0422 15:00:25.528666  7918 solver.cpp:228] Iteration 13, loss = 3.96585
I0422 15:00:25.528687  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:25.528697  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.4362 (* 1 = 3.4362 loss)
I0422 15:00:25.528702  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:25.528707  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.890625
I0422 15:00:25.528712  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.896552
I0422 15:00:25.528717  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 15:00:25.528723  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.49529 (* 1 = 0.49529 loss)
I0422 15:00:25.528729  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0343633 (* 1 = 0.0343633 loss)
I0422 15:00:25.528735  7918 sgd_solver.cpp:106] Iteration 13, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:29.936030  7918 accuracy_layer.cpp:96] Accuracy: 0.828125
I0422 15:00:29.936053  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.844828
I0422 15:00:29.936058  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
[]
get twin regression called
num fg: 7
num bg: 26
('accuracy: ', 0.0)
I0422 15:00:29.951833  7918 solver.cpp:228] Iteration 14, loss = 4.46053
I0422 15:00:29.951849  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:29.951858  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.85802 (* 1 = 3.85802 loss)
I0422 15:00:29.951862  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:29.951866  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.828125
I0422 15:00:29.951870  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.844828
I0422 15:00:29.951874  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 15:00:29.951879  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.588043 (* 1 = 0.588043 loss)
I0422 15:00:29.951884  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.01446 (* 1 = 0.01446 loss)
I0422 15:00:29.951889  7918 sgd_solver.cpp:106] Iteration 14, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:34.302857  7918 accuracy_layer.cpp:96] Accuracy: 0.8125
I0422 15:00:34.302881  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.827586
I0422 15:00:34.302886  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
[]
get twin regression called
num fg: 10
num bg: 24
('accuracy: ', 0.0)
I0422 15:00:34.318795  7918 solver.cpp:228] Iteration 15, loss = 4.64567
I0422 15:00:34.318814  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:34.318826  7918 solver.cpp:244]     Train net output #1: loss_cls = 4.06464 (* 1 = 4.06464 loss)
I0422 15:00:34.318842  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:34.318853  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.8125
I0422 15:00:34.318861  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.827586
I0422 15:00:34.318868  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 15:00:34.318877  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.568225 (* 1 = 0.568225 loss)
I0422 15:00:34.318887  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0128006 (* 1 = 0.0128006 loss)
I0422 15:00:34.318897  7918 sgd_solver.cpp:106] Iteration 15, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:38.704061  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:00:38.704083  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.931035
I0422 15:00:38.704090  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.666667
TRAIN
[]
get twin regression called
num fg: 9
num bg: 23
('accuracy: ', 0.0)
I0422 15:00:38.720325  7918 solver.cpp:228] Iteration 16, loss = 4.11074
I0422 15:00:38.720343  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:38.720355  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.51878 (* 1 = 3.51878 loss)
I0422 15:00:38.720368  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:38.720376  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:00:38.720386  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.931035
I0422 15:00:38.720393  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.666667
I0422 15:00:38.720402  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.581528 (* 1 = 0.581528 loss)
I0422 15:00:38.720413  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0104262 (* 1 = 0.0104262 loss)
I0422 15:00:38.720423  7918 sgd_solver.cpp:106] Iteration 16, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:43.096343  7918 accuracy_layer.cpp:96] Accuracy: 0.84375
I0422 15:00:43.096366  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.827586
I0422 15:00:43.096374  7918 accuracy_layer.cpp:101] Class 1 accuracy : 1
TRAIN
[]
get twin regression called
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 15:00:43.112502  7918 solver.cpp:228] Iteration 17, loss = 2.95014
I0422 15:00:43.112520  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:43.112532  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.41118 (* 1 = 2.41118 loss)
I0422 15:00:43.112545  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:43.112552  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.84375
I0422 15:00:43.112562  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.827586
I0422 15:00:43.112571  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 1
I0422 15:00:43.112581  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.501873 (* 1 = 0.501873 loss)
I0422 15:00:43.112591  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0370881 (* 1 = 0.0370881 loss)
I0422 15:00:43.112601  7918 sgd_solver.cpp:106] Iteration 17, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:47.483942  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:00:47.483970  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.913793
I0422 15:00:47.483979  7918 accuracy_layer.cpp:101] Class 1 accuracy : 1
TRAIN
[]
get twin regression called
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 15:00:47.501605  7918 solver.cpp:228] Iteration 18, loss = 3.19296
I0422 15:00:47.501623  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:47.501631  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.67407 (* 1 = 2.67407 loss)
I0422 15:00:47.501636  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:47.501641  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:00:47.501646  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.913793
I0422 15:00:47.501651  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 1
I0422 15:00:47.501655  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.461068 (* 1 = 0.461068 loss)
I0422 15:00:47.501660  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0578264 (* 1 = 0.0578264 loss)
I0422 15:00:47.501665  7918 sgd_solver.cpp:106] Iteration 18, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:51.848714  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:00:51.848736  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.913793
I0422 15:00:51.848740  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.833333
TRAIN
[]
get twin regression called
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 15:00:51.864529  7918 solver.cpp:228] Iteration 19, loss = 3.42545
I0422 15:00:51.864547  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:51.864554  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.98707 (* 1 = 2.98707 loss)
I0422 15:00:51.864559  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:51.864564  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:00:51.864567  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.913793
I0422 15:00:51.864572  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.833333
I0422 15:00:51.864576  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.357255 (* 1 = 0.357255 loss)
I0422 15:00:51.864581  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0811341 (* 1 = 0.0811341 loss)
I0422 15:00:51.864586  7918 sgd_solver.cpp:106] Iteration 19, lr = 0.0001
speed: 4.220s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:00:56.212704  7918 accuracy_layer.cpp:96] Accuracy: 0.75
I0422 15:00:56.212728  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.775862
I0422 15:00:56.212731  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
[]
get twin regression called
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 15:00:56.228655  7918 solver.cpp:228] Iteration 20, loss = 3.85052
I0422 15:00:56.228672  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:00:56.228679  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.31972 (* 1 = 3.31972 loss)
I0422 15:00:56.228684  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:00:56.228688  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.75
I0422 15:00:56.228693  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.775862
I0422 15:00:56.228695  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 15:00:56.228700  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.44559 (* 1 = 0.44559 loss)
I0422 15:00:56.228705  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0852138 (* 1 = 0.0852138 loss)
I0422 15:00:56.228711  7918 sgd_solver.cpp:106] Iteration 20, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:01:00.561821  7918 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 15:01:00.561842  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.887097
I0422 15:01:00.561846  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
[]
get twin regression called
num fg: 10
num bg: 25
('accuracy: ', 0.0)
I0422 15:01:00.577759  7918 solver.cpp:228] Iteration 21, loss = 4.05814
I0422 15:01:00.577776  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:00.577785  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.64167 (* 1 = 3.64167 loss)
I0422 15:01:00.577790  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:00.577793  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 15:01:00.577797  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.887097
I0422 15:01:00.577801  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 15:01:00.577806  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.398531 (* 1 = 0.398531 loss)
I0422 15:01:00.577811  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.01794 (* 1 = 0.01794 loss)
I0422 15:01:00.577816  7918 sgd_solver.cpp:106] Iteration 21, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:01:04.929806  7918 accuracy_layer.cpp:96] Accuracy: 0.8125
I0422 15:01:04.929838  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.825397
I0422 15:01:04.929843  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 19
('accuracy: ', 0.0)
I0422 15:01:04.945780  7918 solver.cpp:228] Iteration 22, loss = 2.94788
I0422 15:01:04.945796  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:04.945804  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.40268 (* 1 = 2.40268 loss)
I0422 15:01:04.945809  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:04.945814  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.8125
I0422 15:01:04.945818  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.825397
I0422 15:01:04.945822  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:01:04.945827  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.536762 (* 1 = 0.536762 loss)
I0422 15:01:04.945832  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00844069 (* 1 = 0.00844069 loss)
I0422 15:01:04.945838  7918 sgd_solver.cpp:106] Iteration 22, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:01:09.292835  7918 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 15:01:09.292857  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.913793
I0422 15:01:09.292863  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 15:01:09.310055  7918 solver.cpp:228] Iteration 23, loss = 3.62078
I0422 15:01:09.310076  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:09.310084  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.08227 (* 1 = 3.08227 loss)
I0422 15:01:09.310091  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:09.310094  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 15:01:09.310098  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.913793
I0422 15:01:09.310103  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 15:01:09.310108  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.516783 (* 1 = 0.516783 loss)
I0422 15:01:09.310113  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0217307 (* 1 = 0.0217307 loss)
I0422 15:01:09.310120  7918 sgd_solver.cpp:106] Iteration 23, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 15:01:13.691488  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:01:13.691509  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.983333
I0422 15:01:13.691514  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 21
('accuracy: ', 0.0)
I0422 15:01:13.707531  7918 solver.cpp:228] Iteration 24, loss = 3.26703
I0422 15:01:13.707551  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:13.707557  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.69274 (* 1 = 2.69274 loss)
I0422 15:01:13.707562  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:13.707566  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:01:13.707569  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.983333
I0422 15:01:13.707574  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:01:13.707578  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.551423 (* 1 = 0.551423 loss)
I0422 15:01:13.707583  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0228654 (* 1 = 0.0228654 loss)
I0422 15:01:13.707588  7918 sgd_solver.cpp:106] Iteration 24, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:01:18.050649  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:01:18.050670  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.920635
I0422 15:01:18.050675  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 5
num bg: 24
('accuracy: ', 0.0)
I0422 15:01:18.066468  7918 solver.cpp:228] Iteration 25, loss = 1.82279
I0422 15:01:18.066488  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:18.066495  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.3383 (* 1 = 1.3383 loss)
I0422 15:01:18.066500  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:18.066504  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:01:18.066507  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.920635
I0422 15:01:18.066511  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:01:18.066515  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.473994 (* 1 = 0.473994 loss)
I0422 15:01:18.066524  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0104936 (* 1 = 0.0104936 loss)
I0422 15:01:18.066530  7918 sgd_solver.cpp:106] Iteration 25, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:01:22.409669  7918 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 15:01:22.409692  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.967213
I0422 15:01:22.409705  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
[]
get twin regression called
num fg: 7
num bg: 30
('accuracy: ', 0.0)
I0422 15:01:22.427722  7918 solver.cpp:228] Iteration 26, loss = 2.68604
I0422 15:01:22.427740  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:22.427748  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.23851 (* 1 = 2.23851 loss)
I0422 15:01:22.427754  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:22.427758  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 15:01:22.427762  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.967213
I0422 15:01:22.427767  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 15:01:22.427770  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.430699 (* 1 = 0.430699 loss)
I0422 15:01:22.427775  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0168376 (* 1 = 0.0168376 loss)
I0422 15:01:22.427781  7918 sgd_solver.cpp:106] Iteration 26, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:01:26.752831  7918 accuracy_layer.cpp:96] Accuracy: 0.828125
I0422 15:01:26.752852  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.862069
I0422 15:01:26.752856  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
[]
get twin regression called
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 15:01:26.768820  7918 solver.cpp:228] Iteration 27, loss = 3.7849
I0422 15:01:26.768846  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:26.768856  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.32519 (* 1 = 3.32519 loss)
I0422 15:01:26.768860  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:26.768863  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.828125
I0422 15:01:26.768867  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.862069
I0422 15:01:26.768872  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 15:01:26.768877  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.343366 (* 1 = 0.343366 loss)
I0422 15:01:26.768880  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.116343 (* 1 = 0.116343 loss)
I0422 15:01:26.768887  7918 sgd_solver.cpp:106] Iteration 27, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:01:31.110890  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:01:31.110911  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.965517
I0422 15:01:31.110916  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
[]
get twin regression called
num fg: 7
num bg: 27
('accuracy: ', 0.0)
I0422 15:01:31.127028  7918 solver.cpp:228] Iteration 28, loss = 3.161
I0422 15:01:31.127048  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:31.127055  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.78532 (* 1 = 2.78532 loss)
I0422 15:01:31.127061  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:31.127065  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:01:31.127069  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.965517
I0422 15:01:31.127074  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 15:01:31.127077  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.293815 (* 1 = 0.293815 loss)
I0422 15:01:31.127082  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0818679 (* 1 = 0.0818679 loss)
I0422 15:01:31.127087  7918 sgd_solver.cpp:106] Iteration 28, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:01:35.452556  7918 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 15:01:35.452579  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.948276
I0422 15:01:35.452582  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 5
num bg: 28
('accuracy: ', 0.0)
I0422 15:01:35.468420  7918 solver.cpp:228] Iteration 29, loss = 1.45384
I0422 15:01:35.468441  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:35.468448  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.02016 (* 1 = 1.02016 loss)
I0422 15:01:35.468454  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:35.468458  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 15:01:35.468462  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.948276
I0422 15:01:35.468466  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:01:35.468470  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.366006 (* 1 = 0.366006 loss)
I0422 15:01:35.468482  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0676655 (* 1 = 0.0676655 loss)
I0422 15:01:35.468487  7918 sgd_solver.cpp:106] Iteration 29, lr = 0.0001
speed: 4.267s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:01:39.809516  7918 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 15:01:39.809537  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.948276
I0422 15:01:39.809542  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 7
num bg: 25
('accuracy: ', 0.0)
I0422 15:01:39.826951  7918 solver.cpp:228] Iteration 30, loss = 3.0997
I0422 15:01:39.826969  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:39.826977  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.67734 (* 1 = 2.67734 loss)
I0422 15:01:39.826982  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:39.826987  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 15:01:39.826990  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.948276
I0422 15:01:39.826994  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:01:39.826998  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.362663 (* 1 = 0.362663 loss)
I0422 15:01:39.827003  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0596946 (* 1 = 0.0596946 loss)
I0422 15:01:39.827010  7918 sgd_solver.cpp:106] Iteration 30, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:01:44.146085  7918 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 15:01:44.146106  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.918033
I0422 15:01:44.146111  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 19
('accuracy: ', 0.0)
I0422 15:01:44.163192  7918 solver.cpp:228] Iteration 31, loss = 3.14435
I0422 15:01:44.163213  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:44.163223  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.66115 (* 1 = 2.66115 loss)
I0422 15:01:44.163228  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:44.163233  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 15:01:44.163238  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.918033
I0422 15:01:44.163242  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:01:44.163254  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.461994 (* 1 = 0.461994 loss)
I0422 15:01:44.163260  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0212018 (* 1 = 0.0212018 loss)
I0422 15:01:44.163267  7918 sgd_solver.cpp:106] Iteration 31, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 15:01:48.493561  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:01:48.493582  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:01:48.493587  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
[]
get twin regression called
num fg: 8
num bg: 24
('accuracy: ', 0.0)
I0422 15:01:48.509562  7918 solver.cpp:228] Iteration 32, loss = 3.53392
I0422 15:01:48.509582  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:48.509589  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.03397 (* 1 = 3.03397 loss)
I0422 15:01:48.509595  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:48.509599  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:01:48.509603  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:01:48.509606  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 15:01:48.509611  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.475535 (* 1 = 0.475535 loss)
I0422 15:01:48.509616  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0244126 (* 1 = 0.0244126 loss)
I0422 15:01:48.509622  7918 sgd_solver.cpp:106] Iteration 32, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:01:52.850253  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:01:52.850276  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.965517
I0422 15:01:52.850281  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
[]
get twin regression called
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 15:01:52.865885  7918 solver.cpp:228] Iteration 33, loss = 3.51051
I0422 15:01:52.865905  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:52.865912  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.94103 (* 1 = 2.94103 loss)
I0422 15:01:52.865917  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:52.865921  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:01:52.865926  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.965517
I0422 15:01:52.865929  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 15:01:52.865933  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.549776 (* 1 = 0.549776 loss)
I0422 15:01:52.865938  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.019699 (* 1 = 0.019699 loss)
I0422 15:01:52.865944  7918 sgd_solver.cpp:106] Iteration 33, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:01:57.204882  7918 accuracy_layer.cpp:96] Accuracy: 0.890625
I0422 15:01:57.204905  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.948276
I0422 15:01:57.204910  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
[]
get twin regression called
num fg: 6
num bg: 30
('accuracy: ', 0.0)
I0422 15:01:57.222842  7918 solver.cpp:228] Iteration 34, loss = 2.93919
I0422 15:01:57.222863  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:01:57.222872  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.40439 (* 1 = 2.40439 loss)
I0422 15:01:57.222882  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:01:57.222887  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.890625
I0422 15:01:57.222892  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.948276
I0422 15:01:57.222898  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 15:01:57.222904  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.486326 (* 1 = 0.486326 loss)
I0422 15:01:57.222911  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0484753 (* 1 = 0.0484753 loss)
I0422 15:01:57.222916  7918 sgd_solver.cpp:106] Iteration 34, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:02:01.558166  7918 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 15:02:01.558187  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.918033
I0422 15:02:01.558192  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 19
('accuracy: ', 0.0)
I0422 15:02:01.575775  7918 solver.cpp:228] Iteration 35, loss = 3.5862
I0422 15:02:01.575798  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:01.575806  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.10482 (* 1 = 3.10482 loss)
I0422 15:02:01.575812  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:01.575817  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 15:02:01.575821  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.918033
I0422 15:02:01.575825  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:02:01.575830  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.460874 (* 1 = 0.460874 loss)
I0422 15:02:01.575836  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0205048 (* 1 = 0.0205048 loss)
I0422 15:02:01.575842  7918 sgd_solver.cpp:106] Iteration 35, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:05.923651  7918 accuracy_layer.cpp:96] Accuracy: 0.84375
I0422 15:02:05.923672  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.896552
I0422 15:02:05.923677  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
[]
get twin regression called
num fg: 7
num bg: 28
('accuracy: ', 0.0)
I0422 15:02:05.941543  7918 solver.cpp:228] Iteration 36, loss = 2.50636
I0422 15:02:05.941565  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:05.941573  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.96665 (* 1 = 1.96665 loss)
I0422 15:02:05.941579  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:05.941583  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.84375
I0422 15:02:05.941588  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.896552
I0422 15:02:05.941592  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 15:02:05.941597  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.519105 (* 1 = 0.519105 loss)
I0422 15:02:05.941602  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0206077 (* 1 = 0.0206077 loss)
I0422 15:02:05.941608  7918 sgd_solver.cpp:106] Iteration 36, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:10.242467  7918 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 15:02:10.242489  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.931035
I0422 15:02:10.242494  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.333333
TRAIN
[]
get twin regression called
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 15:02:10.257874  7918 solver.cpp:228] Iteration 37, loss = 3.33702
I0422 15:02:10.257894  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:10.257900  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.85279 (* 1 = 2.85279 loss)
I0422 15:02:10.257905  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:10.257910  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 15:02:10.257913  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.931035
I0422 15:02:10.257917  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.333333
I0422 15:02:10.257921  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.440931 (* 1 = 0.440931 loss)
I0422 15:02:10.257932  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0432931 (* 1 = 0.0432931 loss)
I0422 15:02:10.257938  7918 sgd_solver.cpp:106] Iteration 37, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:14.602811  7918 accuracy_layer.cpp:96] Accuracy: 0.828125
I0422 15:02:14.602833  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.896552
I0422 15:02:14.602838  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 15:02:14.618885  7918 solver.cpp:228] Iteration 38, loss = 2.48976
I0422 15:02:14.618904  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:14.618912  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.02625 (* 1 = 2.02625 loss)
I0422 15:02:14.618917  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:14.618921  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.828125
I0422 15:02:14.618926  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.896552
I0422 15:02:14.618929  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:02:14.618933  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.428682 (* 1 = 0.428682 loss)
I0422 15:02:14.618938  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0348286 (* 1 = 0.0348286 loss)
I0422 15:02:14.618944  7918 sgd_solver.cpp:106] Iteration 38, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:02:18.953438  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:02:18.953460  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.95082
I0422 15:02:18.953464  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 24
('accuracy: ', 0.0)
I0422 15:02:18.969301  7918 solver.cpp:228] Iteration 39, loss = 2.49814
I0422 15:02:18.969319  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:18.969327  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.02838 (* 1 = 2.02838 loss)
I0422 15:02:18.969332  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:18.969336  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:02:18.969341  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.95082
I0422 15:02:18.969343  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:02:18.969348  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.462736 (* 1 = 0.462736 loss)
I0422 15:02:18.969353  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00703017 (* 1 = 0.00703017 loss)
I0422 15:02:18.969358  7918 sgd_solver.cpp:106] Iteration 39, lr = 0.0001
speed: 4.288s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:23.327116  7918 accuracy_layer.cpp:96] Accuracy: 0.875
I0422 15:02:23.327139  7918 accuracy_layer.cpp:101] Class 0 accuracy : 0.965517
I0422 15:02:23.327143  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 27
('accuracy: ', 0.0)
I0422 15:02:23.343406  7918 solver.cpp:228] Iteration 40, loss = 1.77544
I0422 15:02:23.343427  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:23.343436  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.33526 (* 1 = 1.33526 loss)
I0422 15:02:23.343441  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:23.343444  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.875
I0422 15:02:23.343449  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 0.965517
I0422 15:02:23.343453  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:02:23.343457  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.426317 (* 1 = 0.426317 loss)
I0422 15:02:23.343462  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0138643 (* 1 = 0.0138643 loss)
I0422 15:02:23.343468  7918 sgd_solver.cpp:106] Iteration 40, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:02:27.674226  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:02:27.674248  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:02:27.674253  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 23
('accuracy: ', 0.0)
I0422 15:02:27.690204  7918 solver.cpp:228] Iteration 41, loss = 3.20019
I0422 15:02:27.690222  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:27.690230  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.77186 (* 1 = 2.77186 loss)
I0422 15:02:27.690235  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:27.690238  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:02:27.690243  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:02:27.690246  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:02:27.690250  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.418871 (* 1 = 0.418871 loss)
I0422 15:02:27.690255  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00945754 (* 1 = 0.00945754 loss)
I0422 15:02:27.690260  7918 sgd_solver.cpp:106] Iteration 41, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:32.022392  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:02:32.022415  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:02:32.022420  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 28
('accuracy: ', 0.0)
I0422 15:02:32.038280  7918 solver.cpp:228] Iteration 42, loss = 2.07203
I0422 15:02:32.038301  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:32.038309  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.67058 (* 1 = 1.67058 loss)
I0422 15:02:32.038316  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:32.038319  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:02:32.038323  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:02:32.038326  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:02:32.038331  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.39161 (* 1 = 0.39161 loss)
I0422 15:02:32.038336  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00983355 (* 1 = 0.00983355 loss)
I0422 15:02:32.038342  7918 sgd_solver.cpp:106] Iteration 42, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:36.370105  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:02:36.370126  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:02:36.370131  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 15:02:36.386587  7918 solver.cpp:228] Iteration 43, loss = 2.03104
I0422 15:02:36.386607  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:36.386616  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.63541 (* 1 = 1.63541 loss)
I0422 15:02:36.386621  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:36.386626  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:02:36.386631  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:02:36.386633  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:02:36.386638  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.386169 (* 1 = 0.386169 loss)
I0422 15:02:36.386644  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0094619 (* 1 = 0.0094619 loss)
I0422 15:02:36.386651  7918 sgd_solver.cpp:106] Iteration 43, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:40.723711  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:02:40.723731  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:02:40.723737  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 15:02:40.739495  7918 solver.cpp:228] Iteration 44, loss = 2.98117
I0422 15:02:40.739517  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:40.739526  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.6009 (* 1 = 2.6009 loss)
I0422 15:02:40.739531  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:40.739534  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:02:40.739538  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:02:40.739542  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:02:40.739547  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.371962 (* 1 = 0.371962 loss)
I0422 15:02:40.739552  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00831655 (* 1 = 0.00831655 loss)
I0422 15:02:40.739558  7918 sgd_solver.cpp:106] Iteration 44, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:45.069301  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:02:45.069324  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:02:45.069329  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 31
('accuracy: ', 0.0)
I0422 15:02:45.085531  7918 solver.cpp:228] Iteration 45, loss = 1.71152
I0422 15:02:45.085551  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:45.085558  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.42566 (* 1 = 1.42566 loss)
I0422 15:02:45.085563  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:45.085567  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:02:45.085572  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:02:45.085575  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:02:45.085580  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.273923 (* 1 = 0.273923 loss)
I0422 15:02:45.085585  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0119383 (* 1 = 0.0119383 loss)
I0422 15:02:45.085590  7918 sgd_solver.cpp:106] Iteration 45, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:49.384320  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:02:49.384341  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:02:49.384356  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 24
('accuracy: ', 0.0)
I0422 15:02:49.400001  7918 solver.cpp:228] Iteration 46, loss = 3.23793
I0422 15:02:49.400019  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:49.400027  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.86561 (* 1 = 2.86561 loss)
I0422 15:02:49.400033  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:49.400036  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:02:49.400040  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:02:49.400044  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:02:49.400049  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.363405 (* 1 = 0.363405 loss)
I0422 15:02:49.400054  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00891428 (* 1 = 0.00891428 loss)
I0422 15:02:49.400059  7918 sgd_solver.cpp:106] Iteration 46, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:53.731097  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:02:53.731122  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:02:53.731127  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 15:02:53.747115  7918 solver.cpp:228] Iteration 47, loss = 2.31853
I0422 15:02:53.747134  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:53.747143  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.96704 (* 1 = 1.96704 loss)
I0422 15:02:53.747148  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:53.747151  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:02:53.747155  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:02:53.747159  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:02:53.747164  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.340777 (* 1 = 0.340777 loss)
I0422 15:02:53.747169  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0107126 (* 1 = 0.0107126 loss)
I0422 15:02:53.747174  7918 sgd_solver.cpp:106] Iteration 47, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:02:58.080358  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:02:58.080380  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:02:58.080387  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 15:02:58.096138  7918 solver.cpp:228] Iteration 48, loss = 2.19253
I0422 15:02:58.096160  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:02:58.096173  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.80119 (* 1 = 1.80119 loss)
I0422 15:02:58.096182  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:02:58.096190  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:02:58.096200  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:02:58.096210  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:02:58.096222  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.382616 (* 1 = 0.382616 loss)
I0422 15:02:58.096233  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00872382 (* 1 = 0.00872382 loss)
I0422 15:02:58.096243  7918 sgd_solver.cpp:106] Iteration 48, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 15:03:02.425921  7918 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 15:03:02.425943  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:02.425951  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 20
('accuracy: ', 0.0)
I0422 15:03:02.441857  7918 solver.cpp:228] Iteration 49, loss = 3.59471
I0422 15:03:02.441874  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:02.441882  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.18515 (* 1 = 3.18515 loss)
I0422 15:03:02.441887  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:02.441891  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 15:03:02.441895  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:02.441900  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:02.441903  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.385984 (* 1 = 0.385984 loss)
I0422 15:03:02.441913  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0235791 (* 1 = 0.0235791 loss)
I0422 15:03:02.441920  7918 sgd_solver.cpp:106] Iteration 49, lr = 0.0001
speed: 4.300s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:06.746193  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:03:06.746217  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:06.746220  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 15:03:06.761601  7918 solver.cpp:228] Iteration 50, loss = 2.67157
I0422 15:03:06.761620  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:06.761626  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.3625 (* 1 = 2.3625 loss)
I0422 15:03:06.761631  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:06.761636  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:03:06.761641  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:06.761644  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:06.761648  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.300404 (* 1 = 0.300404 loss)
I0422 15:03:06.761653  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00866752 (* 1 = 0.00866752 loss)
I0422 15:03:06.761659  7918 sgd_solver.cpp:106] Iteration 50, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:11.069767  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:03:11.069789  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:11.069794  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 6
num bg: 29
('accuracy: ', 0.0)
I0422 15:03:11.085429  7918 solver.cpp:228] Iteration 51, loss = 1.98899
I0422 15:03:11.085448  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:11.085456  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.65307 (* 1 = 1.65307 loss)
I0422 15:03:11.085461  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:11.085465  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:03:11.085469  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:11.085472  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:11.085477  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.326261 (* 1 = 0.326261 loss)
I0422 15:03:11.085482  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00965242 (* 1 = 0.00965242 loss)
I0422 15:03:11.085489  7918 sgd_solver.cpp:106] Iteration 51, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:15.431849  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:03:15.431869  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:15.431874  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 31
('accuracy: ', 0.0)
I0422 15:03:15.447664  7918 solver.cpp:228] Iteration 52, loss = 2.02792
I0422 15:03:15.447681  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:15.447690  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.74988 (* 1 = 1.74988 loss)
I0422 15:03:15.447695  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:15.447700  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:03:15.447702  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:15.447706  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:15.447711  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.269009 (* 1 = 0.269009 loss)
I0422 15:03:15.447716  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0090285 (* 1 = 0.0090285 loss)
I0422 15:03:15.447722  7918 sgd_solver.cpp:106] Iteration 52, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:19.776316  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:03:19.776338  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:19.776343  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 15:03:19.792078  7918 solver.cpp:228] Iteration 53, loss = 2.56845
I0422 15:03:19.792106  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:19.792114  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.23125 (* 1 = 2.23125 loss)
I0422 15:03:19.792120  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:19.792124  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:03:19.792127  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:19.792131  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:19.792135  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.328921 (* 1 = 0.328921 loss)
I0422 15:03:19.792140  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0082825 (* 1 = 0.0082825 loss)
I0422 15:03:19.792146  7918 sgd_solver.cpp:106] Iteration 53, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:24.108352  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:03:24.108373  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:24.108378  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 15:03:24.124205  7918 solver.cpp:228] Iteration 54, loss = 2.4628
I0422 15:03:24.124223  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:24.124231  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.14958 (* 1 = 2.14958 loss)
I0422 15:03:24.124238  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:24.124243  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:03:24.124246  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:24.124249  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:24.124254  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.305006 (* 1 = 0.305006 loss)
I0422 15:03:24.124258  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00821242 (* 1 = 0.00821242 loss)
I0422 15:03:24.124264  7918 sgd_solver.cpp:106] Iteration 54, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:28.454164  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:03:28.454186  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:28.454190  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 15:03:28.469990  7918 solver.cpp:228] Iteration 55, loss = 2.39148
I0422 15:03:28.470011  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:28.470019  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.1152 (* 1 = 2.1152 loss)
I0422 15:03:28.470024  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:28.470028  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:03:28.470032  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:28.470036  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:28.470041  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.260057 (* 1 = 0.260057 loss)
I0422 15:03:28.470046  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0162183 (* 1 = 0.0162183 loss)
I0422 15:03:28.470052  7918 sgd_solver.cpp:106] Iteration 55, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:03:32.789211  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:03:32.789233  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:32.789238  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 23
('accuracy: ', 0.0)
I0422 15:03:32.804821  7918 solver.cpp:228] Iteration 56, loss = 2.69105
I0422 15:03:32.804841  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:32.804848  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.46008 (* 1 = 2.46008 loss)
I0422 15:03:32.804853  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:32.804857  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:03:32.804862  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:32.804864  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:32.804868  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.215997 (* 1 = 0.215997 loss)
I0422 15:03:32.804873  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.01497 (* 1 = 0.01497 loss)
I0422 15:03:32.804879  7918 sgd_solver.cpp:106] Iteration 56, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:37.130718  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:03:37.130740  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:37.130744  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 15:03:37.146370  7918 solver.cpp:228] Iteration 57, loss = 2.26506
I0422 15:03:37.146390  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:37.146399  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.94908 (* 1 = 1.94908 loss)
I0422 15:03:37.146404  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:37.146407  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:03:37.146411  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:37.146414  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:37.146420  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.307707 (* 1 = 0.307707 loss)
I0422 15:03:37.146425  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00827196 (* 1 = 0.00827196 loss)
I0422 15:03:37.146430  7918 sgd_solver.cpp:106] Iteration 57, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:41.439924  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:03:41.439945  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:41.439949  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 15:03:41.455312  7918 solver.cpp:228] Iteration 58, loss = 2.22785
I0422 15:03:41.455329  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:41.455338  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.93996 (* 1 = 1.93996 loss)
I0422 15:03:41.455343  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:41.455346  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:03:41.455350  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:41.455354  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:41.455359  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.280478 (* 1 = 0.280478 loss)
I0422 15:03:41.455364  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00742088 (* 1 = 0.00742088 loss)
I0422 15:03:41.455369  7918 sgd_solver.cpp:106] Iteration 58, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:45.767732  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:03:45.767753  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:45.767758  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 15:03:45.783625  7918 solver.cpp:228] Iteration 59, loss = 2.61906
I0422 15:03:45.783664  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:45.783671  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.35134 (* 1 = 2.35134 loss)
I0422 15:03:45.783677  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:45.783681  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:03:45.783691  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:45.783695  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:03:45.783701  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.257718 (* 1 = 0.257718 loss)
I0422 15:03:45.783710  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0100083 (* 1 = 0.0100083 loss)
I0422 15:03:45.783715  7918 sgd_solver.cpp:106] Iteration 59, lr = 0.0001
speed: 4.305s / iter
rpn: num_positive 5
rpn: num_negative 59
I0422 15:03:50.110273  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:03:50.110296  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:50.110301  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 12
num bg: 20
('accuracy: ', 0.0)
I0422 15:03:50.126209  7918 solver.cpp:228] Iteration 60, loss = 3.16828
I0422 15:03:50.126229  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:50.126236  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.85962 (* 1 = 2.85962 loss)
I0422 15:03:50.126242  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:50.126246  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:03:50.126250  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:50.126255  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:50.126260  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.284037 (* 1 = 0.284037 loss)
I0422 15:03:50.126265  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0246252 (* 1 = 0.0246252 loss)
I0422 15:03:50.126269  7918 sgd_solver.cpp:106] Iteration 60, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:54.458531  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:03:54.458552  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:54.458557  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 15:03:54.474301  7918 solver.cpp:228] Iteration 61, loss = 2.49458
I0422 15:03:54.474321  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:54.474329  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.24889 (* 1 = 2.24889 loss)
I0422 15:03:54.474334  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:54.474337  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:03:54.474341  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:54.474345  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:03:54.474349  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.234605 (* 1 = 0.234605 loss)
I0422 15:03:54.474354  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0110873 (* 1 = 0.0110873 loss)
I0422 15:03:54.474359  7918 sgd_solver.cpp:106] Iteration 61, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:03:58.789223  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:03:58.789244  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:03:58.789260  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 15:03:58.804706  7918 solver.cpp:228] Iteration 62, loss = 2.44637
I0422 15:03:58.804728  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:03:58.804738  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.19025 (* 1 = 2.19025 loss)
I0422 15:03:58.804760  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:03:58.804769  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:03:58.804777  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:03:58.804785  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:03:58.804793  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.24758 (* 1 = 0.24758 loss)
I0422 15:03:58.804803  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0085367 (* 1 = 0.0085367 loss)
I0422 15:03:58.804812  7918 sgd_solver.cpp:106] Iteration 62, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:03.105362  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:04:03.105386  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:03.105392  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 9
num bg: 31
('accuracy: ', 0.0)
I0422 15:04:03.121157  7918 solver.cpp:228] Iteration 63, loss = 3.25398
I0422 15:04:03.121174  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:03.121186  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.93661 (* 1 = 2.93661 loss)
I0422 15:04:03.121201  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:03.121210  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:04:03.121217  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:03.121225  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:04:03.121237  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.310197 (* 1 = 0.310197 loss)
I0422 15:04:03.121248  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00717564 (* 1 = 0.00717564 loss)
I0422 15:04:03.121256  7918 sgd_solver.cpp:106] Iteration 63, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:07.431543  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:04:07.431566  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:07.431573  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 15:04:07.447410  7918 solver.cpp:228] Iteration 64, loss = 9.33246
I0422 15:04:07.447429  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:07.447441  7918 solver.cpp:244]     Train net output #1: loss_cls = 9.0405 (* 1 = 9.0405 loss)
I0422 15:04:07.447455  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:07.447463  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:04:07.447473  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:07.447481  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:04:07.447492  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.283109 (* 1 = 0.283109 loss)
I0422 15:04:07.447501  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00885773 (* 1 = 0.00885773 loss)
I0422 15:04:07.447510  7918 sgd_solver.cpp:106] Iteration 64, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:04:11.749385  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:04:11.749406  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:11.749411  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.5
TRAIN
[]
get twin regression called
num fg: 7
num bg: 18
('accuracy: ', 0.0)
I0422 15:04:11.764784  7918 solver.cpp:228] Iteration 65, loss = 2.77263
I0422 15:04:11.764802  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:11.764811  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.50454 (* 1 = 2.50454 loss)
I0422 15:04:11.764816  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:11.764818  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:04:11.764822  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:11.764827  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.5
I0422 15:04:11.764837  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.266905 (* 1 = 0.266905 loss)
I0422 15:04:11.764842  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00118158 (* 1 = 0.00118158 loss)
I0422 15:04:11.764847  7918 sgd_solver.cpp:106] Iteration 65, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:04:16.069800  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:04:16.069821  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:16.069826  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 10
('accuracy: ', 0.0)
I0422 15:04:16.084707  7918 solver.cpp:228] Iteration 66, loss = 4.26388
I0422 15:04:16.084727  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:16.084735  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.96105 (* 1 = 3.96105 loss)
I0422 15:04:16.084740  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:16.084744  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:04:16.084748  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:16.084753  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:04:16.084758  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.295269 (* 1 = 0.295269 loss)
I0422 15:04:16.084763  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00756301 (* 1 = 0.00756301 loss)
I0422 15:04:16.084767  7918 sgd_solver.cpp:106] Iteration 66, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:20.414688  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:04:20.414710  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:20.414716  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0.166667
TRAIN
[]
get twin regression called
num fg: 9
num bg: 24
('accuracy: ', 0.0)
I0422 15:04:20.431531  7918 solver.cpp:228] Iteration 67, loss = 3.07638
I0422 15:04:20.431553  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:20.431562  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.7166 (* 1 = 2.7166 loss)
I0422 15:04:20.431567  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:20.431572  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:04:20.431576  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:20.431581  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0.166667
I0422 15:04:20.431586  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.350428 (* 1 = 0.350428 loss)
I0422 15:04:20.431591  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00935403 (* 1 = 0.00935403 loss)
I0422 15:04:20.431596  7918 sgd_solver.cpp:106] Iteration 67, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:24.749508  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:04:24.749531  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:24.749536  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 23
('accuracy: ', 0.0)
I0422 15:04:24.765132  7918 solver.cpp:228] Iteration 68, loss = 3.10772
I0422 15:04:24.765149  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:24.765157  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.78504 (* 1 = 2.78504 loss)
I0422 15:04:24.765162  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:24.765166  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:04:24.765170  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:24.765173  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:04:24.765178  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.313024 (* 1 = 0.313024 loss)
I0422 15:04:24.765183  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00965368 (* 1 = 0.00965368 loss)
I0422 15:04:24.765188  7918 sgd_solver.cpp:106] Iteration 68, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:29.087146  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:04:29.087168  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:29.087173  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 23
('accuracy: ', 0.0)
I0422 15:04:29.103134  7918 solver.cpp:228] Iteration 69, loss = 3.16053
I0422 15:04:29.103150  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:29.103169  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.80361 (* 1 = 2.80361 loss)
I0422 15:04:29.103174  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:29.103178  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:04:29.103183  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:29.103185  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:04:29.103189  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.345916 (* 1 = 0.345916 loss)
I0422 15:04:29.103194  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0110028 (* 1 = 0.0110028 loss)
I0422 15:04:29.103200  7918 sgd_solver.cpp:106] Iteration 69, lr = 0.0001
speed: 4.309s / iter
rpn: num_positive 4
rpn: num_negative 60
I0422 15:04:33.402604  7918 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 15:04:33.402627  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:33.402631  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 11
num bg: 26
('accuracy: ', 0.0)
I0422 15:04:33.418915  7918 solver.cpp:228] Iteration 70, loss = 2.74948
I0422 15:04:33.418933  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:33.418941  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.51148 (* 1 = 2.51148 loss)
I0422 15:04:33.418946  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:33.418951  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 15:04:33.418954  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:33.418958  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:04:33.418962  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.225582 (* 1 = 0.225582 loss)
I0422 15:04:33.418967  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0124152 (* 1 = 0.0124152 loss)
I0422 15:04:33.418973  7918 sgd_solver.cpp:106] Iteration 70, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:37.692473  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:04:37.692494  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:37.692499  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 15:04:37.707844  7918 solver.cpp:228] Iteration 71, loss = 2.22292
I0422 15:04:37.707864  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:37.707872  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.93825 (* 1 = 1.93825 loss)
I0422 15:04:37.707877  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:37.707880  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:04:37.707885  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:37.707888  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:04:37.707893  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.277859 (* 1 = 0.277859 loss)
I0422 15:04:37.707898  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00680978 (* 1 = 0.00680978 loss)
I0422 15:04:37.707906  7918 sgd_solver.cpp:106] Iteration 71, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:41.999867  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:04:41.999896  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:41.999904  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 15:04:42.016708  7918 solver.cpp:228] Iteration 72, loss = 2.43919
I0422 15:04:42.016728  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:42.016737  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.19775 (* 1 = 2.19775 loss)
I0422 15:04:42.016744  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:42.016748  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:04:42.016754  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:42.016758  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:04:42.016762  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.235579 (* 1 = 0.235579 loss)
I0422 15:04:42.016769  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00585882 (* 1 = 0.00585882 loss)
I0422 15:04:42.016777  7918 sgd_solver.cpp:106] Iteration 72, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:46.349761  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:04:46.349784  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:46.349788  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 15:04:46.365692  7918 solver.cpp:228] Iteration 73, loss = 2.17445
I0422 15:04:46.365708  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:46.365716  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.95366 (* 1 = 1.95366 loss)
I0422 15:04:46.365721  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:46.365725  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:04:46.365730  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:46.365733  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:04:46.365737  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.215571 (* 1 = 0.215571 loss)
I0422 15:04:46.365748  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00521399 (* 1 = 0.00521399 loss)
I0422 15:04:46.365754  7918 sgd_solver.cpp:106] Iteration 73, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:50.691757  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:04:50.691779  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:50.691783  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 15:04:50.707572  7918 solver.cpp:228] Iteration 74, loss = 3.01531
I0422 15:04:50.707589  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:50.707597  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.8001 (* 1 = 2.8001 loss)
I0422 15:04:50.707602  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:50.707607  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:04:50.707610  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:50.707613  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:04:50.707618  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.209608 (* 1 = 0.209608 loss)
I0422 15:04:50.707628  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00560292 (* 1 = 0.00560292 loss)
I0422 15:04:50.707633  7918 sgd_solver.cpp:106] Iteration 74, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:55.016470  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:04:55.016494  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:55.016497  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 15:04:55.032449  7918 solver.cpp:228] Iteration 75, loss = 1.86672
I0422 15:04:55.032469  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:55.032477  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.6678 (* 1 = 1.6678 loss)
I0422 15:04:55.032483  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:55.032486  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:04:55.032490  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:55.032495  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:04:55.032498  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.186615 (* 1 = 0.186615 loss)
I0422 15:04:55.032505  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0123114 (* 1 = 0.0123114 loss)
I0422 15:04:55.032510  7918 sgd_solver.cpp:106] Iteration 75, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:04:59.349653  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:04:59.349675  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:04:59.349689  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 15:04:59.367471  7918 solver.cpp:228] Iteration 76, loss = 1.73967
I0422 15:04:59.367496  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:04:59.367503  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.55304 (* 1 = 1.55304 loss)
I0422 15:04:59.367509  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:04:59.367513  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:04:59.367517  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:04:59.367522  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:04:59.367527  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.180444 (* 1 = 0.180444 loss)
I0422 15:04:59.367532  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00619194 (* 1 = 0.00619194 loss)
I0422 15:04:59.367538  7918 sgd_solver.cpp:106] Iteration 76, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:05:03.683226  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:05:03.683250  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:03.683254  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 21
('accuracy: ', 0.0)
I0422 15:05:03.699164  7918 solver.cpp:228] Iteration 77, loss = 2.6846
I0422 15:05:03.699185  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:03.699193  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.51536 (* 1 = 2.51536 loss)
I0422 15:05:03.699200  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:03.699205  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:05:03.699209  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:03.699213  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:03.699218  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.166449 (* 1 = 0.166449 loss)
I0422 15:05:03.699223  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00279958 (* 1 = 0.00279958 loss)
I0422 15:05:03.699229  7918 sgd_solver.cpp:106] Iteration 77, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:05:08.002018  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:05:08.002039  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:08.002044  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 29
('accuracy: ', 0.0)
I0422 15:05:08.017925  7918 solver.cpp:228] Iteration 78, loss = 3.13906
I0422 15:05:08.017953  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:08.017961  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.94454 (* 1 = 2.94454 loss)
I0422 15:05:08.017966  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:08.017971  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:05:08.017974  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:08.017978  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:08.017982  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.189325 (* 1 = 0.189325 loss)
I0422 15:05:08.017987  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00518971 (* 1 = 0.00518971 loss)
I0422 15:05:08.017992  7918 sgd_solver.cpp:106] Iteration 78, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:05:12.316804  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:05:12.316828  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:12.316831  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 15:05:12.332425  7918 solver.cpp:228] Iteration 79, loss = 2.75026
I0422 15:05:12.332443  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:12.332451  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.53593 (* 1 = 2.53593 loss)
I0422 15:05:12.332456  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:12.332460  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:05:12.332465  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:12.332468  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:12.332473  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.207474 (* 1 = 0.207474 loss)
I0422 15:05:12.332479  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00685233 (* 1 = 0.00685233 loss)
I0422 15:05:12.332484  7918 sgd_solver.cpp:106] Iteration 79, lr = 0.0001
speed: 4.311s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:05:16.627178  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:05:16.627200  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:16.627205  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 15:05:16.642621  7918 solver.cpp:228] Iteration 80, loss = 2.36608
I0422 15:05:16.642639  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:16.642648  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.13076 (* 1 = 2.13076 loss)
I0422 15:05:16.642653  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:16.642657  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:05:16.642660  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:16.642664  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:16.642668  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.231265 (* 1 = 0.231265 loss)
I0422 15:05:16.642673  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00405617 (* 1 = 0.00405617 loss)
I0422 15:05:16.642678  7918 sgd_solver.cpp:106] Iteration 80, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:05:20.945613  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:05:20.945634  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:20.945638  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 12
('accuracy: ', 0.0)
I0422 15:05:20.960508  7918 solver.cpp:228] Iteration 81, loss = 3.32636
I0422 15:05:20.960537  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:20.960546  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.12727 (* 1 = 3.12727 loss)
I0422 15:05:20.960551  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:20.960556  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:05:20.960559  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:20.960563  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:20.960567  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.1894 (* 1 = 0.1894 loss)
I0422 15:05:20.960572  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00969543 (* 1 = 0.00969543 loss)
I0422 15:05:20.960578  7918 sgd_solver.cpp:106] Iteration 81, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:05:25.271334  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:05:25.271356  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:25.271361  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 25
('accuracy: ', 0.0)
I0422 15:05:25.287003  7918 solver.cpp:228] Iteration 82, loss = 3.23338
I0422 15:05:25.287022  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:25.287030  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.90761 (* 1 = 2.90761 loss)
I0422 15:05:25.287037  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:25.287041  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:05:25.287046  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:25.287050  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:25.287055  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.319621 (* 1 = 0.319621 loss)
I0422 15:05:25.287060  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00615624 (* 1 = 0.00615624 loss)
I0422 15:05:25.287066  7918 sgd_solver.cpp:106] Iteration 82, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:05:29.590521  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:05:29.590543  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:29.590559  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 26
('accuracy: ', 0.0)
I0422 15:05:29.606757  7918 solver.cpp:228] Iteration 83, loss = 2.86453
I0422 15:05:29.606799  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:29.606806  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.57975 (* 1 = 2.57975 loss)
I0422 15:05:29.606812  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:29.606815  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:05:29.606819  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:29.606823  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:29.606827  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.279582 (* 1 = 0.279582 loss)
I0422 15:05:29.606832  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0051956 (* 1 = 0.0051956 loss)
I0422 15:05:29.606837  7918 sgd_solver.cpp:106] Iteration 83, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:05:33.909740  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:05:33.909761  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:33.909766  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 3
num bg: 7
('accuracy: ', 0.0)
I0422 15:05:33.920311  7918 solver.cpp:228] Iteration 84, loss = 2.63616
I0422 15:05:33.920332  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:33.920341  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.40928 (* 1 = 2.40928 loss)
I0422 15:05:33.920346  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:33.920351  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:05:33.920354  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:33.920358  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:33.920362  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.224469 (* 1 = 0.224469 loss)
I0422 15:05:33.920367  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00241264 (* 1 = 0.00241264 loss)
I0422 15:05:33.920375  7918 sgd_solver.cpp:106] Iteration 84, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:05:38.231812  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:05:38.231833  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:38.231837  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 4
num bg: 20
('accuracy: ', 0.0)
I0422 15:05:38.247421  7918 solver.cpp:228] Iteration 85, loss = 2.05457
I0422 15:05:38.247450  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:38.247458  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.72536 (* 1 = 1.72536 loss)
I0422 15:05:38.247463  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:38.247467  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:05:38.247472  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:38.247475  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:38.247479  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.32218 (* 1 = 0.32218 loss)
I0422 15:05:38.247484  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00702804 (* 1 = 0.00702804 loss)
I0422 15:05:38.247489  7918 sgd_solver.cpp:106] Iteration 85, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:05:42.551486  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:05:42.551509  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:42.551514  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 15:05:42.567466  7918 solver.cpp:228] Iteration 86, loss = 2.1173
I0422 15:05:42.567487  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:42.567494  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.8826 (* 1 = 1.8826 loss)
I0422 15:05:42.567500  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:42.567504  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:05:42.567508  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:42.567513  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:42.567519  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.229785 (* 1 = 0.229785 loss)
I0422 15:05:42.567523  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00491585 (* 1 = 0.00491585 loss)
I0422 15:05:42.567529  7918 sgd_solver.cpp:106] Iteration 86, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:05:46.874150  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:05:46.874172  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:46.874177  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 13
num bg: 25
('accuracy: ', 0.0)
I0422 15:05:46.889894  7918 solver.cpp:228] Iteration 87, loss = 2.65617
I0422 15:05:46.889910  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:46.889920  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.49513 (* 1 = 2.49513 loss)
I0422 15:05:46.889927  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:46.889931  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:05:46.889935  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:46.889938  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:46.889942  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.148764 (* 1 = 0.148764 loss)
I0422 15:05:46.889947  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0122785 (* 1 = 0.0122785 loss)
I0422 15:05:46.889953  7918 sgd_solver.cpp:106] Iteration 87, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 15:05:51.176141  7918 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 15:05:51.176162  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:51.176167  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 20
('accuracy: ', 0.0)
I0422 15:05:51.191794  7918 solver.cpp:228] Iteration 88, loss = 2.33365
I0422 15:05:51.191815  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:51.191823  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.16627 (* 1 = 2.16627 loss)
I0422 15:05:51.191828  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:51.191831  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 15:05:51.191835  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:51.191839  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:51.191843  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.147996 (* 1 = 0.147996 loss)
I0422 15:05:51.191854  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0193885 (* 1 = 0.0193885 loss)
I0422 15:05:51.191860  7918 sgd_solver.cpp:106] Iteration 88, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:05:55.491783  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:05:55.491806  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:55.491809  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 15:05:55.507544  7918 solver.cpp:228] Iteration 89, loss = 2.60215
I0422 15:05:55.507563  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:55.507570  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.38329 (* 1 = 2.38329 loss)
I0422 15:05:55.507575  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:55.507580  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:05:55.507583  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:55.507587  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:55.507592  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.215375 (* 1 = 0.215375 loss)
I0422 15:05:55.507597  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00349301 (* 1 = 0.00349301 loss)
I0422 15:05:55.507603  7918 sgd_solver.cpp:106] Iteration 89, lr = 0.0001
speed: 4.312s / iter
rpn: num_positive 2
rpn: num_negative 62
I0422 15:05:59.814206  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:05:59.814251  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:05:59.814256  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 29
('accuracy: ', 0.0)
I0422 15:05:59.829895  7918 solver.cpp:228] Iteration 90, loss = 1.94846
I0422 15:05:59.829911  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:05:59.829921  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.86677 (* 1 = 1.86677 loss)
I0422 15:05:59.829926  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:05:59.829929  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:05:59.829933  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:05:59.829937  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:05:59.829941  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0780798 (* 1 = 0.0780798 loss)
I0422 15:05:59.829946  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00360382 (* 1 = 0.00360382 loss)
I0422 15:05:59.829952  7918 sgd_solver.cpp:106] Iteration 90, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:06:04.117818  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:06:04.117847  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:04.117852  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 20
('accuracy: ', 0.0)
I0422 15:06:04.133291  7918 solver.cpp:228] Iteration 91, loss = 2.66624
I0422 15:06:04.133307  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:04.133316  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.55851 (* 1 = 2.55851 loss)
I0422 15:06:04.133321  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:04.133324  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:06:04.133328  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:04.133332  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:04.133337  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0997918 (* 1 = 0.0997918 loss)
I0422 15:06:04.133342  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00794175 (* 1 = 0.00794175 loss)
I0422 15:06:04.133347  7918 sgd_solver.cpp:106] Iteration 91, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:06:08.422366  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:06:08.422389  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:08.422394  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 15:06:08.438030  7918 solver.cpp:228] Iteration 92, loss = 2.56424
I0422 15:06:08.438046  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:08.438055  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.42694 (* 1 = 2.42694 loss)
I0422 15:06:08.438060  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:08.438063  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:06:08.438067  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:08.438071  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:08.438076  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.133147 (* 1 = 0.133147 loss)
I0422 15:06:08.438086  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0041547 (* 1 = 0.0041547 loss)
I0422 15:06:08.438091  7918 sgd_solver.cpp:106] Iteration 92, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 15:06:12.738284  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:06:12.738306  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:12.738310  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 12
num bg: 24
('accuracy: ', 0.0)
I0422 15:06:12.753901  7918 solver.cpp:228] Iteration 93, loss = 3.69467
I0422 15:06:12.753921  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:12.753929  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.51496 (* 1 = 3.51496 loss)
I0422 15:06:12.753934  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:12.753938  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:06:12.753942  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:12.753945  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:12.753949  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.160013 (* 1 = 0.160013 loss)
I0422 15:06:12.753954  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0196974 (* 1 = 0.0196974 loss)
I0422 15:06:12.753960  7918 sgd_solver.cpp:106] Iteration 93, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:06:17.037051  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:06:17.037072  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:17.037076  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 11
num bg: 28
('accuracy: ', 0.0)
I0422 15:06:17.052532  7918 solver.cpp:228] Iteration 94, loss = 2.2727
I0422 15:06:17.052551  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:17.052558  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.13828 (* 1 = 2.13828 loss)
I0422 15:06:17.052564  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:17.052567  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:06:17.052572  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:17.052575  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:17.052580  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.129881 (* 1 = 0.129881 loss)
I0422 15:06:17.052585  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00454341 (* 1 = 0.00454341 loss)
I0422 15:06:17.052590  7918 sgd_solver.cpp:106] Iteration 94, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 15:06:21.327474  7918 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 15:06:21.327494  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:21.327498  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 15:06:21.342819  7918 solver.cpp:228] Iteration 95, loss = 2.81227
I0422 15:06:21.342836  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:21.342845  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.62523 (* 1 = 2.62523 loss)
I0422 15:06:21.342850  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:21.342854  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 15:06:21.342859  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:21.342861  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:21.342866  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.169914 (* 1 = 0.169914 loss)
I0422 15:06:21.342871  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0171186 (* 1 = 0.0171186 loss)
I0422 15:06:21.342877  7918 sgd_solver.cpp:106] Iteration 95, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:06:25.630105  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:06:25.630126  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:25.630131  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 28
('accuracy: ', 0.0)
I0422 15:06:25.645707  7918 solver.cpp:228] Iteration 96, loss = 2.60071
I0422 15:06:25.645725  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:25.645732  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.42633 (* 1 = 2.42633 loss)
I0422 15:06:25.645738  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:25.645741  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:06:25.645745  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:25.645750  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:25.645754  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.169622 (* 1 = 0.169622 loss)
I0422 15:06:25.645759  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00475698 (* 1 = 0.00475698 loss)
I0422 15:06:25.645766  7918 sgd_solver.cpp:106] Iteration 96, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 15:06:29.931514  7918 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 15:06:29.931535  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:29.931540  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 25
('accuracy: ', 0.0)
I0422 15:06:29.946787  7918 solver.cpp:228] Iteration 97, loss = 2.40645
I0422 15:06:29.946806  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:29.946815  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.2601 (* 1 = 2.2601 loss)
I0422 15:06:29.946820  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:29.946825  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 15:06:29.946828  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:29.946832  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:29.946836  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.144129 (* 1 = 0.144129 loss)
I0422 15:06:29.946841  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0022142 (* 1 = 0.0022142 loss)
I0422 15:06:29.946847  7918 sgd_solver.cpp:106] Iteration 97, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:06:34.267369  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:06:34.267391  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:34.267396  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 24
('accuracy: ', 0.0)
I0422 15:06:34.283179  7918 solver.cpp:228] Iteration 98, loss = 2.95651
I0422 15:06:34.283201  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:34.283210  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.725 (* 1 = 2.725 loss)
I0422 15:06:34.283215  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:34.283218  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:06:34.283222  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:34.283226  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:34.283231  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.225973 (* 1 = 0.225973 loss)
I0422 15:06:34.283236  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00553311 (* 1 = 0.00553311 loss)
I0422 15:06:34.283243  7918 sgd_solver.cpp:106] Iteration 98, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:06:38.580147  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:06:38.580169  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:38.580173  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 28
('accuracy: ', 0.0)
I0422 15:06:38.595623  7918 solver.cpp:228] Iteration 99, loss = 2.25152
I0422 15:06:38.595640  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:38.595649  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.02558 (* 1 = 2.02558 loss)
I0422 15:06:38.595654  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:38.595657  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:06:38.595661  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:38.595665  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:38.595669  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.220878 (* 1 = 0.220878 loss)
I0422 15:06:38.595674  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0050656 (* 1 = 0.0050656 loss)
I0422 15:06:38.595681  7918 sgd_solver.cpp:106] Iteration 99, lr = 0.0001
speed: 4.311s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:06:42.888116  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:06:42.888139  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:42.888144  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 15:06:42.907433  7918 solver.cpp:228] Iteration 100, loss = 2.52203
I0422 15:06:42.907456  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:42.907465  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.27947 (* 1 = 2.27947 loss)
I0422 15:06:42.907471  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:42.907476  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:06:42.907480  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:42.907485  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:42.907490  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.237909 (* 1 = 0.237909 loss)
I0422 15:06:42.907495  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00465374 (* 1 = 0.00465374 loss)
I0422 15:06:42.907501  7918 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:06:47.204310  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:06:47.204334  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:47.204337  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 15:06:47.219971  7918 solver.cpp:228] Iteration 101, loss = 2.3576
I0422 15:06:47.219988  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:47.219996  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.15407 (* 1 = 2.15407 loss)
I0422 15:06:47.220001  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:47.220005  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:06:47.220010  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:47.220013  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:47.220017  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.197641 (* 1 = 0.197641 loss)
I0422 15:06:47.220022  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.005886 (* 1 = 0.005886 loss)
I0422 15:06:47.220028  7918 sgd_solver.cpp:106] Iteration 101, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:06:51.508643  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:06:51.508664  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:51.508669  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 30
('accuracy: ', 0.0)
I0422 15:06:51.525791  7918 solver.cpp:228] Iteration 102, loss = 1.82645
I0422 15:06:51.525815  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:51.525827  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.59802 (* 1 = 1.59802 loss)
I0422 15:06:51.525836  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:51.525842  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:06:51.525849  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:51.525856  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:51.525863  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.223964 (* 1 = 0.223964 loss)
I0422 15:06:51.525871  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00446433 (* 1 = 0.00446433 loss)
I0422 15:06:51.525879  7918 sgd_solver.cpp:106] Iteration 102, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:06:55.804747  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:06:55.804769  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:06:55.804782  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 15:06:55.820220  7918 solver.cpp:228] Iteration 103, loss = 2.03781
I0422 15:06:55.820237  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:06:55.820245  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.84937 (* 1 = 1.84937 loss)
I0422 15:06:55.820250  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:06:55.820255  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:06:55.820258  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:06:55.820262  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:06:55.820267  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.183824 (* 1 = 0.183824 loss)
I0422 15:06:55.820272  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00462029 (* 1 = 0.00462029 loss)
I0422 15:06:55.820277  7918 sgd_solver.cpp:106] Iteration 103, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:07:00.124517  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:07:00.124538  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:00.124542  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 15:07:00.140249  7918 solver.cpp:228] Iteration 104, loss = 2.27916
I0422 15:07:00.140266  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:00.140275  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.1498 (* 1 = 2.1498 loss)
I0422 15:07:00.140280  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:00.140282  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:07:00.140286  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:00.140290  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:00.140295  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.126206 (* 1 = 0.126206 loss)
I0422 15:07:00.140300  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00315501 (* 1 = 0.00315501 loss)
I0422 15:07:00.140305  7918 sgd_solver.cpp:106] Iteration 104, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:07:04.428941  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:07:04.428962  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:04.428967  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 15:07:04.444788  7918 solver.cpp:228] Iteration 105, loss = 2.27825
I0422 15:07:04.444804  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:04.444813  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.11777 (* 1 = 2.11777 loss)
I0422 15:07:04.444818  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:04.444821  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:07:04.444825  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:04.444828  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:04.444833  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.156282 (* 1 = 0.156282 loss)
I0422 15:07:04.444838  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00419833 (* 1 = 0.00419833 loss)
I0422 15:07:04.444844  7918 sgd_solver.cpp:106] Iteration 105, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:07:08.748121  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:07:08.748142  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:08.748147  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 22
('accuracy: ', 0.0)
I0422 15:07:08.764147  7918 solver.cpp:228] Iteration 106, loss = 2.87411
I0422 15:07:08.764185  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:08.764194  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.81201 (* 1 = 2.81201 loss)
I0422 15:07:08.764199  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:08.764202  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:07:08.764206  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:08.764210  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:08.764214  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0529682 (* 1 = 0.0529682 loss)
I0422 15:07:08.764219  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00913061 (* 1 = 0.00913061 loss)
I0422 15:07:08.764225  7918 sgd_solver.cpp:106] Iteration 106, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:07:13.058883  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:07:13.058905  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:13.058909  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 24
('accuracy: ', 0.0)
I0422 15:07:13.074368  7918 solver.cpp:228] Iteration 107, loss = 2.24709
I0422 15:07:13.074384  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:13.074393  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.18383 (* 1 = 2.18383 loss)
I0422 15:07:13.074398  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:13.074403  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:07:13.074406  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:13.074409  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:13.074414  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0520893 (* 1 = 0.0520893 loss)
I0422 15:07:13.074419  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0111747 (* 1 = 0.0111747 loss)
I0422 15:07:13.074424  7918 sgd_solver.cpp:106] Iteration 107, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:07:17.380483  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:07:17.380506  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:17.380509  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 15:07:17.396256  7918 solver.cpp:228] Iteration 108, loss = 2.17936
I0422 15:07:17.396276  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:17.396284  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.05188 (* 1 = 2.05188 loss)
I0422 15:07:17.396289  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:17.396293  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:07:17.396297  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:17.396301  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:17.396306  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.122023 (* 1 = 0.122023 loss)
I0422 15:07:17.396311  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00546059 (* 1 = 0.00546059 loss)
I0422 15:07:17.396317  7918 sgd_solver.cpp:106] Iteration 108, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:07:21.709861  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:07:21.709882  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:21.709887  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 32
('accuracy: ', 0.0)
I0422 15:07:21.725891  7918 solver.cpp:228] Iteration 109, loss = 2.07099
I0422 15:07:21.725908  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:21.725916  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.95046 (* 1 = 1.95046 loss)
I0422 15:07:21.725921  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:21.725925  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:07:21.725929  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:21.725932  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:21.725937  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.113925 (* 1 = 0.113925 loss)
I0422 15:07:21.725942  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00660442 (* 1 = 0.00660442 loss)
I0422 15:07:21.725947  7918 sgd_solver.cpp:106] Iteration 109, lr = 0.0001
speed: 4.311s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:07:26.009546  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:07:26.009567  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:26.009572  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 28
('accuracy: ', 0.0)
I0422 15:07:26.025018  7918 solver.cpp:228] Iteration 110, loss = 2.23237
I0422 15:07:26.025038  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:26.025045  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.07238 (* 1 = 2.07238 loss)
I0422 15:07:26.025050  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:26.025054  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:07:26.025058  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:26.025063  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:26.025066  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.15435 (* 1 = 0.15435 loss)
I0422 15:07:26.025071  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00564319 (* 1 = 0.00564319 loss)
I0422 15:07:26.025077  7918 sgd_solver.cpp:106] Iteration 110, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:07:30.320286  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:07:30.320308  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:30.320313  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 15:07:30.335856  7918 solver.cpp:228] Iteration 111, loss = 2.53097
I0422 15:07:30.335875  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:30.335882  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.37901 (* 1 = 2.37901 loss)
I0422 15:07:30.335887  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:30.335891  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:07:30.335896  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:30.335898  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:30.335902  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.14695 (* 1 = 0.14695 loss)
I0422 15:07:30.335907  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00500644 (* 1 = 0.00500644 loss)
I0422 15:07:30.335913  7918 sgd_solver.cpp:106] Iteration 111, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:07:34.631098  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:07:34.631119  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:34.631124  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 15:07:34.646584  7918 solver.cpp:228] Iteration 112, loss = 2.39522
I0422 15:07:34.646600  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:34.646608  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.24702 (* 1 = 2.24702 loss)
I0422 15:07:34.646615  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:34.646617  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:07:34.646621  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:34.646625  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:34.646630  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.143661 (* 1 = 0.143661 loss)
I0422 15:07:34.646634  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00453786 (* 1 = 0.00453786 loss)
I0422 15:07:34.646641  7918 sgd_solver.cpp:106] Iteration 112, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:07:38.932879  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:07:38.932899  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:38.932904  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 2
num bg: 5
('accuracy: ', 0.0)
I0422 15:07:38.941905  7918 solver.cpp:228] Iteration 113, loss = 2.56547
I0422 15:07:38.941922  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:38.941931  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.40438 (* 1 = 2.40438 loss)
I0422 15:07:38.941936  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:38.941941  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:07:38.941946  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:38.941949  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:38.941953  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.147854 (* 1 = 0.147854 loss)
I0422 15:07:38.941959  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0132387 (* 1 = 0.0132387 loss)
I0422 15:07:38.941965  7918 sgd_solver.cpp:106] Iteration 113, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:07:43.253857  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:07:43.253878  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:43.253882  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 15:07:43.269496  7918 solver.cpp:228] Iteration 114, loss = 2.14875
I0422 15:07:43.269515  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:43.269523  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.92658 (* 1 = 1.92658 loss)
I0422 15:07:43.269528  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:43.269532  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:07:43.269536  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:43.269541  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:43.269544  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.217811 (* 1 = 0.217811 loss)
I0422 15:07:43.269549  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00435751 (* 1 = 0.00435751 loss)
I0422 15:07:43.269556  7918 sgd_solver.cpp:106] Iteration 114, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:07:47.562634  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:07:47.562657  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:47.562662  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 4
num bg: 9
('accuracy: ', 0.0)
I0422 15:07:47.573951  7918 solver.cpp:228] Iteration 115, loss = 2.45716
I0422 15:07:47.573966  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:47.573983  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.31381 (* 1 = 2.31381 loss)
I0422 15:07:47.573988  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:47.573992  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:07:47.573995  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:47.573999  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:47.574003  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.137681 (* 1 = 0.137681 loss)
I0422 15:07:47.574008  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00566401 (* 1 = 0.00566401 loss)
I0422 15:07:47.574014  7918 sgd_solver.cpp:106] Iteration 115, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:07:51.867038  7918 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 15:07:51.867061  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:51.867066  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 23
('accuracy: ', 0.0)
I0422 15:07:51.882560  7918 solver.cpp:228] Iteration 116, loss = 2.27305
I0422 15:07:51.882576  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:51.882585  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.12959 (* 1 = 2.12959 loss)
I0422 15:07:51.882589  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:51.882593  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 15:07:51.882597  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:51.882601  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:51.882606  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.132776 (* 1 = 0.132776 loss)
I0422 15:07:51.882611  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0106796 (* 1 = 0.0106796 loss)
I0422 15:07:51.882616  7918 sgd_solver.cpp:106] Iteration 116, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 15:07:56.165421  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:07:56.165442  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:07:56.165447  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 15:07:56.180783  7918 solver.cpp:228] Iteration 117, loss = 2.1802
I0422 15:07:56.180801  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:07:56.180809  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.95433 (* 1 = 1.95433 loss)
I0422 15:07:56.180814  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:07:56.180819  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:07:56.180822  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:07:56.180826  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:07:56.180831  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.203054 (* 1 = 0.203054 loss)
I0422 15:07:56.180840  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0228163 (* 1 = 0.0228163 loss)
I0422 15:07:56.180846  7918 sgd_solver.cpp:106] Iteration 117, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:00.460842  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:00.460863  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:00.460868  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 15:08:00.476373  7918 solver.cpp:228] Iteration 118, loss = 1.94257
I0422 15:08:00.476389  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:00.476409  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.81009 (* 1 = 1.81009 loss)
I0422 15:08:00.476414  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:00.476418  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:00.476423  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:00.476426  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:00.476431  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.128617 (* 1 = 0.128617 loss)
I0422 15:08:00.476436  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00386316 (* 1 = 0.00386316 loss)
I0422 15:08:00.476441  7918 sgd_solver.cpp:106] Iteration 118, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:08:04.765277  7918 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 15:08:04.765300  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:04.765305  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 18
('accuracy: ', 0.0)
I0422 15:08:04.782717  7918 solver.cpp:228] Iteration 119, loss = 2.29546
I0422 15:08:04.782737  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:04.782747  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.1807 (* 1 = 2.1807 loss)
I0422 15:08:04.782752  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:04.782757  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 15:08:04.782776  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:04.782781  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:04.782788  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.105022 (* 1 = 0.105022 loss)
I0422 15:08:04.782793  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0097424 (* 1 = 0.0097424 loss)
I0422 15:08:04.782799  7918 sgd_solver.cpp:106] Iteration 119, lr = 0.0001
speed: 4.311s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:09.082522  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:09.082543  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:09.082547  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 15:08:09.098094  7918 solver.cpp:228] Iteration 120, loss = 2.93202
I0422 15:08:09.098114  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:09.098122  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.79076 (* 1 = 2.79076 loss)
I0422 15:08:09.098127  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:09.098131  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:09.098135  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:09.098140  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:09.098143  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.137301 (* 1 = 0.137301 loss)
I0422 15:08:09.098148  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00395693 (* 1 = 0.00395693 loss)
I0422 15:08:09.098155  7918 sgd_solver.cpp:106] Iteration 120, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:13.394575  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:13.394598  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:13.394603  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 15:08:13.410089  7918 solver.cpp:228] Iteration 121, loss = 2.22174
I0422 15:08:13.410105  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:13.410125  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.07792 (* 1 = 2.07792 loss)
I0422 15:08:13.410130  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:13.410133  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:13.410137  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:13.410147  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:13.410152  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.138933 (* 1 = 0.138933 loss)
I0422 15:08:13.410158  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00488508 (* 1 = 0.00488508 loss)
I0422 15:08:13.410164  7918 sgd_solver.cpp:106] Iteration 121, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:08:17.713212  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:08:17.713234  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:17.713238  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 21
('accuracy: ', 0.0)
I0422 15:08:17.728983  7918 solver.cpp:228] Iteration 122, loss = 2.35833
I0422 15:08:17.729001  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:17.729009  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.29064 (* 1 = 2.29064 loss)
I0422 15:08:17.729014  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:17.729018  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:08:17.729022  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:17.729025  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:17.729030  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0646157 (* 1 = 0.0646157 loss)
I0422 15:08:17.729034  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00307769 (* 1 = 0.00307769 loss)
I0422 15:08:17.729040  7918 sgd_solver.cpp:106] Iteration 122, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:22.031061  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:22.031085  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:22.031090  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 15:08:22.046617  7918 solver.cpp:228] Iteration 123, loss = 2.1697
I0422 15:08:22.046638  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:22.046645  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.02718 (* 1 = 2.02718 loss)
I0422 15:08:22.046650  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:22.046654  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:22.046658  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:22.046661  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:22.046666  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.138855 (* 1 = 0.138855 loss)
I0422 15:08:22.046671  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00366559 (* 1 = 0.00366559 loss)
I0422 15:08:22.046677  7918 sgd_solver.cpp:106] Iteration 123, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:26.359401  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:26.359422  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:26.359426  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 25
('accuracy: ', 0.0)
I0422 15:08:26.374881  7918 solver.cpp:228] Iteration 124, loss = 2.33597
I0422 15:08:26.374899  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:26.374907  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.19675 (* 1 = 2.19675 loss)
I0422 15:08:26.374912  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:26.374915  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:26.374919  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:26.374923  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:26.374927  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.135765 (* 1 = 0.135765 loss)
I0422 15:08:26.374933  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00345376 (* 1 = 0.00345376 loss)
I0422 15:08:26.374938  7918 sgd_solver.cpp:106] Iteration 124, lr = 0.0001
rpn: num_positive 5
rpn: num_negative 59
I0422 15:08:30.679376  7918 accuracy_layer.cpp:96] Accuracy: 0.921875
I0422 15:08:30.679397  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:30.679401  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 14
num bg: 23
('accuracy: ', 0.0)
I0422 15:08:30.695163  7918 solver.cpp:228] Iteration 125, loss = 2.93529
I0422 15:08:30.695183  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:30.695191  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.79391 (* 1 = 2.79391 loss)
I0422 15:08:30.695196  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:30.695200  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.921875
I0422 15:08:30.695204  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:30.695209  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:30.695214  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.122589 (* 1 = 0.122589 loss)
I0422 15:08:30.695219  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0187927 (* 1 = 0.0187927 loss)
I0422 15:08:30.695225  7918 sgd_solver.cpp:106] Iteration 125, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:34.994696  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:34.994719  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:34.994724  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 15:08:35.010295  7918 solver.cpp:228] Iteration 126, loss = 1.71084
I0422 15:08:35.010313  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:35.010321  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.53655 (* 1 = 1.53655 loss)
I0422 15:08:35.010326  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:35.010330  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:35.010334  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:35.010337  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:35.010342  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.170006 (* 1 = 0.170006 loss)
I0422 15:08:35.010347  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00428183 (* 1 = 0.00428183 loss)
I0422 15:08:35.010352  7918 sgd_solver.cpp:106] Iteration 126, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:39.313403  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:39.313424  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:39.313439  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 15:08:39.329126  7918 solver.cpp:228] Iteration 127, loss = 2.32009
I0422 15:08:39.329145  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:39.329154  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.15019 (* 1 = 2.15019 loss)
I0422 15:08:39.329159  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:39.329162  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:39.329166  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:39.329170  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:39.329174  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.164649 (* 1 = 0.164649 loss)
I0422 15:08:39.329180  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00524601 (* 1 = 0.00524601 loss)
I0422 15:08:39.329185  7918 sgd_solver.cpp:106] Iteration 127, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:43.614519  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:43.614540  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:43.614545  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 15:08:43.629822  7918 solver.cpp:228] Iteration 128, loss = 2.25563
I0422 15:08:43.629839  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:43.629848  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.06552 (* 1 = 2.06552 loss)
I0422 15:08:43.629853  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:43.629858  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:43.629861  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:43.629865  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:43.629869  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.184073 (* 1 = 0.184073 loss)
I0422 15:08:43.629875  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00603752 (* 1 = 0.00603752 loss)
I0422 15:08:43.629881  7918 sgd_solver.cpp:106] Iteration 128, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:47.932392  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:47.932417  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:47.932421  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 15:08:47.948176  7918 solver.cpp:228] Iteration 129, loss = 1.92649
I0422 15:08:47.948195  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:47.948204  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.76103 (* 1 = 1.76103 loss)
I0422 15:08:47.948210  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:47.948213  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:47.948217  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:47.948220  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:47.948225  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.160906 (* 1 = 0.160906 loss)
I0422 15:08:47.948230  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00454666 (* 1 = 0.00454666 loss)
I0422 15:08:47.948235  7918 sgd_solver.cpp:106] Iteration 129, lr = 0.0001
speed: 4.311s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:52.226488  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:52.226512  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:52.226516  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 15:08:52.242314  7918 solver.cpp:228] Iteration 130, loss = 2.22612
I0422 15:08:52.242336  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:52.242342  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.05779 (* 1 = 2.05779 loss)
I0422 15:08:52.242348  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:52.242352  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:52.242357  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:52.242359  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:52.242364  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.163462 (* 1 = 0.163462 loss)
I0422 15:08:52.242369  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0048706 (* 1 = 0.0048706 loss)
I0422 15:08:52.242375  7918 sgd_solver.cpp:106] Iteration 130, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:08:56.532698  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:08:56.532719  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:08:56.532724  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 6
num bg: 28
('accuracy: ', 0.0)
I0422 15:08:56.548112  7918 solver.cpp:228] Iteration 131, loss = 2.11213
I0422 15:08:56.548135  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:08:56.548142  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.91147 (* 1 = 1.91147 loss)
I0422 15:08:56.548148  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:08:56.548152  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:08:56.548156  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:08:56.548161  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:08:56.548164  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.195266 (* 1 = 0.195266 loss)
I0422 15:08:56.548169  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00540336 (* 1 = 0.00540336 loss)
I0422 15:08:56.548176  7918 sgd_solver.cpp:106] Iteration 131, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:00.846279  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:00.846302  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:00.846307  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 15:09:00.862006  7918 solver.cpp:228] Iteration 132, loss = 2.39291
I0422 15:09:00.862025  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:00.862032  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.16729 (* 1 = 2.16729 loss)
I0422 15:09:00.862037  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:00.862041  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:00.862046  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:00.862049  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:00.862053  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.219364 (* 1 = 0.219364 loss)
I0422 15:09:00.862058  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00625668 (* 1 = 0.00625668 loss)
I0422 15:09:00.862064  7918 sgd_solver.cpp:106] Iteration 132, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:05.157753  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:05.157775  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:05.157780  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 6
num bg: 27
('accuracy: ', 0.0)
I0422 15:09:05.174523  7918 solver.cpp:228] Iteration 133, loss = 1.8791
I0422 15:09:05.174546  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:05.174553  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.73415 (* 1 = 1.73415 loss)
I0422 15:09:05.174559  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:05.174563  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:05.174567  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:05.174572  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:05.174576  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.1404 (* 1 = 0.1404 loss)
I0422 15:09:05.174582  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0045507 (* 1 = 0.0045507 loss)
I0422 15:09:05.174588  7918 sgd_solver.cpp:106] Iteration 133, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:09.468605  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:09.468626  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:09.468631  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 15:09:09.484117  7918 solver.cpp:228] Iteration 134, loss = 2.17199
I0422 15:09:09.484135  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:09.484143  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.03912 (* 1 = 2.03912 loss)
I0422 15:09:09.484148  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:09.484153  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:09.484158  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:09.484160  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:09.484165  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.128006 (* 1 = 0.128006 loss)
I0422 15:09:09.484170  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00485809 (* 1 = 0.00485809 loss)
I0422 15:09:09.484175  7918 sgd_solver.cpp:106] Iteration 134, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:13.748814  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:13.748836  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:13.748841  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 32
('accuracy: ', 0.0)
I0422 15:09:13.764533  7918 solver.cpp:228] Iteration 135, loss = 2.07245
I0422 15:09:13.764549  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:13.764556  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.95848 (* 1 = 1.95848 loss)
I0422 15:09:13.764561  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:13.764565  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:13.764569  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:13.764573  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:13.764577  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.110742 (* 1 = 0.110742 loss)
I0422 15:09:13.764582  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00322815 (* 1 = 0.00322815 loss)
I0422 15:09:13.764587  7918 sgd_solver.cpp:106] Iteration 135, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:18.064878  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:18.064899  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:18.064904  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 35
('accuracy: ', 0.0)
I0422 15:09:18.081089  7918 solver.cpp:228] Iteration 136, loss = 2.10961
I0422 15:09:18.081106  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:18.081115  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.99344 (* 1 = 1.99344 loss)
I0422 15:09:18.081120  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:18.081125  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:18.081128  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:18.081131  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:18.081136  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.112429 (* 1 = 0.112429 loss)
I0422 15:09:18.081141  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00373909 (* 1 = 0.00373909 loss)
I0422 15:09:18.081147  7918 sgd_solver.cpp:106] Iteration 136, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:09:22.370426  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:09:22.370448  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:22.370453  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 24
('accuracy: ', 0.0)
I0422 15:09:22.385984  7918 solver.cpp:228] Iteration 137, loss = 2.06984
I0422 15:09:22.386001  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:22.386008  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.01583 (* 1 = 2.01583 loss)
I0422 15:09:22.386013  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:22.386018  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:09:22.386021  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:22.386024  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:22.386029  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0436547 (* 1 = 0.0436547 loss)
I0422 15:09:22.386034  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0103566 (* 1 = 0.0103566 loss)
I0422 15:09:22.386039  7918 sgd_solver.cpp:106] Iteration 137, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:26.674098  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:26.674121  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:26.674126  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 26
('accuracy: ', 0.0)
I0422 15:09:26.689635  7918 solver.cpp:228] Iteration 138, loss = 3.27863
I0422 15:09:26.689652  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:26.689661  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.13264 (* 1 = 3.13264 loss)
I0422 15:09:26.689666  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:26.689669  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:26.689673  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:26.689677  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:26.689682  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.139778 (* 1 = 0.139778 loss)
I0422 15:09:26.689687  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00621333 (* 1 = 0.00621333 loss)
I0422 15:09:26.689692  7918 sgd_solver.cpp:106] Iteration 138, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:30.969444  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:30.969466  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:30.969472  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 15:09:30.985247  7918 solver.cpp:228] Iteration 139, loss = 2.3167
I0422 15:09:30.985265  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:30.985273  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.1852 (* 1 = 2.1852 loss)
I0422 15:09:30.985280  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:30.985282  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:30.985286  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:30.985291  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:30.985296  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.126441 (* 1 = 0.126441 loss)
I0422 15:09:30.985301  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00506129 (* 1 = 0.00506129 loss)
I0422 15:09:30.985306  7918 sgd_solver.cpp:106] Iteration 139, lr = 0.0001
speed: 4.311s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:35.278604  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:35.278625  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:35.278630  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 26
('accuracy: ', 0.0)
I0422 15:09:35.295030  7918 solver.cpp:228] Iteration 140, loss = 2.12109
I0422 15:09:35.295053  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:35.295061  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.95964 (* 1 = 1.95964 loss)
I0422 15:09:35.295066  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:35.295071  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:35.295075  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:35.295079  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:35.295084  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.158398 (* 1 = 0.158398 loss)
I0422 15:09:35.295089  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00305712 (* 1 = 0.00305712 loss)
I0422 15:09:35.295095  7918 sgd_solver.cpp:106] Iteration 140, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:39.583456  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:39.583478  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:39.583492  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 15:09:39.599035  7918 solver.cpp:228] Iteration 141, loss = 2.12676
I0422 15:09:39.599054  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:39.599062  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.96748 (* 1 = 1.96748 loss)
I0422 15:09:39.599067  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:39.599071  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:39.599076  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:39.599079  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:39.599083  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.155337 (* 1 = 0.155337 loss)
I0422 15:09:39.599088  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00393704 (* 1 = 0.00393704 loss)
I0422 15:09:39.599094  7918 sgd_solver.cpp:106] Iteration 141, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:09:43.875435  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:09:43.875468  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:43.875473  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 4
num bg: 10
('accuracy: ', 0.0)
I0422 15:09:43.887075  7918 solver.cpp:228] Iteration 142, loss = 2.55653
I0422 15:09:43.887095  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:43.887104  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.31009 (* 1 = 2.31009 loss)
I0422 15:09:43.887109  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:43.887114  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:09:43.887117  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:43.887121  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:43.887125  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.236438 (* 1 = 0.236438 loss)
I0422 15:09:43.887130  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0100044 (* 1 = 0.0100044 loss)
I0422 15:09:43.887137  7918 sgd_solver.cpp:106] Iteration 142, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:48.182020  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:48.182044  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:48.182049  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 23
('accuracy: ', 0.0)
I0422 15:09:48.197652  7918 solver.cpp:228] Iteration 143, loss = 2.39302
I0422 15:09:48.197674  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:48.197681  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.04453 (* 1 = 2.04453 loss)
I0422 15:09:48.197686  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:48.197690  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:48.197695  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:48.197697  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:48.197701  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.344217 (* 1 = 0.344217 loss)
I0422 15:09:48.197707  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00426735 (* 1 = 0.00426735 loss)
I0422 15:09:48.197712  7918 sgd_solver.cpp:106] Iteration 143, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:09:52.495529  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:09:52.495550  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:52.495566  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 15:09:52.511107  7918 solver.cpp:228] Iteration 144, loss = 2.10776
I0422 15:09:52.511127  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:52.511135  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.81883 (* 1 = 1.81883 loss)
I0422 15:09:52.511140  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:52.511144  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:09:52.511148  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:52.511152  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:52.511157  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.286025 (* 1 = 0.286025 loss)
I0422 15:09:52.511162  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00290883 (* 1 = 0.00290883 loss)
I0422 15:09:52.511168  7918 sgd_solver.cpp:106] Iteration 144, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:09:56.782344  7918 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 15:09:56.782366  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:09:56.782371  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 16
('accuracy: ', 0.0)
I0422 15:09:56.797622  7918 solver.cpp:228] Iteration 145, loss = 2.76168
I0422 15:09:56.797641  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:09:56.797648  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.48289 (* 1 = 2.48289 loss)
I0422 15:09:56.797653  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:09:56.797657  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 15:09:56.797662  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:09:56.797665  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:09:56.797670  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.270424 (* 1 = 0.270424 loss)
I0422 15:09:56.797675  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00836427 (* 1 = 0.00836427 loss)
I0422 15:09:56.797680  7918 sgd_solver.cpp:106] Iteration 145, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:10:01.097290  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:10:01.097314  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:01.097318  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 15:10:01.112753  7918 solver.cpp:228] Iteration 146, loss = 1.93196
I0422 15:10:01.112771  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:01.112778  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.64458 (* 1 = 1.64458 loss)
I0422 15:10:01.112783  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:01.112787  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:10:01.112792  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:01.112795  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:01.112800  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.283798 (* 1 = 0.283798 loss)
I0422 15:10:01.112805  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00357861 (* 1 = 0.00357861 loss)
I0422 15:10:01.112810  7918 sgd_solver.cpp:106] Iteration 146, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 15:10:05.408310  7918 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 15:10:05.408339  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:05.408344  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 11
num bg: 21
('accuracy: ', 0.0)
I0422 15:10:05.423862  7918 solver.cpp:228] Iteration 147, loss = 3.1894
I0422 15:10:05.423888  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:05.423897  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.88024 (* 1 = 2.88024 loss)
I0422 15:10:05.423902  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:05.423905  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 15:10:05.423909  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:05.423913  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:05.423918  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.296869 (* 1 = 0.296869 loss)
I0422 15:10:05.423923  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0122913 (* 1 = 0.0122913 loss)
I0422 15:10:05.423928  7918 sgd_solver.cpp:106] Iteration 147, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:10:09.695713  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:10:09.695735  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:09.695739  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 15:10:09.711077  7918 solver.cpp:228] Iteration 148, loss = 2.03105
I0422 15:10:09.711105  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:09.711122  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.7365 (* 1 = 1.7365 loss)
I0422 15:10:09.711138  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:09.711141  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:10:09.711145  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:09.711148  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:09.711153  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.289851 (* 1 = 0.289851 loss)
I0422 15:10:09.711158  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0046949 (* 1 = 0.0046949 loss)
I0422 15:10:09.711164  7918 sgd_solver.cpp:106] Iteration 148, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:10:13.974324  7918 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 15:10:13.974346  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:13.974350  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 16
('accuracy: ', 0.0)
I0422 15:10:13.990725  7918 solver.cpp:228] Iteration 149, loss = 2.84271
I0422 15:10:13.990746  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:13.990753  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.58082 (* 1 = 2.58082 loss)
I0422 15:10:13.990758  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:13.990788  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 15:10:13.990795  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:13.990798  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:13.990803  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.252331 (* 1 = 0.252331 loss)
I0422 15:10:13.990811  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00954905 (* 1 = 0.00954905 loss)
I0422 15:10:13.990818  7918 sgd_solver.cpp:106] Iteration 149, lr = 0.0001
speed: 4.310s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:10:18.283633  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:10:18.283655  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:18.283659  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 15:10:18.299008  7918 solver.cpp:228] Iteration 150, loss = 1.77708
I0422 15:10:18.299029  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:18.299037  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.57 (* 1 = 1.57 loss)
I0422 15:10:18.299042  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:18.299046  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:10:18.299051  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:18.299054  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:18.299058  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.203225 (* 1 = 0.203225 loss)
I0422 15:10:18.299064  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00386326 (* 1 = 0.00386326 loss)
I0422 15:10:18.299069  7918 sgd_solver.cpp:106] Iteration 150, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:10:22.590082  7918 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 15:10:22.590104  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:22.590108  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 26
('accuracy: ', 0.0)
I0422 15:10:22.605763  7918 solver.cpp:228] Iteration 151, loss = 2.23368
I0422 15:10:22.605782  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:22.605790  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.03941 (* 1 = 2.03941 loss)
I0422 15:10:22.605795  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:22.605798  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 15:10:22.605803  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:22.605806  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:22.605810  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.185732 (* 1 = 0.185732 loss)
I0422 15:10:22.605815  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00854131 (* 1 = 0.00854131 loss)
I0422 15:10:22.605821  7918 sgd_solver.cpp:106] Iteration 151, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:10:26.887285  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:10:26.887308  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:26.887313  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 15:10:26.902858  7918 solver.cpp:228] Iteration 152, loss = 2.42738
I0422 15:10:26.902874  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:26.902882  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.2537 (* 1 = 2.2537 loss)
I0422 15:10:26.902887  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:26.902891  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:10:26.902895  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:26.902899  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:26.902904  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.168581 (* 1 = 0.168581 loss)
I0422 15:10:26.902909  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00509663 (* 1 = 0.00509663 loss)
I0422 15:10:26.902914  7918 sgd_solver.cpp:106] Iteration 152, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:10:31.201653  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:10:31.201673  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:31.201689  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 15:10:31.217249  7918 solver.cpp:228] Iteration 153, loss = 2.20834
I0422 15:10:31.217277  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:31.217284  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.09337 (* 1 = 2.09337 loss)
I0422 15:10:31.217289  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:31.217293  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:10:31.217298  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:31.217301  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:31.217305  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.111163 (* 1 = 0.111163 loss)
I0422 15:10:31.217310  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0038044 (* 1 = 0.0038044 loss)
I0422 15:10:31.217316  7918 sgd_solver.cpp:106] Iteration 153, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:10:35.501947  7918 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 15:10:35.501971  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:35.501974  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 22
('accuracy: ', 0.0)
I0422 15:10:35.517515  7918 solver.cpp:228] Iteration 154, loss = 2.12477
I0422 15:10:35.517532  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:35.517540  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.02658 (* 1 = 2.02658 loss)
I0422 15:10:35.517545  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:35.517549  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 15:10:35.517554  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:35.517556  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:35.517561  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0904194 (* 1 = 0.0904194 loss)
I0422 15:10:35.517566  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00776977 (* 1 = 0.00776977 loss)
I0422 15:10:35.517571  7918 sgd_solver.cpp:106] Iteration 154, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:10:39.782953  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:10:39.782974  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:39.782979  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 6
num bg: 24
('accuracy: ', 0.0)
I0422 15:10:39.798357  7918 solver.cpp:228] Iteration 155, loss = 1.5114
I0422 15:10:39.798375  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:39.798383  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.45407 (* 1 = 1.45407 loss)
I0422 15:10:39.798389  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:39.798393  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:10:39.798396  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:39.798400  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:39.798405  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0471303 (* 1 = 0.0471303 loss)
I0422 15:10:39.798409  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0102013 (* 1 = 0.0102013 loss)
I0422 15:10:39.798416  7918 sgd_solver.cpp:106] Iteration 155, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:10:44.069232  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:10:44.069254  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:44.069259  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 15:10:44.084903  7918 solver.cpp:228] Iteration 156, loss = 2.29388
I0422 15:10:44.084921  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:44.084929  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.18859 (* 1 = 2.18859 loss)
I0422 15:10:44.084934  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:44.084939  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:10:44.084944  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:44.084946  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:44.084951  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.101772 (* 1 = 0.101772 loss)
I0422 15:10:44.084956  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00351469 (* 1 = 0.00351469 loss)
I0422 15:10:44.084962  7918 sgd_solver.cpp:106] Iteration 156, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:10:48.381170  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:10:48.381191  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:48.381196  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 15:10:48.397012  7918 solver.cpp:228] Iteration 157, loss = 2.33297
I0422 15:10:48.397037  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:48.397044  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.19669 (* 1 = 2.19669 loss)
I0422 15:10:48.397050  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:48.397054  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:10:48.397058  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:48.397061  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:48.397066  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.129924 (* 1 = 0.129924 loss)
I0422 15:10:48.397071  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00635751 (* 1 = 0.00635751 loss)
I0422 15:10:48.397076  7918 sgd_solver.cpp:106] Iteration 157, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:10:52.682193  7918 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 15:10:52.682214  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:52.682219  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 15:10:52.697988  7918 solver.cpp:228] Iteration 158, loss = 2.26721
I0422 15:10:52.698014  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:52.698047  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.19771 (* 1 = 2.19771 loss)
I0422 15:10:52.698071  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:52.698081  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 15:10:52.698103  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:52.698124  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:52.698140  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0609322 (* 1 = 0.0609322 loss)
I0422 15:10:52.698173  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00857674 (* 1 = 0.00857674 loss)
I0422 15:10:52.698199  7918 sgd_solver.cpp:106] Iteration 158, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:10:56.979259  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:10:56.979281  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:10:56.979286  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 15:10:56.994664  7918 solver.cpp:228] Iteration 159, loss = 2.20157
I0422 15:10:56.994681  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:10:56.994689  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.0933 (* 1 = 2.0933 loss)
I0422 15:10:56.994695  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:10:56.994699  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:10:56.994704  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:10:56.994707  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:10:56.994711  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.105918 (* 1 = 0.105918 loss)
I0422 15:10:56.994716  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00235414 (* 1 = 0.00235414 loss)
I0422 15:10:56.994722  7918 sgd_solver.cpp:106] Iteration 159, lr = 0.0001
speed: 4.310s / iter
rpn: num_positive 3
rpn: num_negative 61
I0422 15:11:01.261759  7918 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 15:11:01.261781  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:01.261786  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 15:11:01.278528  7918 solver.cpp:228] Iteration 160, loss = 2.47307
I0422 15:11:01.278549  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:01.278558  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.37499 (* 1 = 2.37499 loss)
I0422 15:11:01.278564  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:01.278568  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 15:11:01.278573  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:01.278576  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:01.278581  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0897387 (* 1 = 0.0897387 loss)
I0422 15:11:01.278587  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00834065 (* 1 = 0.00834065 loss)
I0422 15:11:01.278594  7918 sgd_solver.cpp:106] Iteration 160, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:11:05.584501  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:11:05.584522  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:05.584527  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 3
num bg: 7
('accuracy: ', 0.0)
I0422 15:11:05.594604  7918 solver.cpp:228] Iteration 161, loss = 2.69201
I0422 15:11:05.594624  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:05.594633  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.6547 (* 1 = 2.6547 loss)
I0422 15:11:05.594638  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:05.594645  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:11:05.594650  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:05.594655  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:05.594661  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0262584 (* 1 = 0.0262584 loss)
I0422 15:11:05.594666  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.011054 (* 1 = 0.011054 loss)
I0422 15:11:05.594676  7918 sgd_solver.cpp:106] Iteration 161, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:09.876857  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:09.876878  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:09.876883  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 15:11:09.892400  7918 solver.cpp:228] Iteration 162, loss = 1.9641
I0422 15:11:09.892417  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:09.892426  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.83687 (* 1 = 1.83687 loss)
I0422 15:11:09.892431  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:09.892436  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:09.892439  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:09.892442  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:09.892447  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.121507 (* 1 = 0.121507 loss)
I0422 15:11:09.892452  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00572222 (* 1 = 0.00572222 loss)
I0422 15:11:09.892457  7918 sgd_solver.cpp:106] Iteration 162, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:14.185374  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:14.185395  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:14.185400  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 15:11:14.200947  7918 solver.cpp:228] Iteration 163, loss = 2.04785
I0422 15:11:14.200963  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:14.200971  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.88184 (* 1 = 1.88184 loss)
I0422 15:11:14.200976  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:14.200979  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:14.200985  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:14.200989  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:14.200992  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.156902 (* 1 = 0.156902 loss)
I0422 15:11:14.200997  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00910605 (* 1 = 0.00910605 loss)
I0422 15:11:14.201004  7918 sgd_solver.cpp:106] Iteration 163, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:18.478217  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:18.478238  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:18.478243  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 11
num bg: 28
('accuracy: ', 0.0)
I0422 15:11:18.493733  7918 solver.cpp:228] Iteration 164, loss = 2.56447
I0422 15:11:18.493751  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:18.493757  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.46079 (* 1 = 2.46079 loss)
I0422 15:11:18.493762  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:18.493767  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:18.493770  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:18.493773  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:18.493779  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.100323 (* 1 = 0.100323 loss)
I0422 15:11:18.493784  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00335603 (* 1 = 0.00335603 loss)
I0422 15:11:18.493789  7918 sgd_solver.cpp:106] Iteration 164, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:22.758378  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:22.758399  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:22.758404  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 15:11:22.773758  7918 solver.cpp:228] Iteration 165, loss = 2.35169
I0422 15:11:22.773787  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:22.773794  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.19257 (* 1 = 2.19257 loss)
I0422 15:11:22.773799  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:22.773803  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:22.773808  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:22.773811  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:22.773816  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.154205 (* 1 = 0.154205 loss)
I0422 15:11:22.773821  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00490838 (* 1 = 0.00490838 loss)
I0422 15:11:22.773826  7918 sgd_solver.cpp:106] Iteration 165, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:27.077857  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:27.077879  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:27.077883  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 6
num bg: 28
('accuracy: ', 0.0)
I0422 15:11:27.093495  7918 solver.cpp:228] Iteration 166, loss = 1.66117
I0422 15:11:27.093516  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:27.093524  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.51829 (* 1 = 1.51829 loss)
I0422 15:11:27.093529  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:27.093533  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:27.093538  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:27.093541  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:27.093545  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.138647 (* 1 = 0.138647 loss)
I0422 15:11:27.093550  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00422599 (* 1 = 0.00422599 loss)
I0422 15:11:27.093556  7918 sgd_solver.cpp:106] Iteration 166, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:31.388198  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:31.388221  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:31.388226  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 15:11:31.404973  7918 solver.cpp:228] Iteration 167, loss = 1.75482
I0422 15:11:31.405002  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:31.405016  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.6305 (* 1 = 1.6305 loss)
I0422 15:11:31.405027  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:31.405035  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:31.405041  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:31.405047  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:31.405056  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.120169 (* 1 = 0.120169 loss)
I0422 15:11:31.405066  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00415214 (* 1 = 0.00415214 loss)
I0422 15:11:31.405074  7918 sgd_solver.cpp:106] Iteration 167, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:35.673274  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:35.673293  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:35.673297  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 15:11:35.688657  7918 solver.cpp:228] Iteration 168, loss = 2.24973
I0422 15:11:35.688678  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:35.688685  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.08135 (* 1 = 2.08135 loss)
I0422 15:11:35.688690  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:35.688694  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:35.688699  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:35.688704  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:35.688707  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.163944 (* 1 = 0.163944 loss)
I0422 15:11:35.688712  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00443635 (* 1 = 0.00443635 loss)
I0422 15:11:35.688719  7918 sgd_solver.cpp:106] Iteration 168, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:39.981297  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:39.981319  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:39.981324  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 27
('accuracy: ', 0.0)
I0422 15:11:39.997422  7918 solver.cpp:228] Iteration 169, loss = 2.36355
I0422 15:11:39.997453  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:39.997462  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.16811 (* 1 = 2.16811 loss)
I0422 15:11:39.997467  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:39.997470  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:39.997474  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:39.997478  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:39.997483  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.189155 (* 1 = 0.189155 loss)
I0422 15:11:39.997486  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00628274 (* 1 = 0.00628274 loss)
I0422 15:11:39.997493  7918 sgd_solver.cpp:106] Iteration 169, lr = 0.0001
speed: 4.309s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:44.298987  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:44.299008  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:44.299015  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 15:11:44.314512  7918 solver.cpp:228] Iteration 170, loss = 1.89813
I0422 15:11:44.314530  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:44.314548  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.74875 (* 1 = 1.74875 loss)
I0422 15:11:44.314564  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:44.314568  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:44.314571  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:44.314574  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:44.314579  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.144303 (* 1 = 0.144303 loss)
I0422 15:11:44.314584  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00508097 (* 1 = 0.00508097 loss)
I0422 15:11:44.314589  7918 sgd_solver.cpp:106] Iteration 170, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:48.581131  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:48.581162  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:48.581167  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 15:11:48.596506  7918 solver.cpp:228] Iteration 171, loss = 2.01066
I0422 15:11:48.596525  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:48.596534  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.84804 (* 1 = 1.84804 loss)
I0422 15:11:48.596539  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:48.596541  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:48.596545  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:48.596549  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:48.596554  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.158557 (* 1 = 0.158557 loss)
I0422 15:11:48.596559  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00405969 (* 1 = 0.00405969 loss)
I0422 15:11:48.596565  7918 sgd_solver.cpp:106] Iteration 171, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:52.881104  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:52.881126  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:52.881130  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 30
('accuracy: ', 0.0)
I0422 15:11:52.897586  7918 solver.cpp:228] Iteration 172, loss = 1.91967
I0422 15:11:52.897608  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:52.897616  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.76213 (* 1 = 1.76213 loss)
I0422 15:11:52.897621  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:52.897625  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:52.897630  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:52.897635  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:52.897639  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.153466 (* 1 = 0.153466 loss)
I0422 15:11:52.897644  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00407477 (* 1 = 0.00407477 loss)
I0422 15:11:52.897650  7918 sgd_solver.cpp:106] Iteration 172, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:11:57.184731  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:11:57.184752  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:11:57.184757  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 15:11:57.200424  7918 solver.cpp:228] Iteration 173, loss = 2.50111
I0422 15:11:57.200443  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:11:57.200450  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.23476 (* 1 = 2.23476 loss)
I0422 15:11:57.200455  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:11:57.200459  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:11:57.200464  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:11:57.200467  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:11:57.200471  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.262232 (* 1 = 0.262232 loss)
I0422 15:11:57.200476  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0041198 (* 1 = 0.0041198 loss)
I0422 15:11:57.200482  7918 sgd_solver.cpp:106] Iteration 173, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:12:01.500247  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:12:01.500274  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:01.500282  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 15:12:01.516168  7918 solver.cpp:228] Iteration 174, loss = 2.4685
I0422 15:12:01.516185  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:01.516193  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.25433 (* 1 = 2.25433 loss)
I0422 15:12:01.516198  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:01.516202  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:12:01.516206  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:01.516211  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:01.516214  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.209403 (* 1 = 0.209403 loss)
I0422 15:12:01.516219  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0047686 (* 1 = 0.0047686 loss)
I0422 15:12:01.516224  7918 sgd_solver.cpp:106] Iteration 174, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:12:05.808749  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:12:05.808773  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:05.808779  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 11
num bg: 30
('accuracy: ', 0.0)
I0422 15:12:05.824779  7918 solver.cpp:228] Iteration 175, loss = 2.02437
I0422 15:12:05.824795  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:05.824806  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.87944 (* 1 = 1.87944 loss)
I0422 15:12:05.824815  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:05.824818  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:12:05.824822  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:05.824826  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:05.824831  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.140938 (* 1 = 0.140938 loss)
I0422 15:12:05.824836  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00398954 (* 1 = 0.00398954 loss)
I0422 15:12:05.824841  7918 sgd_solver.cpp:106] Iteration 175, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:12:10.098943  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:12:10.098964  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:10.098969  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 31
('accuracy: ', 0.0)
I0422 15:12:10.114984  7918 solver.cpp:228] Iteration 176, loss = 1.38201
I0422 15:12:10.115000  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:10.115007  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.18098 (* 1 = 1.18098 loss)
I0422 15:12:10.115012  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:10.115015  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:12:10.115020  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:10.115025  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:10.115032  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.196577 (* 1 = 0.196577 loss)
I0422 15:12:10.115041  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00445186 (* 1 = 0.00445186 loss)
I0422 15:12:10.115048  7918 sgd_solver.cpp:106] Iteration 176, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:12:14.392253  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:12:14.392278  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:14.392284  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 15:12:14.408637  7918 solver.cpp:228] Iteration 177, loss = 2.28026
I0422 15:12:14.408666  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:14.408674  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.09541 (* 1 = 2.09541 loss)
I0422 15:12:14.408680  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:14.408686  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:12:14.408694  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:14.408697  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:14.408702  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.179663 (* 1 = 0.179663 loss)
I0422 15:12:14.408707  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00517923 (* 1 = 0.00517923 loss)
I0422 15:12:14.408713  7918 sgd_solver.cpp:106] Iteration 177, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:12:18.682505  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:12:18.682525  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:18.682539  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 27
('accuracy: ', 0.0)
I0422 15:12:18.697806  7918 solver.cpp:228] Iteration 178, loss = 2.11773
I0422 15:12:18.697823  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:18.697835  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.98387 (* 1 = 1.98387 loss)
I0422 15:12:18.697844  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:18.697849  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:12:18.697852  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:18.697856  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:18.697866  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.128626 (* 1 = 0.128626 loss)
I0422 15:12:18.697871  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00522641 (* 1 = 0.00522641 loss)
I0422 15:12:18.697892  7918 sgd_solver.cpp:106] Iteration 178, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 15:12:22.987414  7918 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 15:12:22.987437  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:22.987440  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 15:12:23.003113  7918 solver.cpp:228] Iteration 179, loss = 2.00569
I0422 15:12:23.003130  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:23.003139  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.87693 (* 1 = 1.87693 loss)
I0422 15:12:23.003144  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:23.003147  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 15:12:23.003151  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:23.003154  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:23.003159  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.127286 (* 1 = 0.127286 loss)
I0422 15:12:23.003163  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00147754 (* 1 = 0.00147754 loss)
I0422 15:12:23.003168  7918 sgd_solver.cpp:106] Iteration 179, lr = 0.0001
speed: 4.309s / iter
rpn: num_positive 1
rpn: num_negative 63
I0422 15:12:27.298449  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:12:27.298472  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:27.298476  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 2
num bg: 11
('accuracy: ', 0.0)
I0422 15:12:27.310143  7918 solver.cpp:228] Iteration 180, loss = 1.54835
I0422 15:12:27.310166  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:27.310180  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.47117 (* 1 = 1.47117 loss)
I0422 15:12:27.310189  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:27.310194  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:12:27.310197  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:27.310201  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:27.310205  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0658305 (* 1 = 0.0658305 loss)
I0422 15:12:27.310210  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0113465 (* 1 = 0.0113465 loss)
I0422 15:12:27.310216  7918 sgd_solver.cpp:106] Iteration 180, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:12:31.600106  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:12:31.600127  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:31.600132  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 4
num bg: 17
('accuracy: ', 0.0)
I0422 15:12:31.615553  7918 solver.cpp:228] Iteration 181, loss = 1.63533
I0422 15:12:31.615582  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:31.615591  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.54041 (* 1 = 1.54041 loss)
I0422 15:12:31.615595  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:31.615600  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:12:31.615607  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:31.615612  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:31.615620  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0872412 (* 1 = 0.0872412 loss)
I0422 15:12:31.615629  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00768273 (* 1 = 0.00768273 loss)
I0422 15:12:31.615638  7918 sgd_solver.cpp:106] Iteration 181, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:12:35.893051  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:12:35.893071  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:35.893087  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 32
('accuracy: ', 0.0)
I0422 15:12:35.908843  7918 solver.cpp:228] Iteration 182, loss = 1.87835
I0422 15:12:35.908859  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:35.908866  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.77255 (* 1 = 1.77255 loss)
I0422 15:12:35.908871  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:35.908875  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:12:35.908879  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:35.908884  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:35.908887  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.102549 (* 1 = 0.102549 loss)
I0422 15:12:35.908892  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00324792 (* 1 = 0.00324792 loss)
I0422 15:12:35.908898  7918 sgd_solver.cpp:106] Iteration 182, lr = 0.0001
rpn: num_positive 3
rpn: num_negative 61
I0422 15:12:40.211622  7918 accuracy_layer.cpp:96] Accuracy: 0.953125
I0422 15:12:40.211647  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:40.211650  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 5
num bg: 17
('accuracy: ', 0.0)
I0422 15:12:40.227067  7918 solver.cpp:228] Iteration 183, loss = 2.08355
I0422 15:12:40.227084  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:40.227092  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.97701 (* 1 = 1.97701 loss)
I0422 15:12:40.227098  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:40.227103  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.953125
I0422 15:12:40.227108  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:40.227113  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:40.227118  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0989388 (* 1 = 0.0989388 loss)
I0422 15:12:40.227123  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0076052 (* 1 = 0.0076052 loss)
I0422 15:12:40.227129  7918 sgd_solver.cpp:106] Iteration 183, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:12:44.503494  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:12:44.503517  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:44.503521  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 13
('accuracy: ', 0.0)
I0422 15:12:44.518893  7918 solver.cpp:228] Iteration 184, loss = 3.09016
I0422 15:12:44.518909  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:44.518918  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.04388 (* 1 = 3.04388 loss)
I0422 15:12:44.518923  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:44.518931  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:12:44.518935  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:44.518942  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:44.518946  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0341165 (* 1 = 0.0341165 loss)
I0422 15:12:44.518954  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0121619 (* 1 = 0.0121619 loss)
I0422 15:12:44.518959  7918 sgd_solver.cpp:106] Iteration 184, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:12:48.783828  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:12:48.783849  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:48.783854  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 33
('accuracy: ', 0.0)
I0422 15:12:48.799705  7918 solver.cpp:228] Iteration 185, loss = 1.97076
I0422 15:12:48.799726  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:48.799733  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.86874 (* 1 = 1.86874 loss)
I0422 15:12:48.799738  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:48.799742  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:12:48.799746  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:48.799751  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:48.799754  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.098256 (* 1 = 0.098256 loss)
I0422 15:12:48.799759  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00375813 (* 1 = 0.00375813 loss)
I0422 15:12:48.799764  7918 sgd_solver.cpp:106] Iteration 185, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:12:53.072139  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:12:53.072166  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:53.072175  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 31
('accuracy: ', 0.0)
I0422 15:12:53.087910  7918 solver.cpp:228] Iteration 186, loss = 2.18503
I0422 15:12:53.087929  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:53.087936  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.08875 (* 1 = 2.08875 loss)
I0422 15:12:53.087941  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:53.087945  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:12:53.087949  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:53.087954  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:53.087960  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0927449 (* 1 = 0.0927449 loss)
I0422 15:12:53.087965  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00353463 (* 1 = 0.00353463 loss)
I0422 15:12:53.087971  7918 sgd_solver.cpp:106] Iteration 186, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:12:57.375722  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:12:57.375748  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:12:57.375756  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 15:12:57.391633  7918 solver.cpp:228] Iteration 187, loss = 1.96464
I0422 15:12:57.391651  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:12:57.391659  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.84699 (* 1 = 1.84699 loss)
I0422 15:12:57.391664  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:12:57.391669  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:12:57.391672  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:12:57.391675  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:12:57.391680  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.11373 (* 1 = 0.11373 loss)
I0422 15:12:57.391685  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00392452 (* 1 = 0.00392452 loss)
I0422 15:12:57.391690  7918 sgd_solver.cpp:106] Iteration 187, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:13:01.697371  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:13:01.697391  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:01.697396  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 5
num bg: 14
('accuracy: ', 0.0)
I0422 15:13:01.712182  7918 solver.cpp:228] Iteration 188, loss = 2.48741
I0422 15:13:01.712209  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:01.712218  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.41896 (* 1 = 2.41896 loss)
I0422 15:13:01.712224  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:01.712227  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:13:01.712231  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:01.712234  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:01.712239  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0643436 (* 1 = 0.0643436 loss)
I0422 15:13:01.712244  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00410804 (* 1 = 0.00410804 loss)
I0422 15:13:01.712250  7918 sgd_solver.cpp:106] Iteration 188, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:13:06.003198  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:13:06.003231  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:06.003235  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 21
('accuracy: ', 0.0)
I0422 15:13:06.018865  7918 solver.cpp:228] Iteration 189, loss = 1.94723
I0422 15:13:06.018882  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:06.018890  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.88591 (* 1 = 1.88591 loss)
I0422 15:13:06.018895  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:06.018899  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:13:06.018903  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:06.018908  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:06.018911  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0583201 (* 1 = 0.0583201 loss)
I0422 15:13:06.018916  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0029968 (* 1 = 0.0029968 loss)
I0422 15:13:06.018923  7918 sgd_solver.cpp:106] Iteration 189, lr = 0.0001
speed: 4.308s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:13:10.286610  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:13:10.286638  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:10.286645  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 30
('accuracy: ', 0.0)
I0422 15:13:10.302335  7918 solver.cpp:228] Iteration 190, loss = 2.49747
I0422 15:13:10.302356  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:10.302364  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.37727 (* 1 = 2.37727 loss)
I0422 15:13:10.302369  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:10.302373  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:13:10.302377  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:10.302381  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:10.302386  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.115894 (* 1 = 0.115894 loss)
I0422 15:13:10.302392  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00430288 (* 1 = 0.00430288 loss)
I0422 15:13:10.302397  7918 sgd_solver.cpp:106] Iteration 190, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:13:14.585407  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:13:14.585427  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:14.585443  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 28
('accuracy: ', 0.0)
I0422 15:13:14.601204  7918 solver.cpp:228] Iteration 191, loss = 2.23892
I0422 15:13:14.601220  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:14.601229  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.11702 (* 1 = 2.11702 loss)
I0422 15:13:14.601234  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:14.601238  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:13:14.601243  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:14.601245  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:14.601250  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.117402 (* 1 = 0.117402 loss)
I0422 15:13:14.601261  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00450228 (* 1 = 0.00450228 loss)
I0422 15:13:14.601267  7918 sgd_solver.cpp:106] Iteration 191, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:13:18.904569  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:13:18.904590  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:18.904594  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 15:13:18.920644  7918 solver.cpp:228] Iteration 192, loss = 1.58873
I0422 15:13:18.920673  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:18.920681  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.48166 (* 1 = 1.48166 loss)
I0422 15:13:18.920686  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:18.920691  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:13:18.920694  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:18.920699  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:18.920707  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.101806 (* 1 = 0.101806 loss)
I0422 15:13:18.920713  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0052641 (* 1 = 0.0052641 loss)
I0422 15:13:18.920719  7918 sgd_solver.cpp:106] Iteration 192, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:13:23.197490  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:13:23.197522  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:23.197526  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 4
num bg: 8
('accuracy: ', 0.0)
I0422 15:13:23.208608  7918 solver.cpp:228] Iteration 193, loss = 2.96754
I0422 15:13:23.208636  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:23.208644  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.88465 (* 1 = 2.88465 loss)
I0422 15:13:23.208649  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:23.208653  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:13:23.208657  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:23.208662  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:23.208665  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0755027 (* 1 = 0.0755027 loss)
I0422 15:13:23.208670  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00737967 (* 1 = 0.00737967 loss)
I0422 15:13:23.208676  7918 sgd_solver.cpp:106] Iteration 193, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:13:27.501143  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:13:27.501164  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:27.501168  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 15:13:27.517366  7918 solver.cpp:228] Iteration 194, loss = 2.17147
I0422 15:13:27.517383  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:27.517391  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.05416 (* 1 = 2.05416 loss)
I0422 15:13:27.517396  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:27.517400  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:13:27.517405  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:27.517407  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:27.517412  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.113 (* 1 = 0.113 loss)
I0422 15:13:27.517417  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00431086 (* 1 = 0.00431086 loss)
I0422 15:13:27.517422  7918 sgd_solver.cpp:106] Iteration 194, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:13:31.811517  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:13:31.811539  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:31.811547  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 32
('accuracy: ', 0.0)
I0422 15:13:31.827572  7918 solver.cpp:228] Iteration 195, loss = 2.01828
I0422 15:13:31.827592  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:31.827600  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.90865 (* 1 = 1.90865 loss)
I0422 15:13:31.827605  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:31.827610  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:13:31.827613  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:31.827617  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:31.827621  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.103597 (* 1 = 0.103597 loss)
I0422 15:13:31.827626  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00602887 (* 1 = 0.00602887 loss)
I0422 15:13:31.827632  7918 sgd_solver.cpp:106] Iteration 195, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:13:36.117367  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:13:36.117388  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:36.117393  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 15:13:36.132895  7918 solver.cpp:228] Iteration 196, loss = 1.94817
I0422 15:13:36.132912  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:36.132920  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.81059 (* 1 = 1.81059 loss)
I0422 15:13:36.132925  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:36.132930  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:13:36.132933  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:36.132937  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:36.132942  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.134479 (* 1 = 0.134479 loss)
I0422 15:13:36.132947  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00310526 (* 1 = 0.00310526 loss)
I0422 15:13:36.132953  7918 sgd_solver.cpp:106] Iteration 196, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:13:40.420970  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:13:40.420991  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:40.420996  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 6
num bg: 25
('accuracy: ', 0.0)
I0422 15:13:40.437048  7918 solver.cpp:228] Iteration 197, loss = 1.74393
I0422 15:13:40.437067  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:40.437074  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.68862 (* 1 = 1.68862 loss)
I0422 15:13:40.437079  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:40.437083  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:13:40.437088  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:40.437091  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:40.437095  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0528979 (* 1 = 0.0528979 loss)
I0422 15:13:40.437100  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00241383 (* 1 = 0.00241383 loss)
I0422 15:13:40.437115  7918 sgd_solver.cpp:106] Iteration 197, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:13:44.716292  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:13:44.716315  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:44.716325  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 26
('accuracy: ', 0.0)
I0422 15:13:44.731853  7918 solver.cpp:228] Iteration 198, loss = 1.7323
I0422 15:13:44.731870  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:44.731879  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.57634 (* 1 = 1.57634 loss)
I0422 15:13:44.731884  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:44.731889  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:13:44.731892  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:44.731895  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:44.731901  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.152641 (* 1 = 0.152641 loss)
I0422 15:13:44.731905  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00331843 (* 1 = 0.00331843 loss)
I0422 15:13:44.731911  7918 sgd_solver.cpp:106] Iteration 198, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:13:49.042251  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:13:49.042273  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:49.042279  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 15:13:49.057891  7918 solver.cpp:228] Iteration 199, loss = 2.2941
I0422 15:13:49.057909  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:49.057926  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.18935 (* 1 = 2.18935 loss)
I0422 15:13:49.057931  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:49.057934  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:13:49.057938  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:49.057942  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:49.057946  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.101147 (* 1 = 0.101147 loss)
I0422 15:13:49.057951  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00361068 (* 1 = 0.00361068 loss)
I0422 15:13:49.057956  7918 sgd_solver.cpp:106] Iteration 199, lr = 0.0001
speed: 4.308s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:13:53.342510  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:13:53.342531  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:53.342535  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 31
('accuracy: ', 0.0)
I0422 15:13:53.358500  7918 solver.cpp:228] Iteration 200, loss = 2.2856
I0422 15:13:53.358520  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:53.358530  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.15971 (* 1 = 2.15971 loss)
I0422 15:13:53.358534  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:53.358538  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:13:53.358543  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:53.358547  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:53.358551  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.122237 (* 1 = 0.122237 loss)
I0422 15:13:53.358556  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0036506 (* 1 = 0.0036506 loss)
I0422 15:13:53.358562  7918 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:13:57.639175  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:13:57.639197  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:13:57.639201  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 29
('accuracy: ', 0.0)
I0422 15:13:57.655449  7918 solver.cpp:228] Iteration 201, loss = 2.07571
I0422 15:13:57.655468  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:13:57.655477  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.97292 (* 1 = 1.97292 loss)
I0422 15:13:57.655481  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:13:57.655485  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:13:57.655489  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:13:57.655493  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:13:57.655498  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.100156 (* 1 = 0.100156 loss)
I0422 15:13:57.655506  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00263823 (* 1 = 0.00263823 loss)
I0422 15:13:57.655513  7918 sgd_solver.cpp:106] Iteration 201, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:01.929175  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:01.929208  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:01.929211  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 30
('accuracy: ', 0.0)
I0422 15:14:01.944795  7918 solver.cpp:228] Iteration 202, loss = 1.80791
I0422 15:14:01.944813  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:01.944820  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.67418 (* 1 = 1.67418 loss)
I0422 15:14:01.944825  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:01.944829  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:01.944844  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:01.944846  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:01.944851  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.122767 (* 1 = 0.122767 loss)
I0422 15:14:01.944855  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0109591 (* 1 = 0.0109591 loss)
I0422 15:14:01.944860  7918 sgd_solver.cpp:106] Iteration 202, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:06.228715  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:06.228737  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:06.228742  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 28
('accuracy: ', 0.0)
I0422 15:14:06.244352  7918 solver.cpp:228] Iteration 203, loss = 2.58622
I0422 15:14:06.244374  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:06.244382  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.4541 (* 1 = 2.4541 loss)
I0422 15:14:06.244387  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:06.244391  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:06.244395  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:06.244398  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:06.244402  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.127884 (* 1 = 0.127884 loss)
I0422 15:14:06.244407  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00423216 (* 1 = 0.00423216 loss)
I0422 15:14:06.244413  7918 sgd_solver.cpp:106] Iteration 203, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:10.531468  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:10.531489  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:10.531493  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 27
('accuracy: ', 0.0)
I0422 15:14:10.547204  7918 solver.cpp:228] Iteration 204, loss = 2.31529
I0422 15:14:10.547222  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:10.547230  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.21321 (* 1 = 2.21321 loss)
I0422 15:14:10.547235  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:10.547240  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:10.547243  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:10.547247  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:10.547252  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0994541 (* 1 = 0.0994541 loss)
I0422 15:14:10.547257  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00262087 (* 1 = 0.00262087 loss)
I0422 15:14:10.547262  7918 sgd_solver.cpp:106] Iteration 204, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:14:14.826001  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:14:14.826025  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:14.826028  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 22
('accuracy: ', 0.0)
I0422 15:14:14.841773  7918 solver.cpp:228] Iteration 205, loss = 1.99549
I0422 15:14:14.841789  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:14.841797  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.945 (* 1 = 1.945 loss)
I0422 15:14:14.841802  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:14.841806  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.984375
I0422 15:14:14.841810  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:14.841814  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:14.841819  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0463406 (* 1 = 0.0463406 loss)
I0422 15:14:14.841823  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00414555 (* 1 = 0.00414555 loss)
I0422 15:14:14.841828  7918 sgd_solver.cpp:106] Iteration 205, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:19.135679  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:19.135701  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:19.135716  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 7
num bg: 31
('accuracy: ', 0.0)
I0422 15:14:19.151592  7918 solver.cpp:228] Iteration 206, loss = 1.79494
I0422 15:14:19.151609  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:19.151624  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.66061 (* 1 = 1.66061 loss)
I0422 15:14:19.151630  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:19.151634  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:19.151638  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:19.151641  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:19.151646  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.130486 (* 1 = 0.130486 loss)
I0422 15:14:19.151651  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00384666 (* 1 = 0.00384666 loss)
I0422 15:14:19.151657  7918 sgd_solver.cpp:106] Iteration 206, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:23.447211  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:23.447234  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:23.447238  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 29
('accuracy: ', 0.0)
I0422 15:14:23.462846  7918 solver.cpp:228] Iteration 207, loss = 1.95347
I0422 15:14:23.462865  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:23.462872  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.82283 (* 1 = 1.82283 loss)
I0422 15:14:23.462878  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:23.462882  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:23.462885  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:23.462890  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:23.462895  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.126159 (* 1 = 0.126159 loss)
I0422 15:14:23.462900  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0044885 (* 1 = 0.0044885 loss)
I0422 15:14:23.462906  7918 sgd_solver.cpp:106] Iteration 207, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:27.742101  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:27.742133  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:27.742137  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 6
num bg: 30
('accuracy: ', 0.0)
I0422 15:14:27.757735  7918 solver.cpp:228] Iteration 208, loss = 1.39907
I0422 15:14:27.757751  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:27.757761  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.27689 (* 1 = 1.27689 loss)
I0422 15:14:27.757766  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:27.757769  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:27.757773  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:27.757776  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:27.757781  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.118701 (* 1 = 0.118701 loss)
I0422 15:14:27.757786  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00347703 (* 1 = 0.00347703 loss)
I0422 15:14:27.757792  7918 sgd_solver.cpp:106] Iteration 208, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:32.035053  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:32.035074  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:32.035079  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 27
('accuracy: ', 0.0)
I0422 15:14:32.050806  7918 solver.cpp:228] Iteration 209, loss = 2.33877
I0422 15:14:32.050825  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:32.050833  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.17343 (* 1 = 2.17343 loss)
I0422 15:14:32.050838  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:32.050843  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:32.050846  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:32.050850  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:32.050854  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.1614 (* 1 = 0.1614 loss)
I0422 15:14:32.050859  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00393833 (* 1 = 0.00393833 loss)
I0422 15:14:32.050865  7918 sgd_solver.cpp:106] Iteration 209, lr = 0.0001
speed: 4.308s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:36.349819  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:36.349841  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:36.349846  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 24
('accuracy: ', 0.0)
I0422 15:14:36.365255  7918 solver.cpp:228] Iteration 210, loss = 2.00289
I0422 15:14:36.365283  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:36.365293  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.88311 (* 1 = 1.88311 loss)
I0422 15:14:36.365298  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:36.365301  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:36.365305  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:36.365309  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:36.365314  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.116537 (* 1 = 0.116537 loss)
I0422 15:14:36.365319  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00324707 (* 1 = 0.00324707 loss)
I0422 15:14:36.365324  7918 sgd_solver.cpp:106] Iteration 210, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:40.636270  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:40.636301  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:40.636306  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 31
('accuracy: ', 0.0)
I0422 15:14:40.652009  7918 solver.cpp:228] Iteration 211, loss = 2.08371
I0422 15:14:40.652024  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:40.652032  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.96377 (* 1 = 1.96377 loss)
I0422 15:14:40.652037  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:40.652041  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:40.652045  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:40.652048  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:40.652055  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.116201 (* 1 = 0.116201 loss)
I0422 15:14:40.652060  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00373529 (* 1 = 0.00373529 loss)
I0422 15:14:40.652065  7918 sgd_solver.cpp:106] Iteration 211, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:44.930837  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:44.930860  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:44.930865  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 28
('accuracy: ', 0.0)
I0422 15:14:44.946429  7918 solver.cpp:228] Iteration 212, loss = 2.43537
I0422 15:14:44.946445  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:44.946454  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.29661 (* 1 = 2.29661 loss)
I0422 15:14:44.946460  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:44.946462  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:44.946467  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:44.946470  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:44.946475  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.128623 (* 1 = 0.128623 loss)
I0422 15:14:44.946480  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0101374 (* 1 = 0.0101374 loss)
I0422 15:14:44.946486  7918 sgd_solver.cpp:106] Iteration 212, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:49.234748  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:49.234786  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:49.234791  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 31
('accuracy: ', 0.0)
I0422 15:14:49.250469  7918 solver.cpp:228] Iteration 213, loss = 1.99067
I0422 15:14:49.250486  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:49.250506  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.83615 (* 1 = 1.83615 loss)
I0422 15:14:49.250511  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:49.250515  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:49.250519  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:49.250522  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:49.250526  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.14839 (* 1 = 0.14839 loss)
I0422 15:14:49.250531  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00613448 (* 1 = 0.00613448 loss)
I0422 15:14:49.250536  7918 sgd_solver.cpp:106] Iteration 213, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:14:53.550559  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:14:53.550578  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:53.550582  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 10
num bg: 25
('accuracy: ', 0.0)
I0422 15:14:53.566603  7918 solver.cpp:228] Iteration 214, loss = 2.24236
I0422 15:14:53.566623  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:53.566632  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.06947 (* 1 = 2.06947 loss)
I0422 15:14:53.566645  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:53.566650  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:14:53.566654  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:53.566658  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:53.566663  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.169384 (* 1 = 0.169384 loss)
I0422 15:14:53.566668  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00350731 (* 1 = 0.00350731 loss)
I0422 15:14:53.566673  7918 sgd_solver.cpp:106] Iteration 214, lr = 0.0001
rpn: num_positive 2
rpn: num_negative 62
I0422 15:14:57.862855  7918 accuracy_layer.cpp:96] Accuracy: 0.96875
I0422 15:14:57.862884  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:14:57.862890  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 11
num bg: 18
('accuracy: ', 0.0)
I0422 15:14:57.878572  7918 solver.cpp:228] Iteration 215, loss = 3.59814
I0422 15:14:57.878592  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:14:57.878602  7918 solver.cpp:244]     Train net output #1: loss_cls = 3.49322 (* 1 = 3.49322 loss)
I0422 15:14:57.878607  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:14:57.878610  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.96875
I0422 15:14:57.878614  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:14:57.878618  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:14:57.878623  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0950683 (* 1 = 0.0950683 loss)
I0422 15:14:57.878628  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0098497 (* 1 = 0.0098497 loss)
I0422 15:14:57.878633  7918 sgd_solver.cpp:106] Iteration 215, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 15:15:02.151172  7918 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 15:15:02.151206  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:15:02.151209  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 25
('accuracy: ', 0.0)
I0422 15:15:02.166494  7918 solver.cpp:228] Iteration 216, loss = 2.11271
I0422 15:15:02.166513  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:15:02.166522  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.89789 (* 1 = 1.89789 loss)
I0422 15:15:02.166527  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:15:02.166529  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 15:15:02.166533  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:15:02.166538  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:15:02.166546  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.199545 (* 1 = 0.199545 loss)
I0422 15:15:02.166551  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0152752 (* 1 = 0.0152752 loss)
I0422 15:15:02.166558  7918 sgd_solver.cpp:106] Iteration 216, lr = 0.0001
rpn: num_positive 4
rpn: num_negative 60
I0422 15:15:06.451382  7918 accuracy_layer.cpp:96] Accuracy: 0.9375
I0422 15:15:06.451412  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:15:06.451417  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 9
num bg: 26
('accuracy: ', 0.0)
I0422 15:15:06.466887  7918 solver.cpp:228] Iteration 217, loss = 2.42904
I0422 15:15:06.466908  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:15:06.466917  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.29825 (* 1 = 2.29825 loss)
I0422 15:15:06.466922  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:15:06.466925  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.9375
I0422 15:15:06.466929  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:15:06.466933  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:15:06.466938  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.116639 (* 1 = 0.116639 loss)
I0422 15:15:06.466943  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0141563 (* 1 = 0.0141563 loss)
I0422 15:15:06.466948  7918 sgd_solver.cpp:106] Iteration 217, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:15:10.760360  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:15:10.760382  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:15:10.760386  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 33
('accuracy: ', 0.0)
I0422 15:15:10.776346  7918 solver.cpp:228] Iteration 218, loss = 1.60828
I0422 15:15:10.776365  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:15:10.776371  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.49378 (* 1 = 1.49378 loss)
I0422 15:15:10.776377  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:15:10.776381  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:15:10.776392  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:15:10.776396  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:15:10.776401  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.109733 (* 1 = 0.109733 loss)
I0422 15:15:10.776407  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00476965 (* 1 = 0.00476965 loss)
I0422 15:15:10.776412  7918 sgd_solver.cpp:106] Iteration 218, lr = 0.0001
rpn: num_positive 6
rpn: num_negative 58
I0422 15:15:15.052294  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:15:15.052314  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:15:15.052320  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 32
('accuracy: ', 0.0)
I0422 15:15:15.068013  7918 solver.cpp:228] Iteration 219, loss = 1.9514
I0422 15:15:15.068032  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:15:15.068039  7918 solver.cpp:244]     Train net output #1: loss_cls = 1.85961 (* 1 = 1.85961 loss)
I0422 15:15:15.068044  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:15:15.068048  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:15:15.068053  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:15:15.068056  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:15:15.068060  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0878946 (* 1 = 0.0878946 loss)
I0422 15:15:15.068065  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.0038989 (* 1 = 0.0038989 loss)
I0422 15:15:15.068070  7918 sgd_solver.cpp:106] Iteration 219, lr = 0.0001
speed: 4.307s / iter
rpn: num_positive 6
rpn: num_negative 58
I0422 15:15:19.339609  7918 accuracy_layer.cpp:96] Accuracy: 0.90625
I0422 15:15:19.339630  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:15:19.339637  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 8
num bg: 28
('accuracy: ', 0.0)
I0422 15:15:19.356192  7918 solver.cpp:228] Iteration 220, loss = 2.20101
I0422 15:15:19.356212  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:15:19.356220  7918 solver.cpp:244]     Train net output #1: loss_cls = 2.10276 (* 1 = 2.10276 loss)
I0422 15:15:19.356245  7918 solver.cpp:244]     Train net output #2: loss_twin = 0 (* 1 = 0 loss)
I0422 15:15:19.356252  7918 solver.cpp:244]     Train net output #3: rpn_accuarcy = 0.90625
I0422 15:15:19.356256  7918 solver.cpp:244]     Train net output #4: rpn_accuarcy_class = 1
I0422 15:15:19.356262  7918 solver.cpp:244]     Train net output #5: rpn_accuarcy_class = 0
I0422 15:15:19.356267  7918 solver.cpp:244]     Train net output #6: rpn_cls_loss = 0.0945073 (* 1 = 0.0945073 loss)
I0422 15:15:19.356276  7918 solver.cpp:244]     Train net output #7: rpn_loss_twin = 0.00374145 (* 1 = 0.00374145 loss)
I0422 15:15:19.356281  7918 sgd_solver.cpp:106] Iteration 220, lr = 0.0001
rpn: num_positive 1
rpn: num_negative 63
I0422 15:15:23.644124  7918 accuracy_layer.cpp:96] Accuracy: 0.984375
I0422 15:15:23.644147  7918 accuracy_layer.cpp:101] Class 0 accuracy : 1
I0422 15:15:23.644151  7918 accuracy_layer.cpp:101] Class 1 accuracy : 0
TRAIN
[]
get twin regression called
num fg: 2
num bg: 17
('accuracy: ', 0.0)
I0422 15:15:23.658855  7918 solver.cpp:228] Iteration 221, loss = 1.07593
I0422 15:15:23.658874  7918 solver.cpp:244]     Train net output #0: accuracy = 0
I0422 15:15:23.658881  7918 solver.cpp:2